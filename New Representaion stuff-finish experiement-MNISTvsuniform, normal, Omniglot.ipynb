{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "def MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y):\n",
    "    \"\"\"\n",
    "    Change the one-channel to RBG-channel on mnist_train_x and mnist_test_x\n",
    "    Change the shape of mnist_train_y and mnist_test_y from (length) to (length,1)\n",
    "    ---------------------------------------\n",
    "    inputs:\n",
    "    mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y which is all multi-dimension array\n",
    "    It is recommended to use the following way to import the data\n",
    "    ========================== codes ==========================\n",
    "    mnist = keras.datasets.mnist\n",
    "    (mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "    ========================== codes ==========================\n",
    "    outputs:\n",
    "    mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y \n",
    "    \"\"\"\n",
    "    from skimage import exposure\n",
    "    import imutils\n",
    "    B= []\n",
    "    for i in range(len(mnist_train_x)):\n",
    "        A = mnist_train_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_train_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    B= []\n",
    "    for i in range(len(mnist_test_x)):\n",
    "        A = mnist_test_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_test_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    M_train_y = np.array([[mnist_train_y[i]] for i in range(len(mnist_train_y))])\n",
    "    M_test_y = np.array([[mnist_test_y[i]] for i in range(len(mnist_test_y))])\n",
    "    return mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y\n",
    "mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y = MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('MNIST_vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 25\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        x_train,y_train,x_test,y_test = mnist_train_RGB_x,M_train_y,mnist_test_RGB_x,M_test_y\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('MNIST_vgg.h5')\n",
    "        return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"MNIST-VGG-3.pkl\",\"rb+\")\n",
    "M_VGG_Model3 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"M_representation_uniform, normal, Omniglot.pkl\",\"rb+\")\n",
    "M_representation_others = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"M_representation.pkl\",\"rb+\")\n",
    "M_representation = pickle.load(fp, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_the_orignal_index_after_ranking(arr, isReverse = True):\n",
    "    \"\"\"\n",
    "    This function return the orignal index of the after the array is sorted\n",
    "    inputs:\n",
    "    arr || one dimension list or ndarray\n",
    "    isReverse || boolean, if it is \"True\" the rank is decending; if it is \"False\" the rank is ascending \n",
    "    outputs:\n",
    "    A || an arr including the orignal index before ranking\n",
    "    ========================= examples =========================\n",
    "    For example, arr = [4,7,2,9]\n",
    "    we have the mapping relationship:\n",
    "    index    value\n",
    "      0        4\n",
    "      1        7\n",
    "      2        2\n",
    "      3        9\n",
    "    After sorting, say decendingly, we have:\n",
    "    orignal_index     value\n",
    "      3                 9\n",
    "      1                 7\n",
    "      0                 4\n",
    "      2                 2    \n",
    "    the result is for this function is [3,1,0,2].\n",
    "    \"\"\"\n",
    "    import operator\n",
    "    similarity_dict = dict(zip(list(range(len(arr))),arr))\n",
    "    sorted_similarity_dict = sorted(similarity_dict.items(), reverse=isReverse, key=operator.itemgetter(1))\n",
    "    A = [sorted_similarity_dict[i][0] for i in range(len(arr))]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx(arr, target):\n",
    "    ans = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == target:\n",
    "            ans.append(i)\n",
    "    return ans\n",
    "def get_submax(arr):\n",
    "    arr = np.array(arr)\n",
    "    MAX = np.max(arr)\n",
    "    idx = find_idx(arr, MAX)\n",
    "    arr_without_max = np.delete(arr,idx)\n",
    "    return np.max(arr_without_max)\n",
    "def find_statistics(Prob_Mat):\n",
    "    Prob_diff = []\n",
    "    MAX_Prob_Mat = []\n",
    "    MAX_Prob_Mat_idx = []\n",
    "    subMAX_Prob_Mat = []\n",
    "    subMAX_Prob_Mat_idx = []\n",
    "    for i in range(len(Prob_Mat)):\n",
    "        MAX = np.max(Prob_Mat[i])\n",
    "        MAX_idx = find_idx(Prob_Mat[i], MAX)[0]\n",
    "        subMAX = get_submax(Prob_Mat[i])\n",
    "        subMAX_idx = find_idx(Prob_Mat[i], subMAX)[0]\n",
    "        prob_difference = MAX - subMAX\n",
    "        Prob_diff.append(prob_difference)\n",
    "        MAX_Prob_Mat.append(MAX)\n",
    "        subMAX_Prob_Mat.append(subMAX)\n",
    "        MAX_Prob_Mat_idx.append(MAX_idx)\n",
    "        subMAX_Prob_Mat_idx.append(subMAX_idx)\n",
    "    return Prob_diff,MAX_Prob_Mat,MAX_Prob_Mat_idx,subMAX_Prob_Mat,subMAX_Prob_Mat_idx\n",
    "def separate_one_class(target_class_label, x_train, y_train, x_test, y_test):\n",
    "    with_train_idx = find_idx(y_train, target_class_label)\n",
    "    with_test_idx = find_idx(y_test, target_class_label)\n",
    "    without_train_idx = list(set(range(len(y_train))).difference(set(with_train_idx)))\n",
    "    without_test_idx = list(set(range(len(y_test))).difference(set(with_test_idx)))\n",
    "    with_train = x_train[with_train_idx]\n",
    "    with_test = x_test[with_test_idx]\n",
    "    without_train = x_train[without_train_idx]\n",
    "    without_test = x_test[without_test_idx]\n",
    "    with_train_y = y_train[with_train_idx]\n",
    "    with_test_y = y_test[with_test_idx]\n",
    "    without_train_y = y_train[without_train_idx]\n",
    "    without_test_y = y_test[without_test_idx]\n",
    "    return with_train, with_train_y, without_train, without_train_y, with_test, with_test_y, without_test, without_test_y\n",
    "def minkowski_distance(x,y,n):\n",
    "    if np.isinf(n):\n",
    "        if n>0:\n",
    "            return np.max(np.abs(x-y))\n",
    "        else:\n",
    "            return np.min(np.abs(x-y))\n",
    "    else:\n",
    "        return np.power(np.sum(np.power(np.abs(x-y),n)),1/n)\n",
    "def minkowski_similarity(x,Y,n):\n",
    "    arr = []\n",
    "    for y in Y:\n",
    "        arr.append(minkowski_distance(x,y,n))\n",
    "    return np.array(arr)\n",
    "\n",
    "def get_KNN_stats(k,testarr_one_sample, testarr_waiting_to_compare, \n",
    "                  testarr_waiting_to_compare_label, Model, similarity_method = 'cosine_similarity', minkowski_power = 2):\n",
    "    \"\"\"\n",
    "    Inputs Example:\n",
    "    k = 50\n",
    "    testarr_one_sample = [mnist_train_RGB_x[0]]\n",
    "    testarr_waiting_to_compare = [C_x_train[i] for i in range(5000)]\n",
    "    testarr_waiting_to_compare_label = C_y_train[:5000].reshape(5000)\n",
    "    Model = C_VGG_Model1.model\n",
    "    \n",
    "    Inputs:\n",
    "    k: int, the number of the nearest neighbour\n",
    "    testarr_one_sample: multi-dimensional ndarray, shape = (1,num_pixel_x,num_pixel_y,num_channel)\n",
    "    testarr_waiting_to_compare_label: multi-dimensional ndarray, shape = (num_neighbour_candidate,num_pixel_x,num_pixel_y,num_channel)\n",
    "    testarr_waiting_to_compare_label: one-dimensional ndarray, shape = (num_neighbour_candidate,)\n",
    "    Model: keras backend model\n",
    "    similarity_method: String, 'cosine_similarity', 'minkowski_similarity'. Default = 'cosine_similarity'\n",
    "    minkowski_power: int, the p-value in the minkowski_distance. Only useful when similarity_method = 'minkowski_similarity'\n",
    "    \n",
    "    Outputs:\n",
    "    similarity: one-dimensional ndarray, shape = (num_neighbour_candidate,)\n",
    "    K_nearest_neighbour_orignal_label: one-dimensional ndarray, shape = (k,)\n",
    "    K_nearest_neighbour: multi-dimensional ndarray, shape = (k,num_pixel_x,num_pixel_y,num_channel)\n",
    "    KNN_oringal_class: dictionary, counts of the orignal class\n",
    "    max_ratio_KNN_from_one_class: float, the max of the ratio of KNN are from one class\n",
    "    \"\"\"\n",
    "    from keras import backend as K\n",
    "    testarr_waiting_to_compare = np.array(testarr_waiting_to_compare)\n",
    "    inp = Model.model.input                                           # input placeholder\n",
    "    outputs = Model.model.layers[55].output          # all layer outputs\n",
    "    functors = K.function([inp, K.learning_phase()], [outputs])   # evaluation functions\n",
    "\n",
    "    # Testing\n",
    "    test1 = testarr_one_sample\n",
    "    layer_outs_one_sample = functors([test1, 0.])\n",
    "    layer_outs_one_sample = np.array(layer_outs_one_sample)[0]\n",
    "\n",
    "    test2 = testarr_waiting_to_compare\n",
    "    layer_outs_waiting_to_compare = functors([test2, 0.])\n",
    "    layer_outs_waiting_to_compare = np.array(layer_outs_waiting_to_compare)[0]\n",
    "    if similarity_method == 'cosine_similarity':\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarity = cosine_similarity(layer_outs_one_sample, layer_outs_waiting_to_compare)\n",
    "        similarity = np.array(similarity[0])\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity)[:k]\n",
    "    elif similarity_method == 'minkowski_similarity':\n",
    "        similarity = minkowski_similarity(layer_outs_one_sample, layer_outs_waiting_to_compare, minkowski_power)\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity, isReverse = False)[:k]\n",
    "    else:\n",
    "        raise Exception(\"invalid similarity method\")\n",
    "    K_nearest_neighbour_orignal_label = np.array(K_nearest_neighbour_orignal_label)\n",
    "    K_nearest_neighbour = testarr_waiting_to_compare[K_nearest_neighbour_orignal_label]\n",
    "    from collections import Counter\n",
    "    KNN_oringal_class = Counter(testarr_waiting_to_compare_label[K_nearest_neighbour_orignal_label])\n",
    "    max_ratio_KNN_from_one_class = max(KNN_oringal_class.values())/k\n",
    "    import operator\n",
    "    max_KNN_class_label = max(KNN_oringal_class.items(), key=operator.itemgetter(1))[0]\n",
    "    return similarity, K_nearest_neighbour_orignal_label, K_nearest_neighbour, KNN_oringal_class, max_ratio_KNN_from_one_class, max_KNN_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(columns,rows,arr):\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img = arr[i-1]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_representations(testarr_one_sample, testarr_waiting_to_compare,testarr_waiting_to_compare_label, MODEL, similarity_method = 'minkowski_similarity', minkowski_power = 2):\n",
    "    arr_KNN_from_same_class_ratio = []\n",
    "    arr_KNN_max_class_label = []\n",
    "    arr_KNN_similarity = []\n",
    "    testarr_waiting_to_compare = testarr_waiting_to_compare[:5000]\n",
    "    testarr_waiting_to_compare_label = testarr_waiting_to_compare_label[:5000].reshape(5000)\n",
    "    for j in range(500):\n",
    "        print(\"current sample: \", j)\n",
    "        k = 50\n",
    "        testarr_one_sample_1 = [testarr_one_sample[j]]\n",
    "        result_l2 = get_KNN_stats(k,testarr_one_sample_1, testarr_waiting_to_compare, \n",
    "                  testarr_waiting_to_compare_label, MODEL, similarity_method = 'minkowski_similarity', minkowski_power = 2)\n",
    "        arr_KNN_from_same_class_ratio.append(result_l2[4])\n",
    "        arr_KNN_max_class_label.append(result_l2[5])\n",
    "        arr_KNN_similarity.append(sorted(result_l2[0],reverse = False))\n",
    "    pred_labels = MODEL.predict(testarr_one_sample[:500])\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],})\n",
    "    return arr_KNN_similarity, arr_KNN_from_same_class_ratio, arr_KNN_max_class_label, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(List):\n",
    "    return np.array(List).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KNN_stats_new(k,testarr_one_sample, testarr_waiting_to_compare, testarr_waiting_to_compare_label, similarity_method = 'cosine_similarity', minkowski_power = 2):\n",
    "    \"\"\"\n",
    "    Inputs Example:\n",
    "    k = 50\n",
    "    testarr_one_sample = [mnist_train_RGB_x[0]]\n",
    "    testarr_waiting_to_compare = [C_x_train[i] for i in range(5000)]\n",
    "    testarr_waiting_to_compare_label = C_y_train[:5000].reshape(5000)\n",
    "    Model = C_VGG_Model1.model\n",
    "    \n",
    "    Inputs:\n",
    "    k: int, the number of the nearest neighbour\n",
    "    testarr_one_sample: multi-dimensional ndarray, shape = (1,num_pixel_x,num_pixel_y,num_channel)\n",
    "    testarr_waiting_to_compare_label: multi-dimensional ndarray, shape = (num_neighbour_candidate,num_pixel_x,num_pixel_y,num_channel)\n",
    "    testarr_waiting_to_compare_label: one-dimensional ndarray, shape = (num_neighbour_candidate,)\n",
    "    Model: keras backend model\n",
    "    similarity_method: String, 'cosine_similarity', 'minkowski_similarity'. Default = 'cosine_similarity'\n",
    "    minkowski_power: int, the p-value in the minkowski_distance. Only useful when similarity_method = 'minkowski_similarity'\n",
    "    \n",
    "    Outputs:\n",
    "    similarity: one-dimensional ndarray, shape = (num_neighbour_candidate,)\n",
    "    K_nearest_neighbour_orignal_label: one-dimensional ndarray, shape = (k,)\n",
    "    K_nearest_neighbour: multi-dimensional ndarray, shape = (k,num_pixel_x,num_pixel_y,num_channel)\n",
    "    KNN_oringal_class: dictionary, counts of the orignal class\n",
    "    max_ratio_KNN_from_one_class: float, the max of the ratio of KNN are from one class\n",
    "    \"\"\"\n",
    "    if similarity_method == 'cosine_similarity':\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarity = cosine_similarity(testarr_one_sample, testarr_waiting_to_compare)\n",
    "        similarity = np.array(similarity[0])\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity)[:k]\n",
    "    elif similarity_method == 'minkowski_similarity':\n",
    "        similarity = minkowski_similarity(testarr_one_sample, testarr_waiting_to_compare, minkowski_power)\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity, isReverse = False)[:k]\n",
    "    else:\n",
    "        raise Exception(\"invalid similarity method\")\n",
    "    K_nearest_neighbour_orignal_label = np.array(K_nearest_neighbour_orignal_label)\n",
    "    K_nearest_neighbour = testarr_waiting_to_compare[K_nearest_neighbour_orignal_label]\n",
    "    from collections import Counter\n",
    "    KNN_oringal_class = Counter(testarr_waiting_to_compare_label[K_nearest_neighbour_orignal_label])\n",
    "    max_ratio_KNN_from_one_class = max(KNN_oringal_class.values())/k\n",
    "    import operator\n",
    "    max_KNN_class_label = max(KNN_oringal_class.items(), key=operator.itemgetter(1))[0]\n",
    "    return similarity, K_nearest_neighbour_orignal_label, K_nearest_neighbour, KNN_oringal_class, max_ratio_KNN_from_one_class, max_KNN_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_representations(testarr_one_sample, testarr_waiting_to_compare,testarr_waiting_to_compare_label, MODEL, similarity_method = 'minkowski_similarity', minkowski_power = 2):\n",
    "    arr_KNN_from_same_class_ratio = []\n",
    "    arr_KNN_max_class_label = []\n",
    "    arr_KNN_similarity = []\n",
    "    testarr_waiting_to_compare = testarr_waiting_to_compare\n",
    "    testarr_waiting_to_compare_label = testarr_waiting_to_compare_label.reshape(len(testarr_waiting_to_compare_label))\n",
    "    for j in range(500):\n",
    "        if j%50 == 0:\n",
    "            print(\"current sample: \", j)\n",
    "        k = 50\n",
    "        testarr_one_sample_1 = [testarr_one_sample[j]]\n",
    "        result_l2 = get_KNN_stats_new(k,testarr_one_sample_1, testarr_waiting_to_compare, \n",
    "                  testarr_waiting_to_compare_label, similarity_method = 'minkowski_similarity', minkowski_power = 2)\n",
    "        arr_KNN_from_same_class_ratio.append(result_l2[4])\n",
    "        arr_KNN_max_class_label.append(result_l2[5])\n",
    "        arr_KNN_similarity.append(sorted(result_l2[0],reverse = False))\n",
    "    #pred_labels = MODEL.predict(testarr_one_sample[:500])\n",
    "    return arr_KNN_similarity, arr_KNN_from_same_class_ratio, arr_KNN_max_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  0\n",
      "current sample:  50\n",
      "current sample:  100\n",
      "current sample:  150\n",
      "current sample:  200\n",
      "current sample:  250\n",
      "current sample:  300\n",
      "current sample:  350\n",
      "current sample:  400\n",
      "current sample:  450\n"
     ]
    }
   ],
   "source": [
    "M_representation_result_ODu = compare_representations(M_representation_others[\"uniform\"],M_representation[\"MNIST_train\"],M_train_y,M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  0\n",
      "current sample:  50\n",
      "current sample:  100\n",
      "current sample:  150\n",
      "current sample:  200\n",
      "current sample:  250\n",
      "current sample:  300\n",
      "current sample:  350\n",
      "current sample:  400\n",
      "current sample:  450\n"
     ]
    }
   ],
   "source": [
    "M_representation_result_ODn = compare_representations(M_representation_others[\"normal\"],M_representation[\"MNIST_train\"],M_train_y,M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  0\n",
      "current sample:  50\n",
      "current sample:  100\n",
      "current sample:  150\n",
      "current sample:  200\n",
      "current sample:  250\n",
      "current sample:  300\n",
      "current sample:  350\n",
      "current sample:  400\n",
      "current sample:  450\n"
     ]
    }
   ],
   "source": [
    "M_representation_result_ODO = compare_representations(M_representation_others[\"Omniglot_RBG\"],M_representation[\"MNIST_train\"],M_train_y,M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(M_representation_result_ODu, open(\"M_representation_result_ODu.pkl\", \"wb\"))\n",
    "pickle.dump(M_representation_result_ODn, open(\"M_representation_result_ODn.pkl\", \"wb\"))\n",
    "pickle.dump(M_representation_result_ODO, open(\"M_representation_result_ODO.pkl\", \"wb\"))\n",
    "#pickle.dump(df_M_0_8_representation_result_ID08, open(\"df_M_0_8_representation_result_ID08.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concact_results(one_sample,arr_KNN_from_same_class_ratio, arr_KNN_max_class_label,MODEL):\n",
    "    pred_labels = MODEL.predict(one_sample[:500])\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency_of_df(df, upper_bound, lower_bound):\n",
    "    return len(df[df['arr_KNN_from_same_class_ratio']>upper_bound][df['arr_KNN_max_class_label'] == df['predicted_label']])/len(df[df['arr_KNN_from_same_class_ratio']>upper_bound]), len(df[df['arr_KNN_from_same_class_ratio']<lower_bound][df['arr_KNN_max_class_label'] == df['predicted_label']])/len(df[df['arr_KNN_from_same_class_ratio']<lower_bound])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "normal = np.random.randn(10000,32,32,3)\n",
    "uniform = np.random.uniform(0,1,[10000,32,32,3])\n",
    "# load Omniglot\n",
    "import scipy.io as sio\n",
    "import scipy.misc as scimisc\n",
    "\n",
    "# other alphabets have characters which overlap\n",
    "safe_list = [0,2,5,6,8,12,13,14,15,16,17,18,19,21,26]\n",
    "m = sio.loadmat(\"./data_background.mat\")\n",
    "\n",
    "squished_set = []\n",
    "for safe_number in safe_list:\n",
    "    for alphabet in m['images'][safe_number]:\n",
    "        for letters in alphabet:\n",
    "            for letter in letters:\n",
    "                for example in letter:\n",
    "                    squished_set.append(scimisc.imresize(1 - example[0], (28,28)).reshape(1, 28, 28))\n",
    "\n",
    "omni_images = np.concatenate(squished_set, axis=0)\n",
    "\n",
    "def MNIST_To_CIFAR_FORM_only_x(mnist_x):\n",
    "    \"\"\"\n",
    "    Change the one-channel to RBG-channel on mnist_x and mnist_test_x\n",
    "    ---------------------------------------\n",
    "    inputs:\n",
    "    mnist_x\n",
    "    It is recommended to use the following way to import the data\n",
    "    ========================== codes ==========================\n",
    "    mnist = keras.datasets.mnist\n",
    "    (mnist_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "    ========================== codes ==========================\n",
    "    outputs:\n",
    "    mnist_RGB_x \n",
    "    \"\"\"\n",
    "    from skimage import exposure\n",
    "    import imutils\n",
    "    B= []\n",
    "    for i in range(len(mnist_x)):\n",
    "        A = mnist_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    return mnist_RGB_x \n",
    "Omniglot_RBG = MNIST_To_CIFAR_FORM_only_x(omni_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n\t [[activation_15/Softmax/_1119]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4834d3d93f14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_M_representation_result_ODu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcact_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_representation_result_ODu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_representation_result_ODu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_VGG_Model3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-dc2246429dab>\u001b[0m in \u001b[0;36mconcact_results\u001b[1;34m(one_sample, arr_KNN_from_same_class_ratio, arr_KNN_max_class_label, MODEL)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconcact_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr_KNN_from_same_class_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_KNN_max_class_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n\u001b[0;32m      5\u001b[0m                    \u001b[1;34m'arr_KNN_from_same_class_ratio'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0marr_KNN_from_same_class_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-6f1b48e0cbd8>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, normalize, batch_size)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_production\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n\t [[activation_15/Softmax/_1119]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "df_M_representation_result_ODu = concact_results(uniform,M_representation_result_ODu[1],M_representation_result_ODu[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_M_representation_result_ODn = concact_results(normal,M_representation_result_ODn[1],M_representation_result_ODn[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_M_representation_result_ODO = concact_results(Omniglot_RBG,M_representation_result_ODO[1],M_representation_result_ODO[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.779246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4</td>\n",
       "      <td>0.734795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5</td>\n",
       "      <td>0.583358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.735721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.748191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.810133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.924085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.785306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4</td>\n",
       "      <td>0.625522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.857798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.979567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.778145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.856598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.867970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.839399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>0.812805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.945570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.945596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.447464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.871873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.933080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.556835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.925722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.889595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.981764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.756854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.974823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.912130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.849399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.653947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.656185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.544027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.905065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.717810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.880046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.940243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.768241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.748739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.766666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.886173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.925285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          1                           0.96                4   \n",
       "1                          8                           0.96                4   \n",
       "7                          1                           0.86                4   \n",
       "8                          1                           0.78                4   \n",
       "9                          5                           0.96                5   \n",
       "11                         1                           1.00                4   \n",
       "12                         1                           1.00                4   \n",
       "15                         1                           0.98                4   \n",
       "16                         1                           0.96                4   \n",
       "19                         7                           0.98                7   \n",
       "21                         1                           0.96                4   \n",
       "22                         7                           0.88                4   \n",
       "23                         1                           1.00                4   \n",
       "24                         8                           1.00                4   \n",
       "25                         1                           0.90                4   \n",
       "26                         1                           0.86                4   \n",
       "27                         1                           0.74                4   \n",
       "29                         7                           0.80                7   \n",
       "30                         1                           0.94                4   \n",
       "31                         7                           0.80                7   \n",
       "32                         8                           1.00                4   \n",
       "35                         1                           0.86                4   \n",
       "36                         4                           1.00                4   \n",
       "38                         1                           0.98                4   \n",
       "39                         8                           1.00                4   \n",
       "40                         1                           0.98                4   \n",
       "43                         1                           0.96                4   \n",
       "44                         1                           1.00                4   \n",
       "47                         1                           0.74                4   \n",
       "48                         8                           0.90                4   \n",
       "..                       ...                            ...              ...   \n",
       "452                        1                           0.96                4   \n",
       "454                        1                           0.84                4   \n",
       "455                        1                           0.98                4   \n",
       "456                        1                           0.98                4   \n",
       "458                        1                           0.98                4   \n",
       "459                        7                           1.00                7   \n",
       "462                        8                           1.00                4   \n",
       "464                        7                           0.92                7   \n",
       "465                        1                           0.96                4   \n",
       "466                        1                           0.96                4   \n",
       "468                        8                           1.00                4   \n",
       "469                        1                           0.86                4   \n",
       "471                        8                           1.00                4   \n",
       "477                        1                           0.96                4   \n",
       "478                        0                           0.80                4   \n",
       "480                        1                           0.92                4   \n",
       "481                        1                           0.94                4   \n",
       "483                        1                           0.98                4   \n",
       "485                        1                           0.90                4   \n",
       "486                        1                           1.00                4   \n",
       "488                        1                           0.98                4   \n",
       "489                        1                           1.00                4   \n",
       "491                        1                           0.96                4   \n",
       "492                        1                           1.00                4   \n",
       "494                        1                           0.96                4   \n",
       "495                        4                           1.00                4   \n",
       "496                        1                           0.98                4   \n",
       "497                        1                           1.00                4   \n",
       "498                        1                           0.98                4   \n",
       "499                        0                           0.96                4   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.779246  \n",
       "1          0.394128  \n",
       "7          0.983009  \n",
       "8          0.734795  \n",
       "9          0.583358  \n",
       "11         0.735721  \n",
       "12         0.748191  \n",
       "15         0.810133  \n",
       "16         0.918515  \n",
       "19         0.924085  \n",
       "21         0.785306  \n",
       "22         0.625522  \n",
       "23         0.794588  \n",
       "24         0.857798  \n",
       "25         0.979567  \n",
       "26         0.910612  \n",
       "27         0.778145  \n",
       "29         0.856598  \n",
       "30         0.867970  \n",
       "31         0.973859  \n",
       "32         0.839399  \n",
       "35         0.812805  \n",
       "36         0.994769  \n",
       "38         0.834451  \n",
       "39         0.945570  \n",
       "40         0.924879  \n",
       "43         0.943835  \n",
       "44         0.945596  \n",
       "47         0.533666  \n",
       "48         0.447464  \n",
       "..              ...  \n",
       "452        0.871873  \n",
       "454        0.933080  \n",
       "455        0.556835  \n",
       "456        0.925722  \n",
       "458        0.889595  \n",
       "459        0.981764  \n",
       "462        0.756854  \n",
       "464        0.974823  \n",
       "465        0.912130  \n",
       "466        0.849399  \n",
       "468        0.653947  \n",
       "469        0.978208  \n",
       "471        0.693887  \n",
       "477        0.656185  \n",
       "478        0.544027  \n",
       "480        0.905065  \n",
       "481        0.717810  \n",
       "483        0.880046  \n",
       "485        0.940243  \n",
       "486        0.803712  \n",
       "488        0.768241  \n",
       "489        0.748739  \n",
       "491        0.887449  \n",
       "492        0.851937  \n",
       "494        0.766666  \n",
       "495        0.993144  \n",
       "496        0.886173  \n",
       "497        0.925285  \n",
       "498        0.530849  \n",
       "499        0.518579  \n",
       "\n",
       "[316 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_0_8_representation_result_OD9[df_M_0_8_representation_result_OD9['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.385660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.635771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.940748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.796542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.635101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.936760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.915929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.975624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.285626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.526346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.649795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.491619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.763466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.976859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.691083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.597333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.941857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.689748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.310066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.734251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.937410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.819631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.925497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.949755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.915611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.761129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.848023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.804883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.585273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.631030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.696393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.885402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.721341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.520805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.840393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.622980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.337043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.649017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.670777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.951652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.679695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.455854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.954169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.988551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.385437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.904320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.773604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.569354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.764359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.912265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.966256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.435968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.726247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.938607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.903497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "2                          6                           0.32                4   \n",
       "5                          8                           0.34                4   \n",
       "6                          2                           0.22                4   \n",
       "13                         8                           0.28                7   \n",
       "34                         0                           0.38                4   \n",
       "42                         1                           0.38                4   \n",
       "45                         2                           0.26                7   \n",
       "52                         8                           0.28                7   \n",
       "54                         8                           0.30                7   \n",
       "58                         0                           0.32                4   \n",
       "61                         8                           0.38                7   \n",
       "63                         6                           0.36                4   \n",
       "79                         6                           0.36                7   \n",
       "88                         2                           0.30                7   \n",
       "103                        8                           0.34                4   \n",
       "108                        6                           0.36                4   \n",
       "112                        8                           0.32                7   \n",
       "118                        8                           0.36                4   \n",
       "120                        8                           0.32                4   \n",
       "126                        2                           0.28                7   \n",
       "131                        8                           0.24                7   \n",
       "140                        7                           0.22                4   \n",
       "147                        8                           0.36                4   \n",
       "149                        8                           0.36                7   \n",
       "153                        8                           0.26                7   \n",
       "156                        2                           0.38                7   \n",
       "158                        8                           0.28                7   \n",
       "160                        0                           0.36                4   \n",
       "161                        0                           0.30                4   \n",
       "162                        8                           0.32                7   \n",
       "..                       ...                            ...              ...   \n",
       "303                        2                           0.28                7   \n",
       "310                        8                           0.36                4   \n",
       "313                        7                           0.22                4   \n",
       "325                        8                           0.22                4   \n",
       "327                        1                           0.36                4   \n",
       "342                        2                           0.38                7   \n",
       "348                        8                           0.38                7   \n",
       "355                        8                           0.32                7   \n",
       "359                        0                           0.38                4   \n",
       "363                        1                           0.38                7   \n",
       "384                        0                           0.36                4   \n",
       "385                        7                           0.22                4   \n",
       "388                        8                           0.28                4   \n",
       "389                        8                           0.24                7   \n",
       "397                        8                           0.34                4   \n",
       "407                        8                           0.38                7   \n",
       "416                        8                           0.36                7   \n",
       "418                        7                           0.30                7   \n",
       "421                        8                           0.26                7   \n",
       "436                        8                           0.38                5   \n",
       "448                        7                           0.24                7   \n",
       "451                        8                           0.36                7   \n",
       "453                        8                           0.30                7   \n",
       "457                        8                           0.38                7   \n",
       "460                        8                           0.30                7   \n",
       "467                        8                           0.34                7   \n",
       "472                        1                           0.36                4   \n",
       "474                        8                           0.34                7   \n",
       "475                        6                           0.34                7   \n",
       "484                        8                           0.28                7   \n",
       "\n",
       "     predicted_prob  \n",
       "2          0.831224  \n",
       "5          0.385660  \n",
       "6          0.635771  \n",
       "13         0.940748  \n",
       "34         0.796542  \n",
       "42         0.635101  \n",
       "45         0.936760  \n",
       "52         0.915929  \n",
       "54         0.975624  \n",
       "58         0.285626  \n",
       "61         0.526346  \n",
       "63         0.649795  \n",
       "79         0.863946  \n",
       "88         0.491619  \n",
       "103        0.794951  \n",
       "108        0.763466  \n",
       "112        0.976859  \n",
       "118        0.691083  \n",
       "120        0.597333  \n",
       "126        0.941857  \n",
       "131        0.689748  \n",
       "140        0.310066  \n",
       "147        0.734251  \n",
       "149        0.937410  \n",
       "153        0.819631  \n",
       "156        0.925497  \n",
       "158        0.949755  \n",
       "160        0.915611  \n",
       "161        0.761129  \n",
       "162        0.825662  \n",
       "..              ...  \n",
       "303        0.848023  \n",
       "310        0.804883  \n",
       "313        0.585273  \n",
       "325        0.631030  \n",
       "327        0.696393  \n",
       "342        0.885402  \n",
       "348        0.721341  \n",
       "355        0.520805  \n",
       "359        0.840393  \n",
       "363        0.622980  \n",
       "384        0.337043  \n",
       "385        0.649017  \n",
       "388        0.670777  \n",
       "389        0.951652  \n",
       "397        0.679695  \n",
       "407        0.455854  \n",
       "416        0.954169  \n",
       "418        0.988551  \n",
       "421        0.800987  \n",
       "436        0.385437  \n",
       "448        0.904320  \n",
       "451        0.773604  \n",
       "453        0.569354  \n",
       "457        0.764359  \n",
       "460        0.912265  \n",
       "467        0.966256  \n",
       "472        0.435968  \n",
       "474        0.726247  \n",
       "475        0.938607  \n",
       "484        0.903497  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_0_8_representation_result_OD9[df_M_0_8_representation_result_OD9['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.793249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.886852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5</td>\n",
       "      <td>0.937563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.877053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.890290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.946549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0.965449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4</td>\n",
       "      <td>0.595229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.984074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.792731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.559310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.937245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>0.912216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.789667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.488045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.596210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.606832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.626083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.983698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.996578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          7                           1.00                7   \n",
       "1                          2                           0.92                2   \n",
       "2                          1                           0.94                1   \n",
       "3                          0                           1.00                0   \n",
       "4                          4                           1.00                4   \n",
       "5                          1                           1.00                1   \n",
       "6                          4                           1.00                4   \n",
       "7                          2                           0.36                5   \n",
       "8                          0                           1.00                0   \n",
       "9                          6                           1.00                6   \n",
       "10                         0                           1.00                0   \n",
       "11                         1                           1.00                1   \n",
       "12                         5                           1.00                5   \n",
       "13                         7                           1.00                7   \n",
       "14                         3                           0.96                5   \n",
       "15                         4                           1.00                4   \n",
       "16                         6                           1.00                6   \n",
       "17                         6                           1.00                6   \n",
       "18                         5                           1.00                5   \n",
       "19                         4                           0.94                4   \n",
       "20                         0                           1.00                0   \n",
       "21                         2                           0.70                7   \n",
       "22                         4                           1.00                4   \n",
       "23                         0                           1.00                0   \n",
       "24                         1                           0.70                4   \n",
       "25                         3                           1.00                3   \n",
       "26                         1                           1.00                4   \n",
       "27                         3                           1.00                3   \n",
       "28                         4                           1.00                4   \n",
       "29                         7                           1.00                7   \n",
       "..                       ...                            ...              ...   \n",
       "470                        3                           1.00                3   \n",
       "471                        3                           0.28                3   \n",
       "472                        3                           0.98                3   \n",
       "473                        1                           0.98                1   \n",
       "474                        3                           1.00                5   \n",
       "475                        4                           1.00                4   \n",
       "476                        4                           1.00                4   \n",
       "477                        6                           1.00                6   \n",
       "478                        4                           1.00                4   \n",
       "479                        5                           0.86                5   \n",
       "480                        1                           0.96                1   \n",
       "481                        8                           1.00                5   \n",
       "482                        2                           1.00                2   \n",
       "483                        5                           1.00                5   \n",
       "484                        4                           1.00                4   \n",
       "485                        1                           1.00                4   \n",
       "486                        8                           1.00                4   \n",
       "487                        4                           1.00                4   \n",
       "488                        0                           1.00                0   \n",
       "489                        0                           1.00                0   \n",
       "490                        2                           0.62                2   \n",
       "491                        3                           1.00                3   \n",
       "492                        2                           1.00                2   \n",
       "493                        7                           1.00                7   \n",
       "494                        7                           0.30                4   \n",
       "495                        0                           0.84                0   \n",
       "496                        8                           1.00                8   \n",
       "497                        7                           1.00                7   \n",
       "498                        4                           1.00                4   \n",
       "499                        4                           1.00                4   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.995818  \n",
       "1          0.985263  \n",
       "2          0.849739  \n",
       "3          0.997723  \n",
       "4          0.999044  \n",
       "5          0.970869  \n",
       "6          0.997948  \n",
       "7          0.793249  \n",
       "8          0.999009  \n",
       "9          0.886852  \n",
       "10         0.994669  \n",
       "11         0.264592  \n",
       "12         0.998388  \n",
       "13         0.995876  \n",
       "14         0.937563  \n",
       "15         0.995262  \n",
       "16         0.877053  \n",
       "17         0.890290  \n",
       "18         0.998756  \n",
       "19         0.946549  \n",
       "20         0.999071  \n",
       "21         0.965449  \n",
       "22         0.999916  \n",
       "23         0.992375  \n",
       "24         0.595229  \n",
       "25         0.998672  \n",
       "26         0.504665  \n",
       "27         0.998174  \n",
       "28         0.984074  \n",
       "29         0.998268  \n",
       "..              ...  \n",
       "470        0.995834  \n",
       "471        0.792731  \n",
       "472        0.996670  \n",
       "473        0.846271  \n",
       "474        0.559310  \n",
       "475        0.999865  \n",
       "476        0.999983  \n",
       "477        0.937245  \n",
       "478        0.999451  \n",
       "479        0.912216  \n",
       "480        0.953811  \n",
       "481        0.745369  \n",
       "482        0.992680  \n",
       "483        0.998476  \n",
       "484        0.999976  \n",
       "485        0.789667  \n",
       "486        0.488045  \n",
       "487        0.999785  \n",
       "488        0.990974  \n",
       "489        0.998066  \n",
       "490        0.945494  \n",
       "491        0.994918  \n",
       "492        0.999031  \n",
       "493        0.596210  \n",
       "494        0.606832  \n",
       "495        0.988056  \n",
       "496        0.626083  \n",
       "497        0.983698  \n",
       "498        0.996578  \n",
       "499        0.999951  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_0_8_representation_result_ID08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.793249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.798814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.302892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.765115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.792731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.606832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "7                          2                           0.36                5   \n",
       "201                        8                           0.28                4   \n",
       "207                        8                           0.28                3   \n",
       "249                        1                           0.26                2   \n",
       "414                        2                           0.30                2   \n",
       "420                        8                           0.30                7   \n",
       "421                        8                           0.36                5   \n",
       "471                        3                           0.28                3   \n",
       "494                        7                           0.30                4   \n",
       "\n",
       "     predicted_prob  \n",
       "7          0.793249  \n",
       "201        0.798814  \n",
       "207        0.965807  \n",
       "249        0.888290  \n",
       "414        0.302892  \n",
       "420        0.989823  \n",
       "421        0.765115  \n",
       "471        0.792731  \n",
       "494        0.606832  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_0_8_representation_result_ID08[df_M_0_8_representation_result_ID08['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.886852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5</td>\n",
       "      <td>0.937563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.877053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.890290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.946549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.984074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.979276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.559310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.937245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>0.912216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.789667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.488045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.596210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.626083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.983698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.996578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          7                           1.00                7   \n",
       "1                          2                           0.92                2   \n",
       "2                          1                           0.94                1   \n",
       "3                          0                           1.00                0   \n",
       "4                          4                           1.00                4   \n",
       "5                          1                           1.00                1   \n",
       "6                          4                           1.00                4   \n",
       "8                          0                           1.00                0   \n",
       "9                          6                           1.00                6   \n",
       "10                         0                           1.00                0   \n",
       "11                         1                           1.00                1   \n",
       "12                         5                           1.00                5   \n",
       "13                         7                           1.00                7   \n",
       "14                         3                           0.96                5   \n",
       "15                         4                           1.00                4   \n",
       "16                         6                           1.00                6   \n",
       "17                         6                           1.00                6   \n",
       "18                         5                           1.00                5   \n",
       "19                         4                           0.94                4   \n",
       "20                         0                           1.00                0   \n",
       "22                         4                           1.00                4   \n",
       "23                         0                           1.00                0   \n",
       "25                         3                           1.00                3   \n",
       "26                         1                           1.00                4   \n",
       "27                         3                           1.00                3   \n",
       "28                         4                           1.00                4   \n",
       "29                         7                           1.00                7   \n",
       "30                         2                           1.00                2   \n",
       "31                         7                           0.98                7   \n",
       "32                         1                           0.98                1   \n",
       "..                       ...                            ...              ...   \n",
       "467                        1                           0.98                1   \n",
       "468                        3                           1.00                3   \n",
       "469                        0                           1.00                0   \n",
       "470                        3                           1.00                3   \n",
       "472                        3                           0.98                3   \n",
       "473                        1                           0.98                1   \n",
       "474                        3                           1.00                5   \n",
       "475                        4                           1.00                4   \n",
       "476                        4                           1.00                4   \n",
       "477                        6                           1.00                6   \n",
       "478                        4                           1.00                4   \n",
       "479                        5                           0.86                5   \n",
       "480                        1                           0.96                1   \n",
       "481                        8                           1.00                5   \n",
       "482                        2                           1.00                2   \n",
       "483                        5                           1.00                5   \n",
       "484                        4                           1.00                4   \n",
       "485                        1                           1.00                4   \n",
       "486                        8                           1.00                4   \n",
       "487                        4                           1.00                4   \n",
       "488                        0                           1.00                0   \n",
       "489                        0                           1.00                0   \n",
       "491                        3                           1.00                3   \n",
       "492                        2                           1.00                2   \n",
       "493                        7                           1.00                7   \n",
       "495                        0                           0.84                0   \n",
       "496                        8                           1.00                8   \n",
       "497                        7                           1.00                7   \n",
       "498                        4                           1.00                4   \n",
       "499                        4                           1.00                4   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.995818  \n",
       "1          0.985263  \n",
       "2          0.849739  \n",
       "3          0.997723  \n",
       "4          0.999044  \n",
       "5          0.970869  \n",
       "6          0.997948  \n",
       "8          0.999009  \n",
       "9          0.886852  \n",
       "10         0.994669  \n",
       "11         0.264592  \n",
       "12         0.998388  \n",
       "13         0.995876  \n",
       "14         0.937563  \n",
       "15         0.995262  \n",
       "16         0.877053  \n",
       "17         0.890290  \n",
       "18         0.998756  \n",
       "19         0.946549  \n",
       "20         0.999071  \n",
       "22         0.999916  \n",
       "23         0.992375  \n",
       "25         0.998672  \n",
       "26         0.504665  \n",
       "27         0.998174  \n",
       "28         0.984074  \n",
       "29         0.998268  \n",
       "30         0.998196  \n",
       "31         0.979276  \n",
       "32         0.633883  \n",
       "..              ...  \n",
       "467        0.923346  \n",
       "468        0.987442  \n",
       "469        0.998508  \n",
       "470        0.995834  \n",
       "472        0.996670  \n",
       "473        0.846271  \n",
       "474        0.559310  \n",
       "475        0.999865  \n",
       "476        0.999983  \n",
       "477        0.937245  \n",
       "478        0.999451  \n",
       "479        0.912216  \n",
       "480        0.953811  \n",
       "481        0.745369  \n",
       "482        0.992680  \n",
       "483        0.998476  \n",
       "484        0.999976  \n",
       "485        0.789667  \n",
       "486        0.488045  \n",
       "487        0.999785  \n",
       "488        0.990974  \n",
       "489        0.998066  \n",
       "491        0.994918  \n",
       "492        0.999031  \n",
       "493        0.596210  \n",
       "495        0.988056  \n",
       "496        0.626083  \n",
       "497        0.983698  \n",
       "498        0.996578  \n",
       "499        0.999951  \n",
       "\n",
       "[448 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_0_8_representation_result_ID08[df_M_0_8_representation_result_ID08['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels, base=None):\n",
    "    \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "    from math import log, e\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    value,counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    ent = 0.\n",
    "\n",
    "    # Compute entropy\n",
    "    base = e if base is None else base\n",
    "    for i in probs:\n",
    "        ent -= i * log(i, base)\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 76.,  76.,   0.,   0.,   0., 336.,   4.,   0.,   6.,   2.]),\n",
       " array([0. , 0.8, 1.6, 2.4, 3.2, 4. , 4.8, 5.6, 6.4, 7.2, 8. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_M_representation_result_ODC['arr_KNN_max_class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9536024062379382"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(df_M_representation_result_ODC['arr_KNN_max_class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 21., 134.,   7.,   1.,  71.,   5.,   3., 255.,   2.,   1.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_M_representation_result_ODC['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.290070755414936"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(df_M_representation_result_ODC['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.647042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.914630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.602245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.727295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.942710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.589536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.799837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.966861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.822357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.930999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.602066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.601866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          9                           0.20                0   \n",
       "1                          1                           0.52                2   \n",
       "2                          0                           0.56                0   \n",
       "3                          9                           0.26                2   \n",
       "4                          9                           0.22                2   \n",
       "5                          9                           0.40                0   \n",
       "6                          9                           0.18                2   \n",
       "7                          9                           0.30                1   \n",
       "8                          9                           0.30                2   \n",
       "9                          9                           0.54                0   \n",
       "10                         7                           0.20                2   \n",
       "11                         9                           0.26                2   \n",
       "12                         9                           0.28                2   \n",
       "13                         5                           0.40                2   \n",
       "14                         9                           0.30                2   \n",
       "15                         2                           0.28                0   \n",
       "16                         5                           0.24                0   \n",
       "17                         9                           0.46                0   \n",
       "18                         1                           0.24                2   \n",
       "19                         2                           0.44                2   \n",
       "20                         9                           0.18                0   \n",
       "21                         1                           0.76                2   \n",
       "22                         2                           0.34                2   \n",
       "23                         2                           0.20                0   \n",
       "24                         1                           0.40                0   \n",
       "25                         5                           0.18                2   \n",
       "26                         9                           0.32                0   \n",
       "27                         7                           0.32                2   \n",
       "28                         2                           0.42                2   \n",
       "29                         0                           0.26                0   \n",
       "..                       ...                            ...              ...   \n",
       "470                        2                           0.30                2   \n",
       "471                        2                           0.36                2   \n",
       "472                        2                           0.44                2   \n",
       "473                        1                           0.34                2   \n",
       "474                        9                           0.34                2   \n",
       "475                        2                           0.26                0   \n",
       "476                        9                           0.24                2   \n",
       "477                        0                           0.20                0   \n",
       "478                        0                           0.22                0   \n",
       "479                        9                           0.24                2   \n",
       "480                        2                           0.34                2   \n",
       "481                        9                           0.34                0   \n",
       "482                        3                           0.24                2   \n",
       "483                        5                           0.26                0   \n",
       "484                        9                           0.24                2   \n",
       "485                        5                           0.34                0   \n",
       "486                        9                           0.34                2   \n",
       "487                        5                           0.34                0   \n",
       "488                        1                           0.50                2   \n",
       "489                        0                           0.20                2   \n",
       "490                        9                           0.28                2   \n",
       "491                        0                           0.20                0   \n",
       "492                        2                           0.34                2   \n",
       "493                        0                           0.26                0   \n",
       "494                        1                           0.78                1   \n",
       "495                        3                           0.24                0   \n",
       "496                        5                           0.54                2   \n",
       "497                        7                           0.30                0   \n",
       "498                        2                           0.40                2   \n",
       "499                        5                           0.36                2   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.987092  \n",
       "1          0.766087  \n",
       "2          0.999704  \n",
       "3          0.797273  \n",
       "4          0.998277  \n",
       "5          0.996893  \n",
       "6          0.999707  \n",
       "7          0.958599  \n",
       "8          0.647042  \n",
       "9          0.999730  \n",
       "10         0.914630  \n",
       "11         0.965705  \n",
       "12         0.897918  \n",
       "13         0.961686  \n",
       "14         0.998828  \n",
       "15         0.602245  \n",
       "16         0.990215  \n",
       "17         0.981295  \n",
       "18         0.995460  \n",
       "19         0.999510  \n",
       "20         0.999908  \n",
       "21         0.783019  \n",
       "22         0.727295  \n",
       "23         0.714947  \n",
       "24         0.999110  \n",
       "25         0.988291  \n",
       "26         0.914478  \n",
       "27         0.942710  \n",
       "28         0.978714  \n",
       "29         0.997996  \n",
       "..              ...  \n",
       "470        0.999060  \n",
       "471        0.991158  \n",
       "472        0.997525  \n",
       "473        0.589536  \n",
       "474        0.993401  \n",
       "475        0.991422  \n",
       "476        0.799837  \n",
       "477        0.536664  \n",
       "478        0.999170  \n",
       "479        0.997516  \n",
       "480        0.986726  \n",
       "481        0.999776  \n",
       "482        0.966861  \n",
       "483        0.999095  \n",
       "484        0.822357  \n",
       "485        0.968725  \n",
       "486        0.930999  \n",
       "487        0.905537  \n",
       "488        0.602066  \n",
       "489        0.601866  \n",
       "490        0.996350  \n",
       "491        0.993027  \n",
       "492        0.997020  \n",
       "493        0.993391  \n",
       "494        0.646448  \n",
       "495        0.607232  \n",
       "496        0.532518  \n",
       "497        0.965460  \n",
       "498        0.985849  \n",
       "499        0.997396  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_ODM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.812479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "21                         1                           0.76                2   \n",
       "88                         1                           0.92                1   \n",
       "118                        1                           0.92                2   \n",
       "326                        1                           0.80                2   \n",
       "352                        1                           0.88                5   \n",
       "359                        1                           0.82                1   \n",
       "494                        1                           0.78                1   \n",
       "\n",
       "     predicted_prob  \n",
       "21         0.783019  \n",
       "88         0.882425  \n",
       "118        0.552476  \n",
       "326        0.812479  \n",
       "352        0.988199  \n",
       "359        0.574194  \n",
       "494        0.646448  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_ODM.loc[df_C_representation_result_ODM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>6</td>\n",
       "      <td>0.76</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>6</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>0.649042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "95                         6                           0.84                6   \n",
       "96                         6                           0.88                6   \n",
       "231                        1                           0.78                1   \n",
       "296                        6                           0.88                6   \n",
       "299                        6                           0.90                6   \n",
       "311                        6                           0.90                6   \n",
       "329                        6                           0.90                6   \n",
       "330                        1                           0.78                1   \n",
       "334                        6                           0.76                6   \n",
       "369                        1                           0.72                1   \n",
       "380                        6                           0.92                6   \n",
       "382                        0                           0.72                0   \n",
       "456                        6                           0.74                3   \n",
       "481                        6                           0.88                6   \n",
       "490                        1                           0.82                1   \n",
       "\n",
       "     predicted_prob  \n",
       "95         0.995010  \n",
       "96         0.999260  \n",
       "231        0.999959  \n",
       "296        0.999957  \n",
       "299        0.999859  \n",
       "311        0.999821  \n",
       "329        0.999586  \n",
       "330        0.999903  \n",
       "334        0.999979  \n",
       "369        0.999850  \n",
       "380        0.999156  \n",
       "382        0.999850  \n",
       "456        0.649042  \n",
       "481        0.999925  \n",
       "490        0.999938  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_IDC.loc[df_C_representation_result_IDC['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.485816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.827864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.961915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.983568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.841327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.550421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.335351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.996275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.287250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.772040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.478722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.253254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.864852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.437678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.972917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.257798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.992411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.655631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.976598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.512767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.668273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.337780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.551052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.305047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.787894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.867049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.262501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.624858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.531626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "2                          4                           0.38                7   \n",
       "12                         4                           0.34                7   \n",
       "13                         0                           0.32                2   \n",
       "29                         8                           0.18                1   \n",
       "32                         7                           0.32                7   \n",
       "43                         0                           0.30                1   \n",
       "46                         1                           0.36                7   \n",
       "50                         4                           0.36                0   \n",
       "68                         7                           0.26                7   \n",
       "84                         4                           0.28                7   \n",
       "103                        0                           0.36                4   \n",
       "106                        4                           0.34                0   \n",
       "114                        4                           0.38                4   \n",
       "124                        4                           0.36                1   \n",
       "134                        4                           0.34                5   \n",
       "138                        1                           0.34                1   \n",
       "140                        0                           0.34                1   \n",
       "162                        7                           0.30                7   \n",
       "166                        4                           0.38                4   \n",
       "202                        1                           0.20                7   \n",
       "207                        4                           0.28                7   \n",
       "212                        0                           0.38                1   \n",
       "214                        4                           0.30                1   \n",
       "215                        4                           0.38                4   \n",
       "219                        0                           0.30                7   \n",
       "234                        0                           0.34                9   \n",
       "291                        0                           0.32                1   \n",
       "319                        0                           0.24                1   \n",
       "321                        4                           0.28                1   \n",
       "325                        4                           0.38                7   \n",
       "339                        7                           0.32                4   \n",
       "340                        4                           0.30                1   \n",
       "346                        1                           0.36                7   \n",
       "355                        1                           0.36                1   \n",
       "357                        4                           0.32                7   \n",
       "360                        4                           0.36                7   \n",
       "370                        4                           0.36                0   \n",
       "374                        0                           0.36                4   \n",
       "382                        0                           0.38                7   \n",
       "385                        0                           0.34                4   \n",
       "401                        8                           0.24                7   \n",
       "404                        7                           0.38                7   \n",
       "406                        1                           0.34                1   \n",
       "408                        0                           0.36                1   \n",
       "422                        0                           0.28                7   \n",
       "424                        0                           0.34                1   \n",
       "432                        4                           0.36                7   \n",
       "433                        4                           0.38                7   \n",
       "441                        4                           0.38                7   \n",
       "442                        4                           0.38                7   \n",
       "459                        4                           0.32                7   \n",
       "466                        1                           0.34                4   \n",
       "468                        4                           0.36                7   \n",
       "495                        4                           0.36                1   \n",
       "\n",
       "     predicted_prob  \n",
       "2          0.993760  \n",
       "12         0.666899  \n",
       "13         0.485816  \n",
       "29         0.620811  \n",
       "32         0.827864  \n",
       "43         0.708303  \n",
       "46         0.961915  \n",
       "50         0.615069  \n",
       "68         0.983568  \n",
       "84         0.841327  \n",
       "103        0.550421  \n",
       "106        0.332704  \n",
       "114        0.335351  \n",
       "124        0.805058  \n",
       "134        0.250353  \n",
       "138        0.722631  \n",
       "140        0.583224  \n",
       "162        0.996275  \n",
       "166        0.287250  \n",
       "202        0.772040  \n",
       "207        0.478722  \n",
       "212        0.770043  \n",
       "214        0.494462  \n",
       "215        0.253254  \n",
       "219        0.864852  \n",
       "234        0.437678  \n",
       "291        0.554824  \n",
       "319        0.955840  \n",
       "321        0.571665  \n",
       "325        0.972917  \n",
       "339        0.257798  \n",
       "340        0.540679  \n",
       "346        0.993617  \n",
       "355        0.433091  \n",
       "357        0.992411  \n",
       "360        0.655631  \n",
       "370        0.858190  \n",
       "374        0.976598  \n",
       "382        0.512767  \n",
       "385        0.668273  \n",
       "401        0.337780  \n",
       "404        0.551052  \n",
       "406        0.361451  \n",
       "408        0.952400  \n",
       "422        0.305047  \n",
       "424        0.787894  \n",
       "432        0.989017  \n",
       "433        0.978543  \n",
       "441        0.867049  \n",
       "442        0.262501  \n",
       "459        0.624858  \n",
       "466        0.966902  \n",
       "468        0.531626  \n",
       "495        0.572713  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_ODC[df_M_representation_result_ODC['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.530925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.669924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.983897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "62                         9                           0.34                9   \n",
       "78                         0                           0.34                9   \n",
       "95                         8                           0.34                4   \n",
       "97                         7                           0.38                7   \n",
       "243                        7                           0.32                7   \n",
       "460                        2                           0.34                5   \n",
       "495                        8                           0.38                8   \n",
       "\n",
       "     predicted_prob  \n",
       "62         0.530925  \n",
       "78         0.669924  \n",
       "95         0.999936  \n",
       "97         0.999799  \n",
       "243        0.999830  \n",
       "460        0.983897  \n",
       "495        0.997395  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_IDM[df_M_representation_result_IDM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 37.,  65.,  72.,  27.,   0., 113.,   0.,  33.,   0., 153.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_C_representation_result_ODM['arr_KNN_max_class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7724415658656787"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(df_C_representation_result_ODM['arr_KNN_max_class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([152.,  41., 265.,  22.,   0.,   0.,  11.,   1.,   1.,   7.]),\n",
       " array([0. , 0.8, 1.6, 2.4, 3.2, 4. , 4.8, 5.6, 6.4, 7.2, 8. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_C_representation_result_ODM['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2095763968063684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(df_C_representation_result_ODM['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  0\n",
      "current sample:  1\n",
      "current sample:  2\n",
      "current sample:  3\n",
      "current sample:  4\n",
      "current sample:  5\n",
      "current sample:  6\n",
      "current sample:  7\n",
      "current sample:  8\n",
      "current sample:  9\n",
      "current sample:  10\n",
      "current sample:  11\n",
      "current sample:  12\n",
      "current sample:  13\n",
      "current sample:  14\n",
      "current sample:  15\n",
      "current sample:  16\n",
      "current sample:  17\n",
      "current sample:  18\n",
      "current sample:  19\n",
      "current sample:  20\n",
      "current sample:  21\n",
      "current sample:  22\n",
      "current sample:  23\n",
      "current sample:  24\n",
      "current sample:  25\n",
      "current sample:  26\n",
      "current sample:  27\n",
      "current sample:  28\n",
      "current sample:  29\n",
      "current sample:  30\n",
      "current sample:  31\n",
      "current sample:  32\n",
      "current sample:  33\n",
      "current sample:  34\n",
      "current sample:  35\n",
      "current sample:  36\n",
      "current sample:  37\n",
      "current sample:  38\n",
      "current sample:  39\n",
      "current sample:  40\n",
      "current sample:  41\n",
      "current sample:  42\n",
      "current sample:  43\n",
      "current sample:  44\n",
      "current sample:  45\n",
      "current sample:  46\n",
      "current sample:  47\n",
      "current sample:  48\n",
      "current sample:  49\n",
      "current sample:  50\n",
      "current sample:  51\n",
      "current sample:  52\n",
      "current sample:  53\n",
      "current sample:  54\n",
      "current sample:  55\n",
      "current sample:  56\n",
      "current sample:  57\n",
      "current sample:  58\n",
      "current sample:  59\n",
      "current sample:  60\n",
      "current sample:  61\n",
      "current sample:  62\n",
      "current sample:  63\n",
      "current sample:  64\n",
      "current sample:  65\n",
      "current sample:  66\n",
      "current sample:  67\n",
      "current sample:  68\n",
      "current sample:  69\n",
      "current sample:  70\n",
      "current sample:  71\n",
      "current sample:  72\n",
      "current sample:  73\n",
      "current sample:  74\n",
      "current sample:  75\n",
      "current sample:  76\n",
      "current sample:  77\n",
      "current sample:  78\n",
      "current sample:  79\n",
      "current sample:  80\n",
      "current sample:  81\n",
      "current sample:  82\n",
      "current sample:  83\n",
      "current sample:  84\n",
      "current sample:  85\n",
      "current sample:  86\n",
      "current sample:  87\n",
      "current sample:  88\n",
      "current sample:  89\n",
      "current sample:  90\n",
      "current sample:  91\n",
      "current sample:  92\n",
      "current sample:  93\n",
      "current sample:  94\n",
      "current sample:  95\n",
      "current sample:  96\n",
      "current sample:  97\n",
      "current sample:  98\n",
      "current sample:  99\n",
      "current sample:  100\n",
      "current sample:  101\n",
      "current sample:  102\n",
      "current sample:  103\n",
      "current sample:  104\n",
      "current sample:  105\n",
      "current sample:  106\n",
      "current sample:  107\n",
      "current sample:  108\n",
      "current sample:  109\n",
      "current sample:  110\n",
      "current sample:  111\n",
      "current sample:  112\n",
      "current sample:  113\n",
      "current sample:  114\n",
      "current sample:  115\n",
      "current sample:  116\n",
      "current sample:  117\n",
      "current sample:  118\n",
      "current sample:  119\n",
      "current sample:  120\n",
      "current sample:  121\n",
      "current sample:  122\n",
      "current sample:  123\n",
      "current sample:  124\n",
      "current sample:  125\n",
      "current sample:  126\n",
      "current sample:  127\n",
      "current sample:  128\n",
      "current sample:  129\n",
      "current sample:  130\n",
      "current sample:  131\n",
      "current sample:  132\n",
      "current sample:  133\n",
      "current sample:  134\n",
      "current sample:  135\n",
      "current sample:  136\n",
      "current sample:  137\n",
      "current sample:  138\n",
      "current sample:  139\n",
      "current sample:  140\n",
      "current sample:  141\n",
      "current sample:  142\n",
      "current sample:  143\n",
      "current sample:  144\n",
      "current sample:  145\n",
      "current sample:  146\n",
      "current sample:  147\n",
      "current sample:  148\n",
      "current sample:  149\n",
      "current sample:  150\n",
      "current sample:  151\n",
      "current sample:  152\n",
      "current sample:  153\n",
      "current sample:  154\n",
      "current sample:  155\n",
      "current sample:  156\n",
      "current sample:  157\n",
      "current sample:  158\n",
      "current sample:  159\n",
      "current sample:  160\n",
      "current sample:  161\n",
      "current sample:  162\n",
      "current sample:  163\n",
      "current sample:  164\n",
      "current sample:  165\n",
      "current sample:  166\n",
      "current sample:  167\n",
      "current sample:  168\n",
      "current sample:  169\n",
      "current sample:  170\n",
      "current sample:  171\n",
      "current sample:  172\n",
      "current sample:  173\n",
      "current sample:  174\n",
      "current sample:  175\n",
      "current sample:  176\n",
      "current sample:  177\n",
      "current sample:  178\n",
      "current sample:  179\n",
      "current sample:  180\n",
      "current sample:  181\n",
      "current sample:  182\n",
      "current sample:  183\n",
      "current sample:  184\n",
      "current sample:  185\n",
      "current sample:  186\n",
      "current sample:  187\n",
      "current sample:  188\n",
      "current sample:  189\n",
      "current sample:  190\n",
      "current sample:  191\n",
      "current sample:  192\n",
      "current sample:  193\n",
      "current sample:  194\n",
      "current sample:  195\n",
      "current sample:  196\n",
      "current sample:  197\n",
      "current sample:  198\n",
      "current sample:  199\n",
      "current sample:  200\n",
      "current sample:  201\n",
      "current sample:  202\n",
      "current sample:  203\n",
      "current sample:  204\n",
      "current sample:  205\n",
      "current sample:  206\n",
      "current sample:  207\n",
      "current sample:  208\n",
      "current sample:  209\n",
      "current sample:  210\n",
      "current sample:  211\n",
      "current sample:  212\n",
      "current sample:  213\n",
      "current sample:  214\n",
      "current sample:  215\n",
      "current sample:  216\n",
      "current sample:  217\n",
      "current sample:  218\n",
      "current sample:  219\n",
      "current sample:  220\n",
      "current sample:  221\n",
      "current sample:  222\n",
      "current sample:  223\n",
      "current sample:  224\n",
      "current sample:  225\n",
      "current sample:  226\n",
      "current sample:  227\n",
      "current sample:  228\n",
      "current sample:  229\n",
      "current sample:  230\n",
      "current sample:  231\n",
      "current sample:  232\n",
      "current sample:  233\n",
      "current sample:  234\n",
      "current sample:  235\n",
      "current sample:  236\n",
      "current sample:  237\n",
      "current sample:  238\n",
      "current sample:  239\n",
      "current sample:  240\n",
      "current sample:  241\n",
      "current sample:  242\n",
      "current sample:  243\n",
      "current sample:  244\n",
      "current sample:  245\n",
      "current sample:  246\n",
      "current sample:  247\n",
      "current sample:  248\n",
      "current sample:  249\n",
      "current sample:  250\n",
      "current sample:  251\n",
      "current sample:  252\n",
      "current sample:  253\n",
      "current sample:  254\n",
      "current sample:  255\n",
      "current sample:  256\n",
      "current sample:  257\n",
      "current sample:  258\n",
      "current sample:  259\n",
      "current sample:  260\n",
      "current sample:  261\n",
      "current sample:  262\n",
      "current sample:  263\n",
      "current sample:  264\n",
      "current sample:  265\n",
      "current sample:  266\n",
      "current sample:  267\n",
      "current sample:  268\n",
      "current sample:  269\n",
      "current sample:  270\n",
      "current sample:  271\n",
      "current sample:  272\n",
      "current sample:  273\n",
      "current sample:  274\n",
      "current sample:  275\n",
      "current sample:  276\n",
      "current sample:  277\n",
      "current sample:  278\n",
      "current sample:  279\n",
      "current sample:  280\n",
      "current sample:  281\n",
      "current sample:  282\n",
      "current sample:  283\n",
      "current sample:  284\n",
      "current sample:  285\n",
      "current sample:  286\n",
      "current sample:  287\n",
      "current sample:  288\n",
      "current sample:  289\n",
      "current sample:  290\n",
      "current sample:  291\n",
      "current sample:  292\n",
      "current sample:  293\n",
      "current sample:  294\n",
      "current sample:  295\n",
      "current sample:  296\n",
      "current sample:  297\n",
      "current sample:  298\n",
      "current sample:  299\n",
      "current sample:  300\n",
      "current sample:  301\n",
      "current sample:  302\n",
      "current sample:  303\n",
      "current sample:  304\n",
      "current sample:  305\n",
      "current sample:  306\n",
      "current sample:  307\n",
      "current sample:  308\n",
      "current sample:  309\n",
      "current sample:  310\n",
      "current sample:  311\n",
      "current sample:  312\n",
      "current sample:  313\n",
      "current sample:  314\n",
      "current sample:  315\n",
      "current sample:  316\n",
      "current sample:  317\n",
      "current sample:  318\n",
      "current sample:  319\n",
      "current sample:  320\n",
      "current sample:  321\n",
      "current sample:  322\n",
      "current sample:  323\n",
      "current sample:  324\n",
      "current sample:  325\n",
      "current sample:  326\n",
      "current sample:  327\n",
      "current sample:  328\n",
      "current sample:  329\n",
      "current sample:  330\n",
      "current sample:  331\n",
      "current sample:  332\n",
      "current sample:  333\n",
      "current sample:  334\n",
      "current sample:  335\n",
      "current sample:  336\n",
      "current sample:  337\n",
      "current sample:  338\n",
      "current sample:  339\n",
      "current sample:  340\n",
      "current sample:  341\n",
      "current sample:  342\n",
      "current sample:  343\n",
      "current sample:  344\n",
      "current sample:  345\n",
      "current sample:  346\n",
      "current sample:  347\n",
      "current sample:  348\n",
      "current sample:  349\n",
      "current sample:  350\n",
      "current sample:  351\n",
      "current sample:  352\n",
      "current sample:  353\n",
      "current sample:  354\n",
      "current sample:  355\n",
      "current sample:  356\n",
      "current sample:  357\n",
      "current sample:  358\n",
      "current sample:  359\n",
      "current sample:  360\n",
      "current sample:  361\n",
      "current sample:  362\n",
      "current sample:  363\n",
      "current sample:  364\n",
      "current sample:  365\n",
      "current sample:  366\n",
      "current sample:  367\n",
      "current sample:  368\n",
      "current sample:  369\n",
      "current sample:  370\n",
      "current sample:  371\n",
      "current sample:  372\n",
      "current sample:  373\n",
      "current sample:  374\n",
      "current sample:  375\n",
      "current sample:  376\n",
      "current sample:  377\n",
      "current sample:  378\n",
      "current sample:  379\n",
      "current sample:  380\n",
      "current sample:  381\n",
      "current sample:  382\n",
      "current sample:  383\n",
      "current sample:  384\n",
      "current sample:  385\n",
      "current sample:  386\n",
      "current sample:  387\n",
      "current sample:  388\n",
      "current sample:  389\n",
      "current sample:  390\n",
      "current sample:  391\n",
      "current sample:  392\n",
      "current sample:  393\n",
      "current sample:  394\n",
      "current sample:  395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  396\n",
      "current sample:  397\n",
      "current sample:  398\n",
      "current sample:  399\n",
      "current sample:  400\n",
      "current sample:  401\n",
      "current sample:  402\n",
      "current sample:  403\n",
      "current sample:  404\n",
      "current sample:  405\n",
      "current sample:  406\n",
      "current sample:  407\n",
      "current sample:  408\n",
      "current sample:  409\n",
      "current sample:  410\n",
      "current sample:  411\n",
      "current sample:  412\n",
      "current sample:  413\n",
      "current sample:  414\n",
      "current sample:  415\n",
      "current sample:  416\n",
      "current sample:  417\n",
      "current sample:  418\n",
      "current sample:  419\n",
      "current sample:  420\n",
      "current sample:  421\n",
      "current sample:  422\n",
      "current sample:  423\n",
      "current sample:  424\n",
      "current sample:  425\n",
      "current sample:  426\n",
      "current sample:  427\n",
      "current sample:  428\n",
      "current sample:  429\n",
      "current sample:  430\n",
      "current sample:  431\n",
      "current sample:  432\n",
      "current sample:  433\n",
      "current sample:  434\n",
      "current sample:  435\n",
      "current sample:  436\n",
      "current sample:  437\n",
      "current sample:  438\n",
      "current sample:  439\n",
      "current sample:  440\n",
      "current sample:  441\n",
      "current sample:  442\n",
      "current sample:  443\n",
      "current sample:  444\n",
      "current sample:  445\n",
      "current sample:  446\n",
      "current sample:  447\n",
      "current sample:  448\n",
      "current sample:  449\n",
      "current sample:  450\n",
      "current sample:  451\n",
      "current sample:  452\n",
      "current sample:  453\n",
      "current sample:  454\n",
      "current sample:  455\n",
      "current sample:  456\n",
      "current sample:  457\n",
      "current sample:  458\n",
      "current sample:  459\n",
      "current sample:  460\n",
      "current sample:  461\n",
      "current sample:  462\n",
      "current sample:  463\n",
      "current sample:  464\n",
      "current sample:  465\n",
      "current sample:  466\n",
      "current sample:  467\n",
      "current sample:  468\n",
      "current sample:  469\n",
      "current sample:  470\n",
      "current sample:  471\n",
      "current sample:  472\n",
      "current sample:  473\n",
      "current sample:  474\n",
      "current sample:  475\n",
      "current sample:  476\n",
      "current sample:  477\n",
      "current sample:  478\n",
      "current sample:  479\n",
      "current sample:  480\n",
      "current sample:  481\n",
      "current sample:  482\n",
      "current sample:  483\n",
      "current sample:  484\n",
      "current sample:  485\n",
      "current sample:  486\n",
      "current sample:  487\n",
      "current sample:  488\n",
      "current sample:  489\n",
      "current sample:  490\n",
      "current sample:  491\n",
      "current sample:  492\n",
      "current sample:  493\n",
      "current sample:  494\n",
      "current sample:  495\n",
      "current sample:  496\n",
      "current sample:  497\n",
      "current sample:  498\n",
      "current sample:  499\n"
     ]
    }
   ],
   "source": [
    "M_representation_result_IDM = compare_representations(M_representation[\"MNIST_test\"],M_representation[\"MNIST_train\"],mnist_train_y,M_VGG_Model3)\n",
    "df_M_representation_result_IDM = concact_results(mnist_test_RGB_x,M_representation_result_IDM[1],M_representation_result_IDM[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5</td>\n",
       "      <td>0.968685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9</td>\n",
       "      <td>0.301881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9</td>\n",
       "      <td>0.990595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>0.54</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.923092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.997961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          7                           1.00                7   \n",
       "1                          2                           1.00                2   \n",
       "2                          1                           1.00                1   \n",
       "3                          0                           1.00                0   \n",
       "4                          4                           1.00                4   \n",
       "5                          1                           1.00                1   \n",
       "6                          4                           0.98                4   \n",
       "7                          9                           0.98                9   \n",
       "8                          2                           0.70                5   \n",
       "9                          9                           1.00                9   \n",
       "10                         0                           1.00                0   \n",
       "11                         6                           1.00                6   \n",
       "12                         9                           1.00                9   \n",
       "13                         0                           1.00                0   \n",
       "14                         1                           1.00                1   \n",
       "15                         5                           1.00                5   \n",
       "16                         9                           1.00                9   \n",
       "17                         7                           1.00                7   \n",
       "18                         8                           0.50                9   \n",
       "19                         4                           1.00                4   \n",
       "20                         9                           0.82                9   \n",
       "21                         6                           0.98                6   \n",
       "22                         6                           1.00                6   \n",
       "23                         5                           1.00                5   \n",
       "24                         4                           1.00                4   \n",
       "25                         0                           1.00                0   \n",
       "26                         7                           0.54                7   \n",
       "27                         4                           1.00                4   \n",
       "28                         0                           1.00                0   \n",
       "29                         1                           1.00                1   \n",
       "..                       ...                            ...              ...   \n",
       "470                        8                           1.00                8   \n",
       "471                        9                           1.00                9   \n",
       "472                        6                           1.00                6   \n",
       "473                        1                           1.00                1   \n",
       "474                        8                           0.82                8   \n",
       "475                        4                           1.00                4   \n",
       "476                        1                           1.00                1   \n",
       "477                        2                           1.00                2   \n",
       "478                        5                           1.00                5   \n",
       "479                        9                           0.98                9   \n",
       "480                        1                           1.00                1   \n",
       "481                        9                           1.00                9   \n",
       "482                        7                           1.00                7   \n",
       "483                        5                           1.00                5   \n",
       "484                        4                           1.00                4   \n",
       "485                        0                           1.00                0   \n",
       "486                        8                           1.00                8   \n",
       "487                        9                           0.98                9   \n",
       "488                        9                           1.00                9   \n",
       "489                        1                           1.00                1   \n",
       "490                        0                           0.78                0   \n",
       "491                        5                           1.00                5   \n",
       "492                        2                           0.98                2   \n",
       "493                        3                           1.00                3   \n",
       "494                        7                           1.00                7   \n",
       "495                        8                           0.38                8   \n",
       "496                        9                           1.00                9   \n",
       "497                        1                           0.74                4   \n",
       "498                        2                           0.60                0   \n",
       "499                        6                           1.00                6   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.999994  \n",
       "1          0.999490  \n",
       "2          0.999907  \n",
       "3          0.999972  \n",
       "4          0.999983  \n",
       "5          0.999893  \n",
       "6          0.999968  \n",
       "7          0.996378  \n",
       "8          0.968685  \n",
       "9          0.999572  \n",
       "10         0.999984  \n",
       "11         0.999890  \n",
       "12         0.999383  \n",
       "13         0.999986  \n",
       "14         0.999917  \n",
       "15         0.999001  \n",
       "16         0.999653  \n",
       "17         0.999978  \n",
       "18         0.301881  \n",
       "19         0.999999  \n",
       "20         0.990595  \n",
       "21         0.999241  \n",
       "22         0.999920  \n",
       "23         0.999638  \n",
       "24         0.999989  \n",
       "25         0.999979  \n",
       "26         0.999955  \n",
       "27         0.999998  \n",
       "28         0.999944  \n",
       "29         0.999875  \n",
       "..              ...  \n",
       "470        0.999586  \n",
       "471        0.923092  \n",
       "472        0.999899  \n",
       "473        0.999921  \n",
       "474        0.997717  \n",
       "475        0.999996  \n",
       "476        0.999918  \n",
       "477        0.999709  \n",
       "478        0.999589  \n",
       "479        0.996429  \n",
       "480        0.999856  \n",
       "481        0.999862  \n",
       "482        0.999935  \n",
       "483        0.994905  \n",
       "484        0.999999  \n",
       "485        0.999972  \n",
       "486        0.999603  \n",
       "487        0.997961  \n",
       "488        0.998771  \n",
       "489        0.999922  \n",
       "490        0.999799  \n",
       "491        0.999407  \n",
       "492        0.987551  \n",
       "493        0.999986  \n",
       "494        0.999989  \n",
       "495        0.997395  \n",
       "496        0.999788  \n",
       "497        0.992982  \n",
       "498        0.999406  \n",
       "499        0.999663  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_IDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  0\n",
      "current sample:  1\n",
      "current sample:  2\n",
      "current sample:  3\n",
      "current sample:  4\n",
      "current sample:  5\n",
      "current sample:  6\n",
      "current sample:  7\n",
      "current sample:  8\n",
      "current sample:  9\n",
      "current sample:  10\n",
      "current sample:  11\n",
      "current sample:  12\n",
      "current sample:  13\n",
      "current sample:  14\n",
      "current sample:  15\n",
      "current sample:  16\n",
      "current sample:  17\n",
      "current sample:  18\n",
      "current sample:  19\n",
      "current sample:  20\n",
      "current sample:  21\n",
      "current sample:  22\n",
      "current sample:  23\n",
      "current sample:  24\n",
      "current sample:  25\n",
      "current sample:  26\n",
      "current sample:  27\n",
      "current sample:  28\n",
      "current sample:  29\n",
      "current sample:  30\n",
      "current sample:  31\n",
      "current sample:  32\n",
      "current sample:  33\n",
      "current sample:  34\n",
      "current sample:  35\n",
      "current sample:  36\n",
      "current sample:  37\n",
      "current sample:  38\n",
      "current sample:  39\n",
      "current sample:  40\n",
      "current sample:  41\n",
      "current sample:  42\n",
      "current sample:  43\n",
      "current sample:  44\n",
      "current sample:  45\n",
      "current sample:  46\n",
      "current sample:  47\n",
      "current sample:  48\n",
      "current sample:  49\n",
      "current sample:  50\n",
      "current sample:  51\n",
      "current sample:  52\n",
      "current sample:  53\n",
      "current sample:  54\n",
      "current sample:  55\n",
      "current sample:  56\n",
      "current sample:  57\n",
      "current sample:  58\n",
      "current sample:  59\n",
      "current sample:  60\n",
      "current sample:  61\n",
      "current sample:  62\n",
      "current sample:  63\n",
      "current sample:  64\n",
      "current sample:  65\n",
      "current sample:  66\n",
      "current sample:  67\n",
      "current sample:  68\n",
      "current sample:  69\n",
      "current sample:  70\n",
      "current sample:  71\n",
      "current sample:  72\n",
      "current sample:  73\n",
      "current sample:  74\n",
      "current sample:  75\n",
      "current sample:  76\n",
      "current sample:  77\n",
      "current sample:  78\n",
      "current sample:  79\n",
      "current sample:  80\n",
      "current sample:  81\n",
      "current sample:  82\n",
      "current sample:  83\n",
      "current sample:  84\n",
      "current sample:  85\n",
      "current sample:  86\n",
      "current sample:  87\n",
      "current sample:  88\n",
      "current sample:  89\n",
      "current sample:  90\n",
      "current sample:  91\n",
      "current sample:  92\n",
      "current sample:  93\n",
      "current sample:  94\n",
      "current sample:  95\n",
      "current sample:  96\n",
      "current sample:  97\n",
      "current sample:  98\n",
      "current sample:  99\n",
      "current sample:  100\n",
      "current sample:  101\n",
      "current sample:  102\n",
      "current sample:  103\n",
      "current sample:  104\n",
      "current sample:  105\n",
      "current sample:  106\n",
      "current sample:  107\n",
      "current sample:  108\n",
      "current sample:  109\n",
      "current sample:  110\n",
      "current sample:  111\n",
      "current sample:  112\n",
      "current sample:  113\n",
      "current sample:  114\n",
      "current sample:  115\n",
      "current sample:  116\n",
      "current sample:  117\n",
      "current sample:  118\n",
      "current sample:  119\n",
      "current sample:  120\n",
      "current sample:  121\n",
      "current sample:  122\n",
      "current sample:  123\n",
      "current sample:  124\n",
      "current sample:  125\n",
      "current sample:  126\n",
      "current sample:  127\n",
      "current sample:  128\n",
      "current sample:  129\n",
      "current sample:  130\n",
      "current sample:  131\n",
      "current sample:  132\n",
      "current sample:  133\n",
      "current sample:  134\n",
      "current sample:  135\n",
      "current sample:  136\n",
      "current sample:  137\n",
      "current sample:  138\n",
      "current sample:  139\n",
      "current sample:  140\n",
      "current sample:  141\n",
      "current sample:  142\n",
      "current sample:  143\n",
      "current sample:  144\n",
      "current sample:  145\n",
      "current sample:  146\n",
      "current sample:  147\n",
      "current sample:  148\n",
      "current sample:  149\n",
      "current sample:  150\n",
      "current sample:  151\n",
      "current sample:  152\n",
      "current sample:  153\n",
      "current sample:  154\n",
      "current sample:  155\n",
      "current sample:  156\n",
      "current sample:  157\n",
      "current sample:  158\n",
      "current sample:  159\n",
      "current sample:  160\n",
      "current sample:  161\n",
      "current sample:  162\n",
      "current sample:  163\n",
      "current sample:  164\n",
      "current sample:  165\n",
      "current sample:  166\n",
      "current sample:  167\n",
      "current sample:  168\n",
      "current sample:  169\n",
      "current sample:  170\n",
      "current sample:  171\n",
      "current sample:  172\n",
      "current sample:  173\n",
      "current sample:  174\n",
      "current sample:  175\n",
      "current sample:  176\n",
      "current sample:  177\n",
      "current sample:  178\n",
      "current sample:  179\n",
      "current sample:  180\n",
      "current sample:  181\n",
      "current sample:  182\n",
      "current sample:  183\n",
      "current sample:  184\n",
      "current sample:  185\n",
      "current sample:  186\n",
      "current sample:  187\n",
      "current sample:  188\n",
      "current sample:  189\n",
      "current sample:  190\n",
      "current sample:  191\n",
      "current sample:  192\n",
      "current sample:  193\n",
      "current sample:  194\n",
      "current sample:  195\n",
      "current sample:  196\n",
      "current sample:  197\n",
      "current sample:  198\n",
      "current sample:  199\n",
      "current sample:  200\n",
      "current sample:  201\n",
      "current sample:  202\n",
      "current sample:  203\n",
      "current sample:  204\n",
      "current sample:  205\n",
      "current sample:  206\n",
      "current sample:  207\n",
      "current sample:  208\n",
      "current sample:  209\n",
      "current sample:  210\n",
      "current sample:  211\n",
      "current sample:  212\n",
      "current sample:  213\n",
      "current sample:  214\n",
      "current sample:  215\n",
      "current sample:  216\n",
      "current sample:  217\n",
      "current sample:  218\n",
      "current sample:  219\n",
      "current sample:  220\n",
      "current sample:  221\n",
      "current sample:  222\n",
      "current sample:  223\n",
      "current sample:  224\n",
      "current sample:  225\n",
      "current sample:  226\n",
      "current sample:  227\n",
      "current sample:  228\n",
      "current sample:  229\n",
      "current sample:  230\n",
      "current sample:  231\n",
      "current sample:  232\n",
      "current sample:  233\n",
      "current sample:  234\n",
      "current sample:  235\n",
      "current sample:  236\n",
      "current sample:  237\n",
      "current sample:  238\n",
      "current sample:  239\n",
      "current sample:  240\n",
      "current sample:  241\n",
      "current sample:  242\n",
      "current sample:  243\n",
      "current sample:  244\n",
      "current sample:  245\n",
      "current sample:  246\n",
      "current sample:  247\n",
      "current sample:  248\n",
      "current sample:  249\n",
      "current sample:  250\n",
      "current sample:  251\n",
      "current sample:  252\n",
      "current sample:  253\n",
      "current sample:  254\n",
      "current sample:  255\n",
      "current sample:  256\n",
      "current sample:  257\n",
      "current sample:  258\n",
      "current sample:  259\n",
      "current sample:  260\n",
      "current sample:  261\n",
      "current sample:  262\n",
      "current sample:  263\n",
      "current sample:  264\n",
      "current sample:  265\n",
      "current sample:  266\n",
      "current sample:  267\n",
      "current sample:  268\n",
      "current sample:  269\n",
      "current sample:  270\n",
      "current sample:  271\n",
      "current sample:  272\n",
      "current sample:  273\n",
      "current sample:  274\n",
      "current sample:  275\n",
      "current sample:  276\n",
      "current sample:  277\n",
      "current sample:  278\n",
      "current sample:  279\n",
      "current sample:  280\n",
      "current sample:  281\n",
      "current sample:  282\n",
      "current sample:  283\n",
      "current sample:  284\n",
      "current sample:  285\n",
      "current sample:  286\n",
      "current sample:  287\n",
      "current sample:  288\n",
      "current sample:  289\n",
      "current sample:  290\n",
      "current sample:  291\n",
      "current sample:  292\n",
      "current sample:  293\n",
      "current sample:  294\n",
      "current sample:  295\n",
      "current sample:  296\n",
      "current sample:  297\n",
      "current sample:  298\n",
      "current sample:  299\n",
      "current sample:  300\n",
      "current sample:  301\n",
      "current sample:  302\n",
      "current sample:  303\n",
      "current sample:  304\n",
      "current sample:  305\n",
      "current sample:  306\n",
      "current sample:  307\n",
      "current sample:  308\n",
      "current sample:  309\n",
      "current sample:  310\n",
      "current sample:  311\n",
      "current sample:  312\n",
      "current sample:  313\n",
      "current sample:  314\n",
      "current sample:  315\n",
      "current sample:  316\n",
      "current sample:  317\n",
      "current sample:  318\n",
      "current sample:  319\n",
      "current sample:  320\n",
      "current sample:  321\n",
      "current sample:  322\n",
      "current sample:  323\n",
      "current sample:  324\n",
      "current sample:  325\n",
      "current sample:  326\n",
      "current sample:  327\n",
      "current sample:  328\n",
      "current sample:  329\n",
      "current sample:  330\n",
      "current sample:  331\n",
      "current sample:  332\n",
      "current sample:  333\n",
      "current sample:  334\n",
      "current sample:  335\n",
      "current sample:  336\n",
      "current sample:  337\n",
      "current sample:  338\n",
      "current sample:  339\n",
      "current sample:  340\n",
      "current sample:  341\n",
      "current sample:  342\n",
      "current sample:  343\n",
      "current sample:  344\n",
      "current sample:  345\n",
      "current sample:  346\n",
      "current sample:  347\n",
      "current sample:  348\n",
      "current sample:  349\n",
      "current sample:  350\n",
      "current sample:  351\n",
      "current sample:  352\n",
      "current sample:  353\n",
      "current sample:  354\n",
      "current sample:  355\n",
      "current sample:  356\n",
      "current sample:  357\n",
      "current sample:  358\n",
      "current sample:  359\n",
      "current sample:  360\n",
      "current sample:  361\n",
      "current sample:  362\n",
      "current sample:  363\n",
      "current sample:  364\n",
      "current sample:  365\n",
      "current sample:  366\n",
      "current sample:  367\n",
      "current sample:  368\n",
      "current sample:  369\n",
      "current sample:  370\n",
      "current sample:  371\n",
      "current sample:  372\n",
      "current sample:  373\n",
      "current sample:  374\n",
      "current sample:  375\n",
      "current sample:  376\n",
      "current sample:  377\n",
      "current sample:  378\n",
      "current sample:  379\n",
      "current sample:  380\n",
      "current sample:  381\n",
      "current sample:  382\n",
      "current sample:  383\n",
      "current sample:  384\n",
      "current sample:  385\n",
      "current sample:  386\n",
      "current sample:  387\n",
      "current sample:  388\n",
      "current sample:  389\n",
      "current sample:  390\n",
      "current sample:  391\n",
      "current sample:  392\n",
      "current sample:  393\n",
      "current sample:  394\n",
      "current sample:  395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  396\n",
      "current sample:  397\n",
      "current sample:  398\n",
      "current sample:  399\n",
      "current sample:  400\n",
      "current sample:  401\n",
      "current sample:  402\n",
      "current sample:  403\n",
      "current sample:  404\n",
      "current sample:  405\n",
      "current sample:  406\n",
      "current sample:  407\n",
      "current sample:  408\n",
      "current sample:  409\n",
      "current sample:  410\n",
      "current sample:  411\n",
      "current sample:  412\n",
      "current sample:  413\n",
      "current sample:  414\n",
      "current sample:  415\n",
      "current sample:  416\n",
      "current sample:  417\n",
      "current sample:  418\n",
      "current sample:  419\n",
      "current sample:  420\n",
      "current sample:  421\n",
      "current sample:  422\n",
      "current sample:  423\n",
      "current sample:  424\n",
      "current sample:  425\n",
      "current sample:  426\n",
      "current sample:  427\n",
      "current sample:  428\n",
      "current sample:  429\n",
      "current sample:  430\n",
      "current sample:  431\n",
      "current sample:  432\n",
      "current sample:  433\n",
      "current sample:  434\n",
      "current sample:  435\n",
      "current sample:  436\n",
      "current sample:  437\n",
      "current sample:  438\n",
      "current sample:  439\n",
      "current sample:  440\n",
      "current sample:  441\n",
      "current sample:  442\n",
      "current sample:  443\n",
      "current sample:  444\n",
      "current sample:  445\n",
      "current sample:  446\n",
      "current sample:  447\n",
      "current sample:  448\n",
      "current sample:  449\n",
      "current sample:  450\n",
      "current sample:  451\n",
      "current sample:  452\n",
      "current sample:  453\n",
      "current sample:  454\n",
      "current sample:  455\n",
      "current sample:  456\n",
      "current sample:  457\n",
      "current sample:  458\n",
      "current sample:  459\n",
      "current sample:  460\n",
      "current sample:  461\n",
      "current sample:  462\n",
      "current sample:  463\n",
      "current sample:  464\n",
      "current sample:  465\n",
      "current sample:  466\n",
      "current sample:  467\n",
      "current sample:  468\n",
      "current sample:  469\n",
      "current sample:  470\n",
      "current sample:  471\n",
      "current sample:  472\n",
      "current sample:  473\n",
      "current sample:  474\n",
      "current sample:  475\n",
      "current sample:  476\n",
      "current sample:  477\n",
      "current sample:  478\n",
      "current sample:  479\n",
      "current sample:  480\n",
      "current sample:  481\n",
      "current sample:  482\n",
      "current sample:  483\n",
      "current sample:  484\n",
      "current sample:  485\n",
      "current sample:  486\n",
      "current sample:  487\n",
      "current sample:  488\n",
      "current sample:  489\n",
      "current sample:  490\n",
      "current sample:  491\n",
      "current sample:  492\n",
      "current sample:  493\n",
      "current sample:  494\n",
      "current sample:  495\n",
      "current sample:  496\n",
      "current sample:  497\n",
      "current sample:  498\n",
      "current sample:  499\n"
     ]
    }
   ],
   "source": [
    "C_representation_result_IDC = compare_representations(C_representation[\"CIFAR_test\"],C_representation[\"CIFAR_train\"],C_y_train,C_VGG_Model3)\n",
    "df_C_representation_result_IDC = concact_results(C_x_test,C_representation_result_IDC[1],C_representation_result_IDC[2],C_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.470286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>9</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.974922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.991903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.761012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.973906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>8</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          9                           0.34                3   \n",
       "1                          1                           0.28                8   \n",
       "2                          9                           0.44                8   \n",
       "3                          3                           0.26                0   \n",
       "4                          6                           0.36                6   \n",
       "5                          2                           0.24                6   \n",
       "6                          7                           0.32                1   \n",
       "7                          3                           0.24                6   \n",
       "8                          4                           0.30                3   \n",
       "9                          9                           0.28                1   \n",
       "10                         5                           0.20                0   \n",
       "11                         9                           0.38                9   \n",
       "12                         7                           0.22                5   \n",
       "13                         5                           0.24                7   \n",
       "14                         9                           0.38                9   \n",
       "15                         8                           0.42                8   \n",
       "16                         7                           0.36                5   \n",
       "17                         1                           0.52                7   \n",
       "18                         9                           0.40                8   \n",
       "19                         4                           0.28                6   \n",
       "20                         7                           0.24                7   \n",
       "21                         0                           0.32                0   \n",
       "22                         9                           0.20                4   \n",
       "23                         1                           0.58                9   \n",
       "24                         0                           0.24                5   \n",
       "25                         9                           0.24                2   \n",
       "26                         1                           0.30                4   \n",
       "27                         7                           0.22                0   \n",
       "28                         1                           0.32                9   \n",
       "29                         5                           0.38                6   \n",
       "..                       ...                            ...              ...   \n",
       "470                        4                           0.28                4   \n",
       "471                        4                           0.28                7   \n",
       "472                        0                           0.44                8   \n",
       "473                        9                           0.50                0   \n",
       "474                        9                           0.28                5   \n",
       "475                        2                           0.24                7   \n",
       "476                        6                           0.22                6   \n",
       "477                        9                           0.48                0   \n",
       "478                        7                           0.16                5   \n",
       "479                        8                           0.24                4   \n",
       "480                        9                           0.50                8   \n",
       "481                        6                           0.88                6   \n",
       "482                        8                           0.60                8   \n",
       "483                        8                           0.26                5   \n",
       "484                        7                           0.24                5   \n",
       "485                        9                           0.30                9   \n",
       "486                        9                           0.40                9   \n",
       "487                        9                           0.28                9   \n",
       "488                        0                           0.24                5   \n",
       "489                        8                           0.54                0   \n",
       "490                        1                           0.82                1   \n",
       "491                        2                           0.24                0   \n",
       "492                        8                           0.62                8   \n",
       "493                        1                           0.38                1   \n",
       "494                        5                           0.20                1   \n",
       "495                        8                           0.34                8   \n",
       "496                        5                           0.16                0   \n",
       "497                        0                           0.20                2   \n",
       "498                        2                           0.22                2   \n",
       "499                        0                           0.22                0   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.998380  \n",
       "1          0.999866  \n",
       "2          0.999801  \n",
       "3          0.999574  \n",
       "4          0.999851  \n",
       "5          0.999952  \n",
       "6          0.999344  \n",
       "7          0.999454  \n",
       "8          0.999920  \n",
       "9          0.998949  \n",
       "10         0.999819  \n",
       "11         0.999923  \n",
       "12         0.998151  \n",
       "13         0.999975  \n",
       "14         0.999852  \n",
       "15         0.999769  \n",
       "16         0.999618  \n",
       "17         0.999515  \n",
       "18         0.999876  \n",
       "19         0.999930  \n",
       "20         0.999091  \n",
       "21         0.999877  \n",
       "22         0.997884  \n",
       "23         0.999888  \n",
       "24         0.999778  \n",
       "25         0.973371  \n",
       "26         0.998684  \n",
       "27         0.999893  \n",
       "28         0.999176  \n",
       "29         0.999982  \n",
       "..              ...  \n",
       "470        0.824856  \n",
       "471        0.999882  \n",
       "472        0.999943  \n",
       "473        0.996931  \n",
       "474        0.470286  \n",
       "475        0.999877  \n",
       "476        0.999663  \n",
       "477        0.989784  \n",
       "478        0.996148  \n",
       "479        0.999609  \n",
       "480        0.998326  \n",
       "481        0.999925  \n",
       "482        0.999884  \n",
       "483        0.974922  \n",
       "484        0.991903  \n",
       "485        0.761012  \n",
       "486        0.999923  \n",
       "487        0.999856  \n",
       "488        0.973906  \n",
       "489        0.998989  \n",
       "490        0.999938  \n",
       "491        0.999502  \n",
       "492        0.999882  \n",
       "493        0.999908  \n",
       "494        0.999923  \n",
       "495        0.999920  \n",
       "496        0.999767  \n",
       "497        0.999738  \n",
       "498        0.999976  \n",
       "499        0.998370  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_IDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "rand_noise_N = np.random.rand(500,32,32,3)\n",
    "rand_noise_U = np.random.uniform(0,1,(500,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  0\n",
      "current sample:  1\n",
      "current sample:  2\n",
      "current sample:  3\n",
      "current sample:  4\n",
      "current sample:  5\n",
      "current sample:  6\n",
      "current sample:  7\n",
      "current sample:  8\n",
      "current sample:  9\n",
      "current sample:  10\n",
      "current sample:  11\n",
      "current sample:  12\n",
      "current sample:  13\n",
      "current sample:  14\n",
      "current sample:  15\n",
      "current sample:  16\n",
      "current sample:  17\n",
      "current sample:  18\n",
      "current sample:  19\n",
      "current sample:  20\n",
      "current sample:  21\n",
      "current sample:  22\n",
      "current sample:  23\n",
      "current sample:  24\n",
      "current sample:  25\n",
      "current sample:  26\n",
      "current sample:  27\n",
      "current sample:  28\n",
      "current sample:  29\n",
      "current sample:  30\n",
      "current sample:  31\n",
      "current sample:  32\n",
      "current sample:  33\n",
      "current sample:  34\n",
      "current sample:  35\n",
      "current sample:  36\n",
      "current sample:  37\n",
      "current sample:  38\n",
      "current sample:  39\n",
      "current sample:  40\n",
      "current sample:  41\n",
      "current sample:  42\n",
      "current sample:  43\n",
      "current sample:  44\n",
      "current sample:  45\n",
      "current sample:  46\n",
      "current sample:  47\n",
      "current sample:  48\n",
      "current sample:  49\n",
      "current sample:  50\n",
      "current sample:  51\n",
      "current sample:  52\n",
      "current sample:  53\n",
      "current sample:  54\n",
      "current sample:  55\n",
      "current sample:  56\n",
      "current sample:  57\n",
      "current sample:  58\n",
      "current sample:  59\n",
      "current sample:  60\n",
      "current sample:  61\n",
      "current sample:  62\n",
      "current sample:  63\n",
      "current sample:  64\n",
      "current sample:  65\n",
      "current sample:  66\n",
      "current sample:  67\n",
      "current sample:  68\n",
      "current sample:  69\n",
      "current sample:  70\n",
      "current sample:  71\n",
      "current sample:  72\n",
      "current sample:  73\n",
      "current sample:  74\n",
      "current sample:  75\n",
      "current sample:  76\n",
      "current sample:  77\n",
      "current sample:  78\n",
      "current sample:  79\n",
      "current sample:  80\n",
      "current sample:  81\n",
      "current sample:  82\n",
      "current sample:  83\n",
      "current sample:  84\n",
      "current sample:  85\n",
      "current sample:  86\n",
      "current sample:  87\n",
      "current sample:  88\n",
      "current sample:  89\n",
      "current sample:  90\n",
      "current sample:  91\n",
      "current sample:  92\n",
      "current sample:  93\n",
      "current sample:  94\n",
      "current sample:  95\n",
      "current sample:  96\n",
      "current sample:  97\n",
      "current sample:  98\n",
      "current sample:  99\n",
      "current sample:  100\n",
      "current sample:  101\n",
      "current sample:  102\n",
      "current sample:  103\n",
      "current sample:  104\n",
      "current sample:  105\n",
      "current sample:  106\n",
      "current sample:  107\n",
      "current sample:  108\n",
      "current sample:  109\n",
      "current sample:  110\n",
      "current sample:  111\n",
      "current sample:  112\n",
      "current sample:  113\n",
      "current sample:  114\n",
      "current sample:  115\n",
      "current sample:  116\n",
      "current sample:  117\n",
      "current sample:  118\n",
      "current sample:  119\n",
      "current sample:  120\n",
      "current sample:  121\n",
      "current sample:  122\n",
      "current sample:  123\n",
      "current sample:  124\n",
      "current sample:  125\n",
      "current sample:  126\n",
      "current sample:  127\n",
      "current sample:  128\n",
      "current sample:  129\n",
      "current sample:  130\n",
      "current sample:  131\n",
      "current sample:  132\n",
      "current sample:  133\n",
      "current sample:  134\n",
      "current sample:  135\n",
      "current sample:  136\n",
      "current sample:  137\n",
      "current sample:  138\n",
      "current sample:  139\n",
      "current sample:  140\n",
      "current sample:  141\n",
      "current sample:  142\n",
      "current sample:  143\n",
      "current sample:  144\n",
      "current sample:  145\n",
      "current sample:  146\n",
      "current sample:  147\n",
      "current sample:  148\n",
      "current sample:  149\n",
      "current sample:  150\n",
      "current sample:  151\n",
      "current sample:  152\n",
      "current sample:  153\n",
      "current sample:  154\n",
      "current sample:  155\n",
      "current sample:  156\n",
      "current sample:  157\n",
      "current sample:  158\n",
      "current sample:  159\n",
      "current sample:  160\n",
      "current sample:  161\n",
      "current sample:  162\n",
      "current sample:  163\n",
      "current sample:  164\n",
      "current sample:  165\n",
      "current sample:  166\n",
      "current sample:  167\n",
      "current sample:  168\n",
      "current sample:  169\n",
      "current sample:  170\n",
      "current sample:  171\n",
      "current sample:  172\n",
      "current sample:  173\n",
      "current sample:  174\n",
      "current sample:  175\n",
      "current sample:  176\n",
      "current sample:  177\n",
      "current sample:  178\n",
      "current sample:  179\n",
      "current sample:  180\n",
      "current sample:  181\n",
      "current sample:  182\n",
      "current sample:  183\n",
      "current sample:  184\n",
      "current sample:  185\n",
      "current sample:  186\n",
      "current sample:  187\n",
      "current sample:  188\n",
      "current sample:  189\n",
      "current sample:  190\n",
      "current sample:  191\n",
      "current sample:  192\n",
      "current sample:  193\n",
      "current sample:  194\n",
      "current sample:  195\n",
      "current sample:  196\n",
      "current sample:  197\n",
      "current sample:  198\n",
      "current sample:  199\n",
      "current sample:  200\n",
      "current sample:  201\n",
      "current sample:  202\n",
      "current sample:  203\n",
      "current sample:  204\n",
      "current sample:  205\n",
      "current sample:  206\n",
      "current sample:  207\n",
      "current sample:  208\n",
      "current sample:  209\n",
      "current sample:  210\n",
      "current sample:  211\n",
      "current sample:  212\n",
      "current sample:  213\n",
      "current sample:  214\n",
      "current sample:  215\n",
      "current sample:  216\n",
      "current sample:  217\n",
      "current sample:  218\n",
      "current sample:  219\n",
      "current sample:  220\n",
      "current sample:  221\n",
      "current sample:  222\n",
      "current sample:  223\n",
      "current sample:  224\n",
      "current sample:  225\n",
      "current sample:  226\n",
      "current sample:  227\n",
      "current sample:  228\n",
      "current sample:  229\n",
      "current sample:  230\n",
      "current sample:  231\n",
      "current sample:  232\n",
      "current sample:  233\n",
      "current sample:  234\n",
      "current sample:  235\n",
      "current sample:  236\n",
      "current sample:  237\n",
      "current sample:  238\n",
      "current sample:  239\n",
      "current sample:  240\n",
      "current sample:  241\n",
      "current sample:  242\n",
      "current sample:  243\n",
      "current sample:  244\n",
      "current sample:  245\n",
      "current sample:  246\n",
      "current sample:  247\n",
      "current sample:  248\n",
      "current sample:  249\n",
      "current sample:  250\n",
      "current sample:  251\n",
      "current sample:  252\n",
      "current sample:  253\n",
      "current sample:  254\n",
      "current sample:  255\n",
      "current sample:  256\n",
      "current sample:  257\n",
      "current sample:  258\n",
      "current sample:  259\n",
      "current sample:  260\n",
      "current sample:  261\n",
      "current sample:  262\n",
      "current sample:  263\n",
      "current sample:  264\n",
      "current sample:  265\n",
      "current sample:  266\n",
      "current sample:  267\n",
      "current sample:  268\n",
      "current sample:  269\n",
      "current sample:  270\n",
      "current sample:  271\n",
      "current sample:  272\n",
      "current sample:  273\n",
      "current sample:  274\n",
      "current sample:  275\n",
      "current sample:  276\n",
      "current sample:  277\n",
      "current sample:  278\n",
      "current sample:  279\n",
      "current sample:  280\n",
      "current sample:  281\n",
      "current sample:  282\n",
      "current sample:  283\n",
      "current sample:  284\n",
      "current sample:  285\n",
      "current sample:  286\n",
      "current sample:  287\n",
      "current sample:  288\n",
      "current sample:  289\n",
      "current sample:  290\n",
      "current sample:  291\n",
      "current sample:  292\n",
      "current sample:  293\n",
      "current sample:  294\n",
      "current sample:  295\n",
      "current sample:  296\n",
      "current sample:  297\n",
      "current sample:  298\n",
      "current sample:  299\n",
      "current sample:  300\n",
      "current sample:  301\n",
      "current sample:  302\n",
      "current sample:  303\n",
      "current sample:  304\n",
      "current sample:  305\n",
      "current sample:  306\n",
      "current sample:  307\n",
      "current sample:  308\n",
      "current sample:  309\n",
      "current sample:  310\n",
      "current sample:  311\n",
      "current sample:  312\n",
      "current sample:  313\n",
      "current sample:  314\n",
      "current sample:  315\n",
      "current sample:  316\n",
      "current sample:  317\n",
      "current sample:  318\n",
      "current sample:  319\n",
      "current sample:  320\n",
      "current sample:  321\n",
      "current sample:  322\n",
      "current sample:  323\n",
      "current sample:  324\n",
      "current sample:  325\n",
      "current sample:  326\n",
      "current sample:  327\n",
      "current sample:  328\n",
      "current sample:  329\n",
      "current sample:  330\n",
      "current sample:  331\n",
      "current sample:  332\n",
      "current sample:  333\n",
      "current sample:  334\n",
      "current sample:  335\n",
      "current sample:  336\n",
      "current sample:  337\n",
      "current sample:  338\n",
      "current sample:  339\n",
      "current sample:  340\n",
      "current sample:  341\n",
      "current sample:  342\n",
      "current sample:  343\n",
      "current sample:  344\n",
      "current sample:  345\n",
      "current sample:  346\n",
      "current sample:  347\n",
      "current sample:  348\n",
      "current sample:  349\n",
      "current sample:  350\n",
      "current sample:  351\n",
      "current sample:  352\n",
      "current sample:  353\n",
      "current sample:  354\n",
      "current sample:  355\n",
      "current sample:  356\n",
      "current sample:  357\n",
      "current sample:  358\n",
      "current sample:  359\n",
      "current sample:  360\n",
      "current sample:  361\n",
      "current sample:  362\n",
      "current sample:  363\n",
      "current sample:  364\n",
      "current sample:  365\n",
      "current sample:  366\n",
      "current sample:  367\n",
      "current sample:  368\n",
      "current sample:  369\n",
      "current sample:  370\n",
      "current sample:  371\n",
      "current sample:  372\n",
      "current sample:  373\n",
      "current sample:  374\n",
      "current sample:  375\n",
      "current sample:  376\n",
      "current sample:  377\n",
      "current sample:  378\n",
      "current sample:  379\n",
      "current sample:  380\n",
      "current sample:  381\n",
      "current sample:  382\n",
      "current sample:  383\n",
      "current sample:  384\n",
      "current sample:  385\n",
      "current sample:  386\n",
      "current sample:  387\n",
      "current sample:  388\n",
      "current sample:  389\n",
      "current sample:  390\n",
      "current sample:  391\n",
      "current sample:  392\n",
      "current sample:  393\n",
      "current sample:  394\n",
      "current sample:  395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample:  396\n",
      "current sample:  397\n",
      "current sample:  398\n",
      "current sample:  399\n",
      "current sample:  400\n",
      "current sample:  401\n",
      "current sample:  402\n",
      "current sample:  403\n",
      "current sample:  404\n",
      "current sample:  405\n",
      "current sample:  406\n",
      "current sample:  407\n",
      "current sample:  408\n",
      "current sample:  409\n",
      "current sample:  410\n",
      "current sample:  411\n",
      "current sample:  412\n",
      "current sample:  413\n",
      "current sample:  414\n",
      "current sample:  415\n",
      "current sample:  416\n",
      "current sample:  417\n",
      "current sample:  418\n",
      "current sample:  419\n",
      "current sample:  420\n",
      "current sample:  421\n",
      "current sample:  422\n",
      "current sample:  423\n",
      "current sample:  424\n",
      "current sample:  425\n",
      "current sample:  426\n",
      "current sample:  427\n",
      "current sample:  428\n",
      "current sample:  429\n",
      "current sample:  430\n",
      "current sample:  431\n",
      "current sample:  432\n",
      "current sample:  433\n",
      "current sample:  434\n",
      "current sample:  435\n",
      "current sample:  436\n",
      "current sample:  437\n",
      "current sample:  438\n",
      "current sample:  439\n",
      "current sample:  440\n",
      "current sample:  441\n",
      "current sample:  442\n",
      "current sample:  443\n",
      "current sample:  444\n",
      "current sample:  445\n",
      "current sample:  446\n",
      "current sample:  447\n",
      "current sample:  448\n",
      "current sample:  449\n",
      "current sample:  450\n",
      "current sample:  451\n",
      "current sample:  452\n",
      "current sample:  453\n",
      "current sample:  454\n",
      "current sample:  455\n",
      "current sample:  456\n",
      "current sample:  457\n",
      "current sample:  458\n",
      "current sample:  459\n",
      "current sample:  460\n",
      "current sample:  461\n",
      "current sample:  462\n",
      "current sample:  463\n",
      "current sample:  464\n",
      "current sample:  465\n",
      "current sample:  466\n",
      "current sample:  467\n",
      "current sample:  468\n",
      "current sample:  469\n",
      "current sample:  470\n",
      "current sample:  471\n",
      "current sample:  472\n",
      "current sample:  473\n",
      "current sample:  474\n",
      "current sample:  475\n",
      "current sample:  476\n",
      "current sample:  477\n",
      "current sample:  478\n",
      "current sample:  479\n",
      "current sample:  480\n",
      "current sample:  481\n",
      "current sample:  482\n",
      "current sample:  483\n",
      "current sample:  484\n",
      "current sample:  485\n",
      "current sample:  486\n",
      "current sample:  487\n",
      "current sample:  488\n",
      "current sample:  489\n",
      "current sample:  490\n",
      "current sample:  491\n",
      "current sample:  492\n",
      "current sample:  493\n",
      "current sample:  494\n",
      "current sample:  495\n",
      "current sample:  496\n",
      "current sample:  497\n",
      "current sample:  498\n",
      "current sample:  499\n"
     ]
    }
   ],
   "source": [
    "C_representation_result_IDC_t = compare_representations(C_representation[\"CIFAR_train\"],C_representation[\"CIFAR_train\"],C_y_train,C_VGG_Model3)\n",
    "df_C_representation_result_IDC_t = concact_results(C_x_train,C_representation_result_IDC_t[1],C_representation_result_IDC_t[2],C_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3</td>\n",
       "      <td>0.947240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>6</td>\n",
       "      <td>0.76</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>6</td>\n",
       "      <td>0.74</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>9</td>\n",
       "      <td>0.72</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "39                         6                           0.72                3   \n",
       "45                         1                           0.92                1   \n",
       "61                         1                           0.88                1   \n",
       "99                         1                           0.96                1   \n",
       "117                        6                           0.72                6   \n",
       "136                        1                           0.94                1   \n",
       "143                        6                           0.98                6   \n",
       "158                        1                           0.76                4   \n",
       "160                        1                           0.88                1   \n",
       "184                        1                           1.00                1   \n",
       "201                        1                           0.86                1   \n",
       "206                        1                           0.96                1   \n",
       "224                        6                           0.76                6   \n",
       "226                        1                           0.72                1   \n",
       "243                        6                           0.74                6   \n",
       "261                        1                           0.98                1   \n",
       "312                        1                           0.78                1   \n",
       "316                        9                           0.72                9   \n",
       "432                        1                           0.88                1   \n",
       "464                        6                           0.72                6   \n",
       "486                        1                           0.88                1   \n",
       "\n",
       "     predicted_prob  \n",
       "39         0.947240  \n",
       "45         0.999913  \n",
       "61         0.999919  \n",
       "99         0.999631  \n",
       "117        0.999921  \n",
       "136        0.999910  \n",
       "143        0.999960  \n",
       "158        0.999671  \n",
       "160        0.999887  \n",
       "184        0.999962  \n",
       "201        0.999950  \n",
       "206        0.999658  \n",
       "224        0.999512  \n",
       "226        0.999945  \n",
       "243        0.999853  \n",
       "261        0.999898  \n",
       "312        0.999900  \n",
       "316        0.999960  \n",
       "432        0.999894  \n",
       "464        0.999773  \n",
       "486        0.999932  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_IDC_t[df_C_representation_result_IDC_t['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.42</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.992922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>9</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>8</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.992850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          6                           0.28                6   \n",
       "1                          1                           0.20                9   \n",
       "2                          9                           0.20                9   \n",
       "3                          6                           0.26                4   \n",
       "4                          1                           0.62                1   \n",
       "5                          1                           0.24                1   \n",
       "6                          2                           0.30                2   \n",
       "7                          7                           0.42                7   \n",
       "8                          8                           0.20                8   \n",
       "9                          9                           0.62                3   \n",
       "10                         6                           0.46                4   \n",
       "11                         8                           0.26                7   \n",
       "12                         9                           0.56                7   \n",
       "13                         9                           0.30                2   \n",
       "14                         9                           0.26                9   \n",
       "15                         8                           0.20                9   \n",
       "16                         9                           0.64                9   \n",
       "17                         3                           0.22                3   \n",
       "18                         9                           0.34                2   \n",
       "19                         3                           0.24                6   \n",
       "20                         3                           0.20                4   \n",
       "21                         1                           0.16                3   \n",
       "22                         6                           0.38                6   \n",
       "23                         0                           0.28                6   \n",
       "24                         2                           0.20                2   \n",
       "25                         9                           0.42                6   \n",
       "26                         8                           0.50                3   \n",
       "27                         5                           0.36                5   \n",
       "28                         0                           0.26                4   \n",
       "29                         9                           0.34                0   \n",
       "..                       ...                            ...              ...   \n",
       "470                        4                           0.34                7   \n",
       "471                        1                           0.32                5   \n",
       "472                        9                           0.38                9   \n",
       "473                        3                           0.24                6   \n",
       "474                        2                           0.34                2   \n",
       "475                        8                           0.34                8   \n",
       "476                        1                           0.44                3   \n",
       "477                        6                           0.28                4   \n",
       "478                        7                           0.22                7   \n",
       "479                        9                           0.32                3   \n",
       "480                        9                           0.48                9   \n",
       "481                        5                           0.24                0   \n",
       "482                        1                           0.54                1   \n",
       "483                        4                           0.26                2   \n",
       "484                        3                           0.22                4   \n",
       "485                        8                           0.44                8   \n",
       "486                        1                           0.88                1   \n",
       "487                        6                           0.32                8   \n",
       "488                        7                           0.22                6   \n",
       "489                        1                           0.30                4   \n",
       "490                        4                           0.22                4   \n",
       "491                        5                           0.24                5   \n",
       "492                        3                           0.24                7   \n",
       "493                        6                           0.60                1   \n",
       "494                        9                           0.28                3   \n",
       "495                        2                           0.26                9   \n",
       "496                        7                           0.32                8   \n",
       "497                        0                           0.40                0   \n",
       "498                        7                           0.26                1   \n",
       "499                        9                           0.22                7   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.999873  \n",
       "1          0.999948  \n",
       "2          0.999871  \n",
       "3          0.999891  \n",
       "4          0.999953  \n",
       "5          0.999918  \n",
       "6          0.999937  \n",
       "7          0.999960  \n",
       "8          0.999905  \n",
       "9          0.999909  \n",
       "10         0.985948  \n",
       "11         0.999709  \n",
       "12         0.999890  \n",
       "13         0.999887  \n",
       "14         0.999823  \n",
       "15         0.999907  \n",
       "16         0.999740  \n",
       "17         0.982392  \n",
       "18         0.999396  \n",
       "19         0.999517  \n",
       "20         0.999382  \n",
       "21         0.995749  \n",
       "22         0.999963  \n",
       "23         0.999874  \n",
       "24         0.999767  \n",
       "25         0.998607  \n",
       "26         0.999929  \n",
       "27         0.994590  \n",
       "28         0.999839  \n",
       "29         0.999879  \n",
       "..              ...  \n",
       "470        0.998801  \n",
       "471        0.999879  \n",
       "472        0.999530  \n",
       "473        0.999891  \n",
       "474        0.999894  \n",
       "475        0.999397  \n",
       "476        0.999541  \n",
       "477        0.990083  \n",
       "478        0.992922  \n",
       "479        0.999918  \n",
       "480        0.999932  \n",
       "481        0.999827  \n",
       "482        0.999913  \n",
       "483        0.999846  \n",
       "484        0.999700  \n",
       "485        0.999835  \n",
       "486        0.999932  \n",
       "487        0.999716  \n",
       "488        0.999905  \n",
       "489        0.999933  \n",
       "490        0.999783  \n",
       "491        0.999000  \n",
       "492        0.999622  \n",
       "493        0.996636  \n",
       "494        0.999470  \n",
       "495        0.999754  \n",
       "496        0.992850  \n",
       "497        0.999424  \n",
       "498        0.999774  \n",
       "499        0.999669  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_IDC_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
