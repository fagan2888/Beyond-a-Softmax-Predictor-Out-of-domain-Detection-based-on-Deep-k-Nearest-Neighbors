{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('MNIST_vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 25\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        x_train,y_train,x_test,y_test = mnist_train_RGB_x,M_train_y,mnist_test_RGB_x,M_test_y\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('MNIST_vgg.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('cifar10vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 250\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('cifar10vgg.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "def MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y):\n",
    "    \"\"\"\n",
    "    Change the one-channel to RBG-channel on mnist_train_x and mnist_test_x\n",
    "    Change the shape of mnist_train_y and mnist_test_y from (length) to (length,1)\n",
    "    ---------------------------------------\n",
    "    inputs:\n",
    "    mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y which is all multi-dimension array\n",
    "    It is recommended to use the following way to import the data\n",
    "    ========================== codes ==========================\n",
    "    mnist = keras.datasets.mnist\n",
    "    (mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "    ========================== codes ==========================\n",
    "    outputs:\n",
    "    mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y \n",
    "    \"\"\"\n",
    "    from skimage import exposure\n",
    "    import imutils\n",
    "    B= []\n",
    "    for i in range(len(mnist_train_x)):\n",
    "        A = mnist_train_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_train_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    B= []\n",
    "    for i in range(len(mnist_test_x)):\n",
    "        A = mnist_test_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_test_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    M_train_y = np.array([[mnist_train_y[i]] for i in range(len(mnist_train_y))])\n",
    "    M_test_y = np.array([[mnist_test_y[i]] for i in range(len(mnist_test_y))])\n",
    "    return mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1025 15:06:23.552950 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1025 15:06:23.566946 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1025 15:06:23.585863 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1025 15:06:23.586894 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1025 15:06:23.586894 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1025 15:06:25.278805 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1025 15:06:25.326338 19100 deprecation.py:506] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1025 15:06:25.406121 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1025 15:06:26.943287 19100 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1025 15:06:27.154981 19100 deprecation.py:323] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"MNIST-VGG-1.pkl\",\"rb+\")\n",
    "M_VGG_Model1 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"MNIST-VGG-2.pkl\",\"rb+\")\n",
    "M_VGG_Model2 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"MNIST-VGG-3.pkl\",\"rb+\")\n",
    "M_VGG_Model3 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"CIFAR-VGG-1.pkl\",\"rb+\")\n",
    "C_VGG_Model1 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"CIFAR-VGG-2.pkl\",\"rb+\")\n",
    "C_VGG_Model2 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"CIFAR-VGG-3.pkl\",\"rb+\")\n",
    "C_VGG_Model3 = pickle.load(fp, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y = MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y)\n",
    "(C_x_train, C_y_train), (C_x_test, C_y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    shape = arr.shape\n",
    "    flatten = arr.reshape(shape[0],shape[1]*shape[2]*shape[3])\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_RGB_x_flatten = flatten(mnist_train_RGB_x)\n",
    "mnist_test_RGB_x_flatten = flatten(mnist_test_RGB_x)\n",
    "C_x_train_flatten = flatten(C_x_train)\n",
    "C_x_test_flatten = flatten(C_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_the_orignal_index_after_ranking(arr, isReverse = True):\n",
    "    \"\"\"\n",
    "    This function return the orignal index of the after the array is sorted\n",
    "    inputs:\n",
    "    arr || one dimension list or ndarray\n",
    "    isReverse || boolean, if it is \"True\" the rank is decending; if it is \"False\" the rank is ascending \n",
    "    outputs:\n",
    "    A || an arr including the orignal index before ranking\n",
    "    ========================= examples =========================\n",
    "    For example, arr = [4,7,2,9]\n",
    "    we have the mapping relationship:\n",
    "    index    value\n",
    "      0        4\n",
    "      1        7\n",
    "      2        2\n",
    "      3        9\n",
    "    After sorting, say decendingly, we have:\n",
    "    orignal_index     value\n",
    "      3                 9\n",
    "      1                 7\n",
    "      0                 4\n",
    "      2                 2    \n",
    "    the result is for this function is [3,1,0,2].\n",
    "    \"\"\"\n",
    "    import operator\n",
    "    similarity_dict = dict(zip(list(range(len(arr))),arr))\n",
    "    sorted_similarity_dict = sorted(similarity_dict.items(), reverse=isReverse, key=operator.itemgetter(1))\n",
    "    A = [sorted_similarity_dict[i][0] for i in range(len(arr))]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx(arr, target):\n",
    "    ans = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == target:\n",
    "            ans.append(i)\n",
    "    return ans\n",
    "def get_submax(arr):\n",
    "    arr = np.array(arr)\n",
    "    MAX = np.max(arr)\n",
    "    idx = find_idx(arr, MAX)\n",
    "    arr_without_max = np.delete(arr,idx)\n",
    "    return np.max(arr_without_max)\n",
    "def find_statistics(Prob_Mat):\n",
    "    Prob_diff = []\n",
    "    MAX_Prob_Mat = []\n",
    "    MAX_Prob_Mat_idx = []\n",
    "    subMAX_Prob_Mat = []\n",
    "    subMAX_Prob_Mat_idx = []\n",
    "    for i in range(len(Prob_Mat)):\n",
    "        MAX = np.max(Prob_Mat[i])\n",
    "        MAX_idx = find_idx(Prob_Mat[i], MAX)[0]\n",
    "        subMAX = get_submax(Prob_Mat[i])\n",
    "        subMAX_idx = find_idx(Prob_Mat[i], subMAX)[0]\n",
    "        prob_difference = MAX - subMAX\n",
    "        Prob_diff.append(prob_difference)\n",
    "        MAX_Prob_Mat.append(MAX)\n",
    "        subMAX_Prob_Mat.append(subMAX)\n",
    "        MAX_Prob_Mat_idx.append(MAX_idx)\n",
    "        subMAX_Prob_Mat_idx.append(subMAX_idx)\n",
    "    return Prob_diff,MAX_Prob_Mat,MAX_Prob_Mat_idx,subMAX_Prob_Mat,subMAX_Prob_Mat_idx\n",
    "def separate_one_class(target_class_label, x_train, y_train, x_test, y_test):\n",
    "    with_train_idx = find_idx(y_train, target_class_label)\n",
    "    with_test_idx = find_idx(y_test, target_class_label)\n",
    "    without_train_idx = list(set(range(len(y_train))).difference(set(with_train_idx)))\n",
    "    without_test_idx = list(set(range(len(y_test))).difference(set(with_test_idx)))\n",
    "    with_train = x_train[with_train_idx]\n",
    "    with_test = x_test[with_test_idx]\n",
    "    without_train = x_train[without_train_idx]\n",
    "    without_test = x_test[without_test_idx]\n",
    "    with_train_y = y_train[with_train_idx]\n",
    "    with_test_y = y_test[with_test_idx]\n",
    "    without_train_y = y_train[without_train_idx]\n",
    "    without_test_y = y_test[without_test_idx]\n",
    "    return with_train, with_train_y, without_train, without_train_y, with_test, with_test_y, without_test, without_test_y\n",
    "def minkowski_distance(x,y,n):\n",
    "    if np.isinf(n):\n",
    "        if n>0:\n",
    "            return np.max(np.abs(x-y))\n",
    "        else:\n",
    "            return np.min(np.abs(x-y))\n",
    "    else:\n",
    "        return np.power(np.sum(np.power(np.abs(x-y),n)),1/n)\n",
    "def minkowski_similarity(x,Y,n):\n",
    "    arr = []\n",
    "    for y in Y:\n",
    "        arr.append(minkowski_distance(x,y,n))\n",
    "    return np.array(arr)\n",
    "\n",
    "def get_KNN_stats(k,testarr_one_sample, testarr_waiting_to_compare, \n",
    "                  testarr_waiting_to_compare_label, Model, similarity_method = 'cosine_similarity', minkowski_power = 2):\n",
    "    \"\"\"\n",
    "    Inputs Example:\n",
    "    k = 50\n",
    "    testarr_one_sample = [mnist_train_RGB_x[0]]\n",
    "    testarr_waiting_to_compare = [C_x_train[i] for i in range(5000)]\n",
    "    testarr_waiting_to_compare_label = C_y_train[:5000].reshape(5000)\n",
    "    Model = C_VGG_Model1.model\n",
    "    \n",
    "    Inputs:\n",
    "    k: int, the number of the nearest neighbour\n",
    "    testarr_one_sample: multi-dimensional ndarray, shape = (1,num_pixel_x,num_pixel_y,num_channel)\n",
    "    testarr_waiting_to_compare_label: multi-dimensional ndarray, shape = (num_neighbour_candidate,num_pixel_x,num_pixel_y,num_channel)\n",
    "    testarr_waiting_to_compare_label: one-dimensional ndarray, shape = (num_neighbour_candidate,)\n",
    "    Model: keras backend model\n",
    "    similarity_method: String, 'cosine_similarity', 'minkowski_similarity'. Default = 'cosine_similarity'\n",
    "    minkowski_power: int, the p-value in the minkowski_distance. Only useful when similarity_method = 'minkowski_similarity'\n",
    "    \n",
    "    Outputs:\n",
    "    similarity: one-dimensional ndarray, shape = (num_neighbour_candidate,)\n",
    "    K_nearest_neighbour_orignal_label: one-dimensional ndarray, shape = (k,)\n",
    "    K_nearest_neighbour: multi-dimensional ndarray, shape = (k,num_pixel_x,num_pixel_y,num_channel)\n",
    "    KNN_oringal_class: dictionary, counts of the orignal class\n",
    "    max_ratio_KNN_from_one_class: float, the max of the ratio of KNN are from one class\n",
    "    \"\"\"\n",
    "    from keras import backend as K\n",
    "    testarr_waiting_to_compare = np.array(testarr_waiting_to_compare)\n",
    "    inp = Model.model.input                                           # input placeholder\n",
    "    outputs = Model.model.layers[58].output          # all layer outputs\n",
    "    functors = K.function([inp, K.learning_phase()], [outputs])   # evaluation functions\n",
    "\n",
    "    # Testing\n",
    "    test1 = testarr_one_sample\n",
    "    layer_outs_one_sample = functors([test1, 0.])\n",
    "    layer_outs_one_sample = np.array(layer_outs_one_sample)[0]\n",
    "\n",
    "    test2 = testarr_waiting_to_compare\n",
    "    layer_outs_waiting_to_compare = functors([test2, 0.])\n",
    "    layer_outs_waiting_to_compare = np.array(layer_outs_waiting_to_compare)[0]\n",
    "    if similarity_method == 'cosine_similarity':\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarity = cosine_similarity(layer_outs_one_sample, layer_outs_waiting_to_compare)\n",
    "        similarity = np.array(similarity[0])\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity)[:k]\n",
    "    elif similarity_method == 'minkowski_similarity':\n",
    "        similarity = minkowski_similarity(layer_outs_one_sample, layer_outs_waiting_to_compare, minkowski_power)\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity, isReverse = False)[:k]\n",
    "    else:\n",
    "        raise Exception(\"invalid similarity method\")\n",
    "    \n",
    "    K_nearest_neighbour_orignal_label = np.array(K_nearest_neighbour_orignal_label)\n",
    "    K_nearest_neighbour = testarr_waiting_to_compare[K_nearest_neighbour_orignal_label]\n",
    "    from collections import Counter\n",
    "    KNN_oringal_class = Counter(testarr_waiting_to_compare_label[K_nearest_neighbour_orignal_label])\n",
    "    max_ratio_KNN_from_one_class = max(KNN_oringal_class.values())/k\n",
    "    return similarity, K_nearest_neighbour_orignal_label, K_nearest_neighbour, KNN_oringal_class, max_ratio_KNN_from_one_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(columns,rows,arr):\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img = arr[i-1]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KNN_in_pixel_representation(testarr_one_sample, testarr_waiting_to_compare, testarr_waiting_to_compare_label, similarity_method = 'cosine_similarity', minkowski_power = 2):\n",
    "    testarr_one_sample = np.array(testarr_one_sample)\n",
    "    testarr_waiting_to_compare = np.array(testarr_waiting_to_compare)\n",
    "    testarr_one_sample_flatten = flatten(testarr_one_sample)\n",
    "    testarr_waiting_to_compare_flatten = flatten(testarr_waiting_to_compare)\n",
    "    if similarity_method == 'cosine_similarity':\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarity = cosine_similarity(testarr_one_sample_flatten, testarr_waiting_to_compare_flatten)\n",
    "        similarity = np.array(similarity[0])\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity)[:k]\n",
    "    elif similarity_method == 'minkowski_similarity':\n",
    "        similarity = minkowski_similarity(testarr_one_sample_flatten, testarr_waiting_to_compare_flatten, minkowski_power)\n",
    "        K_nearest_neighbour_orignal_label = get_the_orignal_index_after_ranking(similarity, isReverse= False)[:k]\n",
    "    else:\n",
    "        raise Exception(\"invalid similarity method\")\n",
    "    \n",
    "    K_nearest_neighbour_orignal_label = np.array(K_nearest_neighbour_orignal_label)\n",
    "    K_nearest_neighbour = testarr_waiting_to_compare_flatten[K_nearest_neighbour_orignal_label]\n",
    "    from collections import Counter\n",
    "    KNN_oringal_class = Counter(testarr_waiting_to_compare_label[K_nearest_neighbour_orignal_label])\n",
    "    max_ratio_KNN_from_one_class = max(KNN_oringal_class.values())/k\n",
    "    import operator\n",
    "    max_KNN_class_label = max(KNN_oringal_class.items(), key=operator.itemgetter(1))[0]\n",
    "    return similarity, K_nearest_neighbour_orignal_label, K_nearest_neighbour, KNN_oringal_class, max_ratio_KNN_from_one_class, max_KNN_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel representation\n",
    "k = 50\n",
    "testarr_one_sample_1 = [C_x_train[0]]\n",
    "testarr_waiting_to_compare_1 = [mnist_train_RGB_x[i] for i in range(5000)]\n",
    "testarr_waiting_to_compare_label_1 = M_train_y[:5000].reshape(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_l2_1 = get_KNN_in_pixel_representation(testarr_one_sample_1, testarr_waiting_to_compare_1, testarr_waiting_to_compare_label_1, similarity_method = 'minkowski_similarity', minkowski_power = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({7: 8, 0: 10, 9: 12, 2: 4, 5: 3, 3: 3, 4: 9, 8: 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_l2_1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[573.7159575957427,\n",
       " 573.4439815709987,\n",
       " 573.4413657907842,\n",
       " 573.1378542724254,\n",
       " 572.6936353758439,\n",
       " 572.6360100447753,\n",
       " 572.5146286340638,\n",
       " 572.167807552994,\n",
       " 572.1503298959112,\n",
       " 572.1127511251607,\n",
       " 572.0742958742335,\n",
       " 572.067303732699,\n",
       " 571.9230717500387,\n",
       " 571.7123402551322,\n",
       " 571.5120296196748,\n",
       " 571.3536558034787,\n",
       " 571.338778659387,\n",
       " 571.2460065505928,\n",
       " 571.233752504174,\n",
       " 571.1917366349062,\n",
       " 571.1777306583302,\n",
       " 571.1777306583302,\n",
       " 571.1645997433665,\n",
       " 571.1427142142321,\n",
       " 571.1182014259394,\n",
       " 571.1120730644731,\n",
       " 571.0429055683994,\n",
       " 571.041154383815,\n",
       " 571.0192641233743,\n",
       " 571.0148859705848,\n",
       " 571.0113834241836,\n",
       " 570.9422037299397,\n",
       " 570.9308189264265,\n",
       " 570.9255643251579,\n",
       " 570.924688553578,\n",
       " 570.9045454364503,\n",
       " 570.9036696326273,\n",
       " 570.894035701898,\n",
       " 570.8835257738657,\n",
       " 570.8817741003824,\n",
       " 570.84761539311,\n",
       " 570.8300973144286,\n",
       " 570.8222140036248,\n",
       " 570.8187102749874,\n",
       " 570.781043833798,\n",
       " 570.7591435973671,\n",
       " 570.7565155125257,\n",
       " 570.7004468195202,\n",
       " 570.6654010889393,\n",
       " 570.6426202098824,\n",
       " 570.6408677969008,\n",
       " 570.6172096949057,\n",
       " 570.5953031702942,\n",
       " 570.5821588518169,\n",
       " 570.5549929673738,\n",
       " 570.5541166269857,\n",
       " 570.5532402852516,\n",
       " 570.5479822065801,\n",
       " 570.5287021701888,\n",
       " 570.5094214822399,\n",
       " 570.5076686601154,\n",
       " 570.4997808939106,\n",
       " 570.4936458892421,\n",
       " 570.4813756819761,\n",
       " 570.4769934011362,\n",
       " 570.4699816817708,\n",
       " 570.4542049980874,\n",
       " 570.4419339424478,\n",
       " 570.437551358604,\n",
       " 570.4103785872063,\n",
       " 570.3849577259203,\n",
       " 570.3683020645519,\n",
       " 570.3437559928223,\n",
       " 570.3288525052893,\n",
       " 570.3113184919268,\n",
       " 570.3034280100375,\n",
       " 570.2990443618155,\n",
       " 570.294660679898,\n",
       " 570.2788791459842,\n",
       " 570.2753720791386,\n",
       " 570.2718649907252,\n",
       " 570.2648507491936,\n",
       " 570.2534524226925,\n",
       " 570.2499451994713,\n",
       " 570.2341624280327,\n",
       " 570.2332855945889,\n",
       " 570.2324087597968,\n",
       " 570.2271477227299,\n",
       " 570.2061030890497,\n",
       " 570.1999649245868,\n",
       " 570.1938266940462,\n",
       " 570.1859345862541,\n",
       " 570.1719039026739,\n",
       " 570.1692731110649,\n",
       " 570.166642307317,\n",
       " 570.1622576074288,\n",
       " 570.1613806634048,\n",
       " 570.15261114898,\n",
       " 570.15261114898,\n",
       " 570.131563764014,\n",
       " 570.1254247970353,\n",
       " 570.1184087538307,\n",
       " 570.1078845271305,\n",
       " 570.1034993753327,\n",
       " 570.1008682680636,\n",
       " 570.1008682680636,\n",
       " 570.0920978227991,\n",
       " 570.086835490875,\n",
       " 570.0859584308317,\n",
       " 570.079818972747,\n",
       " 570.0605231025912,\n",
       " 570.0596460020653,\n",
       " 570.0570146923902,\n",
       " 570.0394723174878,\n",
       " 570.01491208564,\n",
       " 570.0114033947041,\n",
       " 570.0096490411369,\n",
       " 570.007017500662,\n",
       " 570.0043859480381,\n",
       " 569.9929824129416,\n",
       " 569.9631567040101,\n",
       " 569.9561386633186,\n",
       " 569.9499978068252,\n",
       " 569.9464887162653,\n",
       " 569.9306975413765,\n",
       " 569.9271883319833,\n",
       " 569.9263110262589,\n",
       " 569.8999912265309,\n",
       " 569.8841987632225,\n",
       " 569.8841987632225,\n",
       " 569.8789345115329,\n",
       " 569.8754249833905,\n",
       " 569.8675284660462,\n",
       " 569.8666510684758,\n",
       " 569.8631414646853,\n",
       " 569.851735103088,\n",
       " 569.851735103088,\n",
       " 569.8447156901607,\n",
       " 569.8350638562005,\n",
       " 569.8315540578636,\n",
       " 569.8297991505884,\n",
       " 569.8236569325636,\n",
       " 569.8192695934388,\n",
       " 569.8096173284547,\n",
       " 569.8025973966774,\n",
       " 569.7929448492672,\n",
       " 569.7885572736609,\n",
       " 569.7762718822187,\n",
       " 569.7745168046742,\n",
       " 569.771884178221,\n",
       " 569.767496440434,\n",
       " 569.767496440434,\n",
       " 569.7657413358581,\n",
       " 569.7648637815428,\n",
       " 569.7648637815428,\n",
       " 569.7631086688572,\n",
       " 569.7569657318811,\n",
       " 569.753455452444,\n",
       " 569.7525778792054,\n",
       " 569.7490675727341,\n",
       " 569.7455572446353,\n",
       " 569.7438020724754,\n",
       " 569.7402917119343,\n",
       " 569.7367813297645,\n",
       " 569.7183514685129,\n",
       " 569.716596212538,\n",
       " 569.6981656982932,\n",
       " 569.6972880398853,\n",
       " 569.6964103801251,\n",
       " 569.6621805947802,\n",
       " 569.6586697312698,\n",
       " 569.6586697312698,\n",
       " 569.6569142914005,\n",
       " 569.6569142914005,\n",
       " 569.6534033954331,\n",
       " 569.6516479393349,\n",
       " 569.6490147450446,\n",
       " 569.6411150891411,\n",
       " 569.6402373428338,\n",
       " 569.6314598053727,\n",
       " 569.6226821326552,\n",
       " 569.6182932455733,\n",
       " 569.617415464099,\n",
       " 569.61478211156,\n",
       " 569.6051263814257,\n",
       " 569.6024929720726,\n",
       " 569.5981039294285,\n",
       " 569.5910813908519,\n",
       " 569.5831809314598,\n",
       " 569.5770360539477,\n",
       " 569.5612346359256,\n",
       " 569.5594788957515,\n",
       " 569.5498222280471,\n",
       " 569.5498222280471,\n",
       " 569.5445548857438,\n",
       " 569.5410432971446,\n",
       " 569.5392874947258,\n",
       " 569.5357758736495,\n",
       " 569.5313863168561,\n",
       " 569.5296304846659,\n",
       " 569.5269967262307,\n",
       " 569.5269967262307,\n",
       " 569.5226071017726,\n",
       " 569.5173395077625,\n",
       " 569.5129498088696,\n",
       " 569.5111939198385,\n",
       " 569.5111939198385,\n",
       " 569.505048265597,\n",
       " 569.5032923522041,\n",
       " 569.5024143934774,\n",
       " 569.4980245795415,\n",
       " 569.4962686444925,\n",
       " 569.4945127040295,\n",
       " 569.4830989590472,\n",
       " 569.4629048498242,\n",
       " 569.4558806439705,\n",
       " 569.45061243272,\n",
       " 569.4479783088179,\n",
       " 569.4374416913591,\n",
       " 569.4330513765424,\n",
       " 569.415489778773,\n",
       " 569.4146116846669,\n",
       " 569.4137335892067,\n",
       " 569.4075868830691,\n",
       " 569.4049525601266,\n",
       " 569.4040744497706,\n",
       " 569.4040744497706,\n",
       " 569.4031963380606,\n",
       " 569.3996838776783,\n",
       " 569.3961713956286,\n",
       " 569.3882682317927,\n",
       " 569.3882682317927,\n",
       " 569.3821212507466,\n",
       " 569.3742178918887,\n",
       " 569.372461575022,\n",
       " 569.3707052527378,\n",
       " 569.3680707591532,\n",
       " 569.3663144233245,\n",
       " 569.3592890258312,\n",
       " 569.3505071570587,\n",
       " 569.3505071570587,\n",
       " 569.3487507670496,\n",
       " 569.3408469449562,\n",
       " 569.3303083448131,\n",
       " 569.3294301193291,\n",
       " 569.3215260290094,\n",
       " 569.3180130647545,\n",
       " 569.3171348203039,\n",
       " 569.3145000788229,\n",
       " 569.3118653251485,\n",
       " 569.2881519933469,\n",
       " 569.2872737028292,\n",
       " 569.2846388231462,\n",
       " 569.2811256312649,\n",
       " 569.2793690271939,\n",
       " 569.2776124177026,\n",
       " 569.2749774933025,\n",
       " 569.2653159994907,\n",
       " 569.256532681005,\n",
       " 569.2538976590323,\n",
       " 569.2424790895353,\n",
       " 569.2416007285483,\n",
       " 569.2398440025083,\n",
       " 569.2398440025083,\n",
       " 569.2398440025083,\n",
       " 569.2336954186742,\n",
       " 569.2328170441335,\n",
       " 569.2310602909859,\n",
       " 569.2257899990126,\n",
       " 569.2134924613084,\n",
       " 569.2091004191693,\n",
       " 569.206465177619,\n",
       " 569.2003162332221,\n",
       " 569.1976809510031,\n",
       " 569.1941672223987,\n",
       " 569.1924103499624,\n",
       " 569.1906534721033,\n",
       " 569.1897750311402,\n",
       " 569.1880181451469,\n",
       " 569.183625906438,\n",
       " 569.1783551752474,\n",
       " 569.1713274577348,\n",
       " 569.1669350902247,\n",
       " 569.166056612655,\n",
       " 569.1642996534481,\n",
       " 569.1642996534481,\n",
       " 569.1590287432854,\n",
       " 569.1581502535125,\n",
       " 569.1581502535125,\n",
       " 569.1572717623837,\n",
       " 569.1546362808617,\n",
       " 569.1511222865154,\n",
       " 569.1449727442034,\n",
       " 569.1353090434646,\n",
       " 569.1326734602399,\n",
       " 569.1151025934912,\n",
       " 569.1151025934912,\n",
       " 569.1142240359136,\n",
       " 569.1115883550431,\n",
       " 569.1028026639826,\n",
       " 569.1001669302162,\n",
       " 569.092259655673,\n",
       " 569.0905024686319,\n",
       " 569.0878666778971,\n",
       " 569.0843522712604,\n",
       " 569.0808378429201,\n",
       " 569.0790806206111,\n",
       " 569.0790806206111,\n",
       " 569.0782020074219,\n",
       " 569.0764447769737,\n",
       " 569.072930299799,\n",
       " 569.072930299799,\n",
       " 569.0720516771141,\n",
       " 569.065901280335,\n",
       " 569.0588721740485,\n",
       " 569.0474496911484,\n",
       " 569.0465710291206,\n",
       " 569.0456923657362,\n",
       " 569.0369056572692,\n",
       " 569.0333909358923,\n",
       " 569.0333909358923,\n",
       " 569.0281188131215,\n",
       " 569.0254827334186,\n",
       " 569.0246040374705,\n",
       " 569.0228466415035,\n",
       " 569.0202105373762,\n",
       " 569.0202105373762,\n",
       " 569.0184531278402,\n",
       " 569.0140595802533,\n",
       " 569.0,\n",
       " 568.9973637900267,\n",
       " 568.9929700795959,\n",
       " 568.9789099782171,\n",
       " 568.9745161252831,\n",
       " 568.9718797972357,\n",
       " 568.9701222384177,\n",
       " 568.9692434569728,\n",
       " 568.9692434569728,\n",
       " 568.9683646741706,\n",
       " 568.9683646741706,\n",
       " 568.9657283176202,\n",
       " 568.963091948854,\n",
       " 568.9586979737633,\n",
       " 568.9586979737633,\n",
       " 568.9507887330855,\n",
       " 568.9507887330855,\n",
       " 568.9446370254315,\n",
       " 568.9376064209501,\n",
       " 568.9376064209501,\n",
       " 568.9376064209501,\n",
       " 568.9279391979269,\n",
       " 568.924423803373,\n",
       " 568.9235449513405,\n",
       " 568.9226660979505,\n",
       " 568.9217872432027,\n",
       " 568.9191506708137,\n",
       " 568.9165140862058,\n",
       " 568.9156352219545,\n",
       " 568.9086042590673,\n",
       " 568.9086042590673,\n",
       " 568.9077253825966,\n",
       " 568.9068465047683,\n",
       " 568.894542072606,\n",
       " 568.8936631744108,\n",
       " 568.8910264716785,\n",
       " 568.890147568052,\n",
       " 568.8883897567255,\n",
       " 568.8883897567255,\n",
       " 568.8857530295517,\n",
       " 568.8813584571039,\n",
       " 568.8716902782209,\n",
       " 568.8716902782209,\n",
       " 568.8681745360694,\n",
       " 568.8672955971366,\n",
       " 568.8672955971366,\n",
       " 568.8655377151968,\n",
       " 568.8611429865815,\n",
       " 568.8585061331157,\n",
       " 568.8576271792442,\n",
       " 568.8523534274952,\n",
       " 568.851474464117,\n",
       " 568.8453216824412,\n",
       " 568.8286209395585,\n",
       " 568.8268629381,\n",
       " 568.8251049312082,\n",
       " 568.822467910683,\n",
       " 568.8207098902078,\n",
       " 568.8127987308302,\n",
       " 568.8110406804706,\n",
       " 568.8075245634502,\n",
       " 568.8022503471659,\n",
       " 568.7890645924903,\n",
       " 568.7846692730035,\n",
       " 568.7829111356986,\n",
       " 568.7697249326831,\n",
       " 568.7618130641332,\n",
       " 568.7600548561757,\n",
       " 568.755659312503,\n",
       " 568.7539010855222,\n",
       " 568.7486263719676,\n",
       " 568.7468681232451,\n",
       " 568.7451098690872,\n",
       " 568.7398350739994,\n",
       " 568.7398350739994,\n",
       " 568.7380767980986,\n",
       " 568.7336810845653,\n",
       " 568.7275270285411,\n",
       " 568.7266478722445,\n",
       " 568.7213729059248,\n",
       " 568.7213729059248,\n",
       " 568.7187354044177,\n",
       " 568.7152187167142,\n",
       " 568.7152187167142,\n",
       " 568.7143395413905,\n",
       " 568.7134603647078,\n",
       " 568.7117020072649,\n",
       " 568.7090644609069,\n",
       " 568.702910138501,\n",
       " 568.6985141531495,\n",
       " 568.6853259932069,\n",
       " 568.6826883245172,\n",
       " 568.6800506435934,\n",
       " 568.6774129504354,\n",
       " 568.6774129504354,\n",
       " 568.6738960071932,\n",
       " 568.6738960071932,\n",
       " 568.6712582854879,\n",
       " 568.6712582854879,\n",
       " 568.6686205515476,\n",
       " 568.6686205515476,\n",
       " 568.6659828053723,\n",
       " 568.6651035539282,\n",
       " 568.6589487557546,\n",
       " 568.6580694934347,\n",
       " 568.6580694934347,\n",
       " 568.6545524305595,\n",
       " 568.6545524305595,\n",
       " 568.6536731614419,\n",
       " 568.6501560713757,\n",
       " 568.6466389595563,\n",
       " 568.6404839615274,\n",
       " 568.6369667898844,\n",
       " 568.6360874935745,\n",
       " 568.6352081959049,\n",
       " 568.6352081959049,\n",
       " 568.6352081959049,\n",
       " 568.6334495964866,\n",
       " 568.6325702947379,\n",
       " 568.6281737655988,\n",
       " 568.626415144425,\n",
       " 568.6211392482696,\n",
       " 568.6202599274844,\n",
       " 568.6193806053395,\n",
       " 568.6176219569703,\n",
       " 568.6149839742178,\n",
       " 568.6141046439141,\n",
       " 568.6088286335344,\n",
       " 568.6088286335344,\n",
       " 568.6061906099862,\n",
       " 568.603552574199,\n",
       " 568.5868447299849,\n",
       " 568.5815684666537,\n",
       " 568.5789303166272,\n",
       " 568.5780509305648,\n",
       " 568.5771715431424,\n",
       " 568.5736539798515,\n",
       " 568.5727745856286,\n",
       " 568.5674981917275,\n",
       " 568.5657393828791,\n",
       " 568.5578246757317,\n",
       " 568.5569452570253,\n",
       " 568.5560658369586,\n",
       " 568.5534275685972,\n",
       " 568.5525481430894,\n",
       " 568.5507892879932,\n",
       " 568.5499098584046,\n",
       " 568.5490304274557,\n",
       " 568.5490304274557,\n",
       " 568.5490304274557,\n",
       " 568.5490304274557,\n",
       " 568.5481509951466,\n",
       " 568.5463921264474,\n",
       " 568.5419949308933,\n",
       " 568.5411154877015,\n",
       " 568.5402360431493,\n",
       " 568.5384771499639,\n",
       " 568.5375977013306,\n",
       " 568.5314415228062,\n",
       " 568.5305620632896,\n",
       " 568.5288031401751,\n",
       " 568.5200084429747,\n",
       " 568.5173700072849,\n",
       " 568.5173700072849,\n",
       " 568.5147315593501,\n",
       " 568.5103341189147,\n",
       " 568.5024186404136,\n",
       " 568.5006596302242,\n",
       " 568.4953825670003,\n",
       " 568.4874668803175,\n",
       " 568.4865873527713,\n",
       " 568.4821896946289,\n",
       " 568.4804306218465,\n",
       " 568.4795510834141,\n",
       " 568.4786715436209,\n",
       " 568.4777920024669,\n",
       " 568.476912459952,\n",
       " 568.4760329160764,\n",
       " 568.4707556242449,\n",
       " 568.4681169599576,\n",
       " 568.4637191589275,\n",
       " 568.4593213238745,\n",
       " 568.4593213238745,\n",
       " 568.458441752781,\n",
       " 568.4575621803267,\n",
       " 568.45228471702,\n",
       " 568.4514051350388,\n",
       " 568.4496459669933,\n",
       " 568.4452480230616,\n",
       " 568.4443684301921,\n",
       " 568.4443684301921,\n",
       " 568.44260924037,\n",
       " 568.4417296434174,\n",
       " 568.4390908443929,\n",
       " 568.4355724266384,\n",
       " 568.4346928187969,\n",
       " 568.4329335990307,\n",
       " 568.4329335990307,\n",
       " 568.4329335990307,\n",
       " 568.4276559070644,\n",
       " 568.4214985378368,\n",
       " 568.4206189082166,\n",
       " 568.4197392772352,\n",
       " 568.4171003761235,\n",
       " 568.4153411019093,\n",
       " 568.410942892552,\n",
       " 568.410942892552,\n",
       " 568.4083039506021,\n",
       " 568.4056649964002,\n",
       " 568.4056649964002,\n",
       " 568.4012667121705,\n",
       " 568.3995073889491,\n",
       " 568.3986277252964,\n",
       " 568.3959887261697,\n",
       " 568.3942293866115,\n",
       " 568.3933497147904,\n",
       " 568.3898310138914,\n",
       " 568.3836732349022,\n",
       " 568.3836732349022,\n",
       " 568.3827935467434,\n",
       " 568.3801544740984,\n",
       " 568.3757559924596,\n",
       " 568.3731168871378,\n",
       " 568.3713574767821,\n",
       " 568.3687183510366,\n",
       " 568.3660792130368,\n",
       " 568.3651994976469,\n",
       " 568.3643197808955,\n",
       " 568.3537630736688,\n",
       " 568.3537630736688,\n",
       " 568.3493643877857,\n",
       " 568.3440859197885,\n",
       " 568.342326419562,\n",
       " 568.3388074027674,\n",
       " 568.3352883641838,\n",
       " 568.3352883641838,\n",
       " 568.333528836721,\n",
       " 568.3326490709468,\n",
       " 568.3317693038108,\n",
       " 568.3308895353128,\n",
       " 568.3256108957258,\n",
       " 568.3256108957258,\n",
       " 568.3238513383017,\n",
       " 568.3150534694643,\n",
       " 568.3106544839715,\n",
       " 568.3106544839715,\n",
       " 568.3097746827868,\n",
       " 568.3071352710609,\n",
       " 568.3062554644283,\n",
       " 568.3062554644283,\n",
       " 568.3044958470767,\n",
       " 568.3036160363578,\n",
       " 568.3027362242768,\n",
       " 568.3009765960287,\n",
       " 568.3000967798615,\n",
       " 568.295697678594,\n",
       " 568.2930582014882,\n",
       " 568.2904187121229,\n",
       " 568.28338001388,\n",
       " 568.2816203256973,\n",
       " 568.2807404795626,\n",
       " 568.2763412284555,\n",
       " 568.2719419432918,\n",
       " 568.2684224906395,\n",
       " 568.2666627561396,\n",
       " 568.2666627561396,\n",
       " 568.2666627561396,\n",
       " 568.2649030161901,\n",
       " 568.2622633960485,\n",
       " 568.2605036424756,\n",
       " 568.2578640018984,\n",
       " 568.2569841189811,\n",
       " 568.2561042347015,\n",
       " 568.2543444620551,\n",
       " 568.2499450065966,\n",
       " 568.2464254177056,\n",
       " 568.2464254177056,\n",
       " 568.2437857117313,\n",
       " 568.242905807015,\n",
       " 568.242025900936,\n",
       " 568.2402660846906,\n",
       " 568.2376263501036,\n",
       " 568.2367464358496,\n",
       " 568.2367464358496,\n",
       " 568.234106684912,\n",
       " 568.2332267652077,\n",
       " 568.2305869979193,\n",
       " 568.2305869979193,\n",
       " 568.2297070727648,\n",
       " 568.2297070727648,\n",
       " 568.2297070727648,\n",
       " 568.2288271462475,\n",
       " 568.2270672891252,\n",
       " 568.2253074265524,\n",
       " 568.2235475585292,\n",
       " 568.2235475585292,\n",
       " 568.2226676224735,\n",
       " 568.2209077462743,\n",
       " 568.2200278061307,\n",
       " 568.2165080319297,\n",
       " 568.2121082835176,\n",
       " 568.2103483746138,\n",
       " 568.2103483746138,\n",
       " 568.2041886505237,\n",
       " 568.2033086844884,\n",
       " 568.2033086844884,\n",
       " 568.2024287170902,\n",
       " 568.1980288596574,\n",
       " 568.1980288596574,\n",
       " 568.1971488840824,\n",
       " 568.1971488840824,\n",
       " 568.1962689071445,\n",
       " 568.1918690020124,\n",
       " 568.1909890168973,\n",
       " 568.1909890168973,\n",
       " 568.1848290829314,\n",
       " 568.1839490869132,\n",
       " 568.182189090788,\n",
       " 568.181309090681,\n",
       " 568.181309090681,\n",
       " 568.1804290892111,\n",
       " 568.1804290892111,\n",
       " 568.1795490863782,\n",
       " 568.1786690821823,\n",
       " 568.1689889460705,\n",
       " 568.1681089255186,\n",
       " 568.1681089255186,\n",
       " 568.1663488803257,\n",
       " 568.1663488803257,\n",
       " 568.1637088023134,\n",
       " 568.1619487434899,\n",
       " 568.160188679214,\n",
       " 568.1593086450314,\n",
       " 568.1584286094857,\n",
       " 568.1549084536716,\n",
       " 568.1522683224982,\n",
       " 568.1513882760474,\n",
       " 568.1478680766126,\n",
       " 568.1461079687161,\n",
       " 568.1434677966473,\n",
       " 568.1390674826015,\n",
       " 568.1381874157025,\n",
       " 568.1364272778151,\n",
       " 568.1364272778151,\n",
       " 568.1346671344744,\n",
       " 568.1337870607591,\n",
       " 568.1320269092388,\n",
       " 568.1293866717334,\n",
       " 568.1293866717334,\n",
       " 568.1285065898384,\n",
       " 568.1258663359731,\n",
       " 568.1258663359731,\n",
       " 568.1249862486247,\n",
       " 568.1197056959035,\n",
       " 568.1188255990114,\n",
       " 568.1126648825917,\n",
       " 568.1073842153436,\n",
       " 568.1047438633126,\n",
       " 568.0985829941842,\n",
       " 568.0977028645689,\n",
       " 568.09682273359,\n",
       " 568.09682273359,\n",
       " 568.0959426012475,\n",
       " 568.0950624675417,\n",
       " 568.093302196039,\n",
       " 568.0915419190819,\n",
       " 568.090661778558,\n",
       " 568.0889014934194,\n",
       " 568.0889014934194,\n",
       " 568.0889014934194,\n",
       " 568.0880213488047,\n",
       " 568.0871412028264,\n",
       " 568.0871412028264,\n",
       " 568.0853809067788,\n",
       " 568.0845007567096,\n",
       " 568.0818602983201,\n",
       " 568.0809801427962,\n",
       " 568.0765793447218,\n",
       " 568.0756991810158,\n",
       " 568.0739388495128,\n",
       " 568.0739388495128,\n",
       " 568.0730586817157,\n",
       " 568.0686578222742,\n",
       " 568.0651371101733,\n",
       " 568.062496561778,\n",
       " 568.060736189362,\n",
       " 568.0598560011084,\n",
       " 568.0554550393825,\n",
       " 568.0554550393825,\n",
       " 568.0545748429458,\n",
       " 568.0510540435604,\n",
       " 568.0501738403044,\n",
       " 568.0501738403044,\n",
       " 568.0492936356844,\n",
       " 568.038731073859,\n",
       " 568.037850851508,\n",
       " 568.0308090235951,\n",
       " 568.0264078368187,\n",
       " 568.0255275953714,\n",
       " 568.0255275953714,\n",
       " 568.0255275953714,\n",
       " 568.0246473525599,\n",
       " 568.019365867045,\n",
       " 568.0140843324222,\n",
       " 568.0132040718772,\n",
       " 568.012323809968,\n",
       " 568.0096830160556,\n",
       " 568.0096830160556,\n",
       " 568.0088027486898,\n",
       " 568.0061619384071,\n",
       " 568.0061619384071,\n",
       " 568.0052816655846,\n",
       " 568.0052816655846,\n",
       " 568.000880281008,\n",
       " 567.9982394338912,\n",
       " 567.9964788623254,\n",
       " 567.9938379947445,\n",
       " 567.9920774095357,\n",
       " 567.9885562227464,\n",
       " 567.9867956211658,\n",
       " 567.985915318329,\n",
       " 567.9850350141278,\n",
       " 567.9850350141278,\n",
       " 567.9815137836794,\n",
       " 567.9815137836794,\n",
       " 567.9806334726563,\n",
       " 567.979753160269,\n",
       " 567.9753515778656,\n",
       " 567.9753515778656,\n",
       " 567.9744712572916,\n",
       " 567.9709499613515,\n",
       " 567.9700696339553,\n",
       " 567.9691893051946,\n",
       " 567.9691893051946,\n",
       " 567.9683089750695,\n",
       " 567.9656679765072,\n",
       " 567.9656679765072,\n",
       " 567.9630269656644,\n",
       " 567.9630269656644,\n",
       " 567.9612662849465,\n",
       " 567.9595055987706,\n",
       " 567.9577449071365,\n",
       " 567.9568645592726,\n",
       " 567.9568645592726,\n",
       " 567.9551038594512,\n",
       " 567.9533431541714,\n",
       " 567.9515824434333,\n",
       " 567.9507020860174,\n",
       " 567.9489413670916,\n",
       " 567.9445395458962,\n",
       " 567.9436591775632,\n",
       " 567.9436591775632,\n",
       " 567.9436591775632,\n",
       " 567.9427788078655,\n",
       " 567.9427788078655,\n",
       " 567.9418984368032,\n",
       " 567.9366161817708,\n",
       " 567.9330946511218,\n",
       " 567.9313338776088,\n",
       " 567.9286927071039,\n",
       " 567.927812314206,\n",
       " 567.927812314206,\n",
       " 567.9269319199434,\n",
       " 567.9242907289668,\n",
       " 567.923410329245,\n",
       " 567.921649525707,\n",
       " 567.9198887167098,\n",
       " 567.9190083101639,\n",
       " 567.9181279022532,\n",
       " 567.9163670823373,\n",
       " 567.9154866703319,\n",
       " 567.9154866703319,\n",
       " 567.9146062569619,\n",
       " 567.912845426127,\n",
       " 567.9119650086623,\n",
       " 567.9110845898326,\n",
       " 567.9040411900588,\n",
       " 567.902280326466,\n",
       " 567.8978781435973,\n",
       " 567.8969977029285,\n",
       " 567.8943563727324,\n",
       " 567.8943563727324,\n",
       " 567.8934759266037,\n",
       " 567.8934759266037,\n",
       " 567.8934759266037,\n",
       " 567.8925954791099,\n",
       " 567.8925954791099,\n",
       " 567.8917150302511,\n",
       " 567.8917150302511,\n",
       " 567.8908345800273,\n",
       " 567.8899541284385,\n",
       " 567.8890736754846,\n",
       " 567.8846713902392,\n",
       " 567.883790929095,\n",
       " 567.8785081335619,\n",
       " 567.8767471907967,\n",
       " 567.8758667173663,\n",
       " 567.8741057664101,\n",
       " 567.8679423950607,\n",
       " 567.8661814195312,\n",
       " 567.864420438541,\n",
       " 567.864420438541,\n",
       " 567.8635399459979,\n",
       " 567.8626594520897,\n",
       " 567.8626594520897,\n",
       " 567.8617789568162,\n",
       " 567.8608984601775,\n",
       " 567.8591374628043,\n",
       " 567.8582569620697,\n",
       " 567.8564959565049,\n",
       " 567.8556154516745,\n",
       " 567.8556154516745,\n",
       " 567.8547349454789,\n",
       " 567.8547349454789,\n",
       " 567.8529739289916,\n",
       " 567.8512129070431,\n",
       " 567.8512129070431,\n",
       " 567.8476908467621,\n",
       " 567.8476908467621,\n",
       " 567.8468103282786,\n",
       " 567.8459298084297,\n",
       " 567.8432882406905,\n",
       " 567.8424077153801,\n",
       " 567.8415271887043,\n",
       " 567.8397661312564,\n",
       " 567.8318413051526,\n",
       " 567.8274385761928,\n",
       " 567.8256774750504,\n",
       " 567.8256774750504,\n",
       " 567.8256774750504,\n",
       " 567.824796922431,\n",
       " 567.8230358130955,\n",
       " 567.8177524523163,\n",
       " 567.816871887407,\n",
       " 567.8159913211322,\n",
       " 567.8124690423767,\n",
       " 567.8098273189713,\n",
       " 567.8080661632063,\n",
       " 567.8045438352884,\n",
       " 567.8027826631356,\n",
       " 567.8027826631356,\n",
       " 567.8027826631356,\n",
       " 567.7992603024418,\n",
       " 567.7992603024418,\n",
       " 567.7983797088541,\n",
       " 567.7922155155,\n",
       " 567.7913349109865,\n",
       " 567.7913349109865,\n",
       " 567.7895736978621,\n",
       " 567.7895736978621,\n",
       " 567.7886930892513,\n",
       " 567.7869318679323,\n",
       " 567.7825287907334,\n",
       " 567.7772450530225,\n",
       " 567.7763644252902,\n",
       " 567.7754837961921,\n",
       " 567.7746031657281,\n",
       " 567.7710806302132,\n",
       " 567.7675580728437,\n",
       " 567.7666774300866,\n",
       " 567.7622741958116,\n",
       " 567.76051289254,\n",
       " 567.7596322388551,\n",
       " 567.7578709273874,\n",
       " 567.7578709273874,\n",
       " 567.7561096104558,\n",
       " 567.755228949941,\n",
       " 567.7543482880602,\n",
       " 567.7543482880602,\n",
       " 567.7543482880602,\n",
       " 567.7534676248133,\n",
       " 567.7534676248133,\n",
       " 567.7534676248133,\n",
       " 567.7490642880884,\n",
       " 567.7481836166453,\n",
       " 567.7464222696608,\n",
       " 567.7437802389384,\n",
       " 567.7402575121831,\n",
       " 567.7358540730011,\n",
       " 567.7340926877653,\n",
       " 567.733211993098,\n",
       " 567.7323312970647,\n",
       " 567.7314505996651,\n",
       " 567.7296892007674,\n",
       " 567.7296892007674,\n",
       " 567.7288084992693,\n",
       " 567.7288084992693,\n",
       " 567.7261663865776,\n",
       " 567.7235242615899,\n",
       " 567.7235242615899,\n",
       " 567.7226435505281,\n",
       " 567.7226435505281,\n",
       " 567.7217628381002,\n",
       " 567.7217628381002,\n",
       " 567.7208821243058,\n",
       " 567.7191206926186,\n",
       " 567.7182399747255,\n",
       " 567.7182399747255,\n",
       " 567.7147170894903,\n",
       " 567.7120749112177,\n",
       " 567.7111941823941,\n",
       " 567.7103134522042,\n",
       " 567.709432720648,\n",
       " 567.7076712534366,\n",
       " 567.7067905177813,\n",
       " 567.7067905177813,\n",
       " 567.7041483026172,\n",
       " 567.7032675614964,\n",
       " 567.7023868190092,\n",
       " 567.7006253299356,\n",
       " 567.6997445833492,\n",
       " 567.6997445833492,\n",
       " 567.6935793189843,\n",
       " 567.6935793189843,\n",
       " 567.691817802582,\n",
       " 567.6900562807137,\n",
       " 567.68917551773,\n",
       " 567.68917551773,\n",
       " 567.6865332205793,\n",
       " 567.6856524521295,\n",
       " 567.6847716823131,\n",
       " 567.6838909111302,\n",
       " 567.6838909111302,\n",
       " 567.6830101385808,\n",
       " 567.6812485893822,\n",
       " 567.6794870347175,\n",
       " 567.6786062553352,\n",
       " 567.6759639089892,\n",
       " 567.6750831241407,\n",
       " 567.6733215503438,\n",
       " 567.6724407613955,\n",
       " 567.6724407613955,\n",
       " 567.6715599710805,\n",
       " 567.6706791793989,\n",
       " 567.6689175919358,\n",
       " 567.6671559990061,\n",
       " 567.6671559990061,\n",
       " 567.6662752004913,\n",
       " 567.6653944006099,\n",
       " 567.663632796747,\n",
       " 567.663632796747,\n",
       " 567.6627519927655,\n",
       " 567.6618711874173,\n",
       " 567.660109572621,\n",
       " 567.660109572621,\n",
       " 567.657467140176,\n",
       " 567.6565863266276,\n",
       " 567.6548246954305,\n",
       " 567.6513014166355,\n",
       " 567.6504205935198,\n",
       " 567.6477781159722,\n",
       " 567.6442547934402,\n",
       " 567.6433739593901,\n",
       " 567.6416122871896,\n",
       " 567.6345655437132,\n",
       " 567.6345655437132,\n",
       " 567.6336846946277,\n",
       " 567.6328038441753,\n",
       " 567.6301612846167,\n",
       " 567.6292804286967,\n",
       " 567.6283995714098,\n",
       " 567.6257569913472,\n",
       " 567.6257569913472,\n",
       " 567.6257569913472,\n",
       " 567.6248761285925,\n",
       " 567.6222335321265,\n",
       " 567.6195909233578,\n",
       " 567.6178291773435,\n",
       " 567.614305668911,\n",
       " 567.614305668911,\n",
       " 567.6125439064926,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(result_l2_1[0],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compare_representations(testarr_one_sample, testarr_waiting_to_compare,testarr_waiting_to_compare_label, MODEL, similarity_method = 'minkowski_similarity', minkowski_power = 2):\n",
    "    arr_KNN_from_same_class_ratio = []\n",
    "    arr_KNN_max_class_label = []\n",
    "    testarr_waiting_to_compare = testarr_waiting_to_compare[:5000]\n",
    "    testarr_waiting_to_compare_label = testarr_waiting_to_compare_label[:5000].reshape(5000)\n",
    "    for j in range(500):\n",
    "        #print(\"current sample: \", j)\n",
    "        k = 50\n",
    "        testarr_one_sample_1 = [testarr_one_sample[j]]\n",
    "        result_l2 = get_KNN_in_pixel_representation(testarr_one_sample_1, testarr_waiting_to_compare,\n",
    "                                                    testarr_waiting_to_compare_label, similarity_method = 'minkowski_similarity', minkowski_power = 2)\n",
    "        arr_KNN_from_same_class_ratio.append(result_l2[4])\n",
    "        arr_KNN_max_class_label.append(result_l2[5])\n",
    "    #print(np.mean(arr_KNN_from_same_class_ratio))\n",
    "    pred_labels = MODEL.predict(testarr_one_sample[:500])\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],})\n",
    "    return arr_KNN_from_same_class_ratio, arr_KNN_max_class_label, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>0.936445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.581013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.736561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.719364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.535689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.355403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.319031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.398565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4</td>\n",
       "      <td>0.867571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.953476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.565680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.861063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.352718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>0.866001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.638459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.475814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.931620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.836886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.304493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>7</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.286438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.590402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.560168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.843513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.658360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>3</td>\n",
       "      <td>0.44</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.745595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.930719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.444094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4</td>\n",
       "      <td>0.313472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.969979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.835719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.960389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>7</td>\n",
       "      <td>0.613408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.383262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>7</td>\n",
       "      <td>0.810093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.592646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          9                           0.24                4   \n",
       "1                          2                           0.26                4   \n",
       "2                          0                           0.24                7   \n",
       "3                          3                           0.24                7   \n",
       "4                          7                           0.40                4   \n",
       "5                          2                           0.28                4   \n",
       "6                          0                           0.32                7   \n",
       "7                          0                           0.26                3   \n",
       "8                          4                           0.28                2   \n",
       "9                          2                           0.22                7   \n",
       "10                         8                           0.24                1   \n",
       "11                         5                           0.22                5   \n",
       "12                         6                           0.30                5   \n",
       "13                         0                           0.44                4   \n",
       "14                         8                           0.36                1   \n",
       "15                         0                           0.38                7   \n",
       "16                         8                           0.24                7   \n",
       "17                         8                           0.36                6   \n",
       "18                         0                           0.18                1   \n",
       "19                         7                           0.40                2   \n",
       "20                         0                           0.36                3   \n",
       "21                         7                           0.44                2   \n",
       "22                         3                           0.26                4   \n",
       "23                         0                           0.32                7   \n",
       "24                         0                           0.36                1   \n",
       "25                         4                           0.44                0   \n",
       "26                         0                           0.64                1   \n",
       "27                         0                           0.32                1   \n",
       "28                         0                           0.36                0   \n",
       "29                         3                           0.50                7   \n",
       "..                       ...                            ...              ...   \n",
       "470                        3                           0.26                7   \n",
       "471                        8                           0.22                4   \n",
       "472                        2                           0.22                3   \n",
       "473                        0                           0.36                3   \n",
       "474                        7                           0.58                1   \n",
       "475                        0                           0.38                5   \n",
       "476                        4                           0.26                4   \n",
       "477                        2                           0.36                7   \n",
       "478                        2                           0.26                7   \n",
       "479                        2                           0.28                2   \n",
       "480                        0                           0.32                0   \n",
       "481                        5                           0.18                5   \n",
       "482                        0                           0.52                4   \n",
       "483                        3                           0.44                7   \n",
       "484                        3                           0.24                0   \n",
       "485                        2                           0.34                7   \n",
       "486                        5                           0.22                4   \n",
       "487                        8                           0.20                7   \n",
       "488                        7                           0.24                3   \n",
       "489                        3                           0.38                1   \n",
       "490                        0                           0.52                4   \n",
       "491                        2                           0.26                2   \n",
       "492                        2                           0.20                4   \n",
       "493                        6                           0.30                7   \n",
       "494                        4                           0.36                0   \n",
       "495                        1                           0.64                7   \n",
       "496                        0                           0.82                7   \n",
       "497                        3                           0.20                8   \n",
       "498                        3                           0.40                7   \n",
       "499                        8                           0.30                7   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.929314  \n",
       "1          0.936445  \n",
       "2          0.826902  \n",
       "3          0.581013  \n",
       "4          0.736561  \n",
       "5          0.719364  \n",
       "6          0.977451  \n",
       "7          0.535689  \n",
       "8          0.355403  \n",
       "9          0.978295  \n",
       "10         0.999878  \n",
       "11         0.319031  \n",
       "12         0.398565  \n",
       "13         0.867571  \n",
       "14         0.571284  \n",
       "15         0.700361  \n",
       "16         0.953476  \n",
       "17         0.565680  \n",
       "18         0.586859  \n",
       "19         0.861063  \n",
       "20         0.352718  \n",
       "21         0.769659  \n",
       "22         0.866001  \n",
       "23         0.638459  \n",
       "24         0.919475  \n",
       "25         0.542364  \n",
       "26         0.865885  \n",
       "27         0.994988  \n",
       "28         0.955677  \n",
       "29         0.475814  \n",
       "..              ...  \n",
       "470        0.931620  \n",
       "471        0.992734  \n",
       "472        0.836886  \n",
       "473        0.304493  \n",
       "474        0.940468  \n",
       "475        0.580060  \n",
       "476        0.693151  \n",
       "477        0.286438  \n",
       "478        0.590402  \n",
       "479        0.560168  \n",
       "480        0.843513  \n",
       "481        0.658360  \n",
       "482        0.891211  \n",
       "483        0.977816  \n",
       "484        0.249762  \n",
       "485        0.745595  \n",
       "486        0.934103  \n",
       "487        0.930719  \n",
       "488        0.444094  \n",
       "489        0.814977  \n",
       "490        0.313472  \n",
       "491        0.969979  \n",
       "492        0.469047  \n",
       "493        0.835719  \n",
       "494        0.907276  \n",
       "495        0.960389  \n",
       "496        0.613408  \n",
       "497        0.383262  \n",
       "498        0.810093  \n",
       "499        0.592646  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_representations(C_x_train,mnist_train_RGB_x,M_train_y,M_VGG_Model1)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel representation\n",
    "k = 50\n",
    "testarr_one_sample_2 = [mnist_train_RGB_x[0]]\n",
    "testarr_waiting_to_compare_2 = [C_x_train[i] for i in range(5000)]\n",
    "testarr_waiting_to_compare_label_2 = C_y_train[:5000].reshape(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_l2_2 = get_KNN_in_pixel_representation(testarr_one_sample_2, testarr_waiting_to_compare_2, testarr_waiting_to_compare_label_2, similarity_method = 'minkowski_similarity', minkowski_power = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 16, 2: 10, 3: 5, 9: 1, 6: 5, 8: 5, 4: 3, 1: 1, 5: 4})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_l2_2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_l2_2[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[637.5523507916821,\n",
       " 626.76630413576,\n",
       " 622.0112539174834,\n",
       " 621.6823947965713,\n",
       " 618.6840873984072,\n",
       " 617.7369990538044,\n",
       " 616.644143732834,\n",
       " 615.3429937847671,\n",
       " 610.7470834969251,\n",
       " 608.2902267832354,\n",
       " 607.720330415233,\n",
       " 607.5541128162988,\n",
       " 607.1326049554579,\n",
       " 606.2821125515744,\n",
       " 606.0033003210461,\n",
       " 605.9009820094369,\n",
       " 605.5551172271604,\n",
       " 604.4683614549234,\n",
       " 603.7557453142786,\n",
       " 603.5983764060337,\n",
       " 603.264452789985,\n",
       " 602.7105441254533,\n",
       " 600.6546428689285,\n",
       " 600.1741413956453,\n",
       " 600.0549974793977,\n",
       " 599.9091597900468,\n",
       " 599.769122246219,\n",
       " 599.7632866389872,\n",
       " 599.7574509749754,\n",
       " 599.7516152541817,\n",
       " 599.6649064269144,\n",
       " 599.5681779414248,\n",
       " 599.1719285814381,\n",
       " 599.1393827816696,\n",
       " 599.0158595563227,\n",
       " 598.8722735275027,\n",
       " 598.8180024013974,\n",
       " 598.7127858998837,\n",
       " 598.5423961592028,\n",
       " 598.5031328238808,\n",
       " 598.4504992060747,\n",
       " 598.3761358877875,\n",
       " 598.3076131890684,\n",
       " 598.2967491136819,\n",
       " 598.1805747431122,\n",
       " 598.0158860766159,\n",
       " 597.7767141667531,\n",
       " 597.7633310935023,\n",
       " 597.6754972390954,\n",
       " 597.5809568585665,\n",
       " 597.4445580972347,\n",
       " 597.324032665688,\n",
       " 597.3123136182612,\n",
       " 597.1783653147525,\n",
       " 597.117241419137,\n",
       " 597.0954697533721,\n",
       " 597.0494116905234,\n",
       " 596.9363450151113,\n",
       " 596.8090146772248,\n",
       " 596.7034439317407,\n",
       " 596.5509198718916,\n",
       " 596.481349247401,\n",
       " 596.429375534103,\n",
       " 596.4218305863728,\n",
       " 596.3287683820058,\n",
       " 596.2658802916699,\n",
       " 596.1073728784103,\n",
       " 596.0964687028435,\n",
       " 595.9706368605755,\n",
       " 595.9135843392061,\n",
       " 595.7214113996575,\n",
       " 595.6886770788916,\n",
       " 595.6844802410081,\n",
       " 595.5719939688232,\n",
       " 595.5434492965228,\n",
       " 595.5165824727302,\n",
       " 595.3881087156511,\n",
       " 595.2394476175114,\n",
       " 595.0823472427996,\n",
       " 595.0260498499205,\n",
       " 594.9966386459674,\n",
       " 594.7957632666863,\n",
       " 594.7898788647971,\n",
       " 594.758774630522,\n",
       " 594.7335537869038,\n",
       " 594.6957205159626,\n",
       " 594.6461132471985,\n",
       " 594.6267736992676,\n",
       " 594.620887625048,\n",
       " 594.6023881553117,\n",
       " 594.5981836501016,\n",
       " 594.5603417652409,\n",
       " 594.3618426514273,\n",
       " 594.3416525871294,\n",
       " 594.3256682997967,\n",
       " 594.3021117243317,\n",
       " 594.2541543817763,\n",
       " 594.2078760837827,\n",
       " 594.170009340761,\n",
       " 594.1666432912572,\n",
       " 594.0462944922728,\n",
       " 594.0336690794554,\n",
       " 594.0303022573848,\n",
       " 594.0227268379552,\n",
       " 594.0210433982958,\n",
       " 593.9654872128515,\n",
       " 593.9048745380021,\n",
       " 593.8678304134684,\n",
       " 593.7465789375127,\n",
       " 593.701103249775,\n",
       " 593.7002610745594,\n",
       " 593.6800485109803,\n",
       " 593.6598352592165,\n",
       " 593.6497283752432,\n",
       " 593.6438326134619,\n",
       " 593.5806600623035,\n",
       " 593.574763614492,\n",
       " 593.5705518301932,\n",
       " 593.5427533042587,\n",
       " 593.5040016714294,\n",
       " 593.4458694775792,\n",
       " 593.4399716904819,\n",
       " 593.3860463475696,\n",
       " 593.2882941707177,\n",
       " 593.1829397411898,\n",
       " 593.1627095494119,\n",
       " 593.1559659988256,\n",
       " 593.1458505291932,\n",
       " 593.1348919090833,\n",
       " 593.0952705931821,\n",
       " 593.0657636384012,\n",
       " 593.0320396066304,\n",
       " 593.0252945701388,\n",
       " 592.9418183936768,\n",
       " 592.898810928138,\n",
       " 592.8945943420298,\n",
       " 592.8735109616553,\n",
       " 592.8692941956093,\n",
       " 592.8364023910813,\n",
       " 592.8254380506963,\n",
       " 592.7107220221345,\n",
       " 592.692162931146,\n",
       " 592.6803522979313,\n",
       " 592.6364821709848,\n",
       " 592.6255141318167,\n",
       " 592.6238267231583,\n",
       " 592.6196081804922,\n",
       " 592.5942962938473,\n",
       " 592.5917650457185,\n",
       " 592.5875462748099,\n",
       " 592.570670890823,\n",
       " 592.561389224779,\n",
       " 592.5175102897804,\n",
       " 592.4736281050829,\n",
       " 592.4626570510584,\n",
       " 592.3487148631285,\n",
       " 592.3233914003397,\n",
       " 592.3174824365731,\n",
       " 592.2237752741779,\n",
       " 592.1933805776623,\n",
       " 592.1705835314685,\n",
       " 592.1359641163506,\n",
       " 592.1342753126186,\n",
       " 592.1216091310973,\n",
       " 592.1165425826237,\n",
       " 592.0920536538216,\n",
       " 592.0878313223469,\n",
       " 592.0278709655483,\n",
       " 591.9189133656738,\n",
       " 591.9163792293638,\n",
       " 591.8699181408023,\n",
       " 591.7981074657133,\n",
       " 591.7516370911026,\n",
       " 591.7347378682445,\n",
       " 591.6476992264907,\n",
       " 591.6164297921416,\n",
       " 591.5521954992645,\n",
       " 591.5496597919738,\n",
       " 591.5437430993586,\n",
       " 591.5065511048884,\n",
       " 591.465129994998,\n",
       " 591.4042610600637,\n",
       " 591.390733779284,\n",
       " 591.386506440585,\n",
       " 591.3619872802107,\n",
       " 591.3467679796686,\n",
       " 591.3416947924441,\n",
       " 591.3281660803923,\n",
       " 591.3129459093552,\n",
       " 591.2943429460491,\n",
       " 591.19878213677,\n",
       " 591.1767925079604,\n",
       " 591.1556478627266,\n",
       " 591.1175855952857,\n",
       " 591.1099728476927,\n",
       " 591.0617565026517,\n",
       " 591.0287641054367,\n",
       " 591.0042301033047,\n",
       " 590.9585433852361,\n",
       " 590.8299247668486,\n",
       " 590.807075109972,\n",
       " 590.7977657371429,\n",
       " 590.7292103832348,\n",
       " 590.6428701000292,\n",
       " 590.6369443236682,\n",
       " 590.6352512337882,\n",
       " 590.6327115898679,\n",
       " 590.6242460312648,\n",
       " 590.6200132064608,\n",
       " 590.6183200680453,\n",
       " 590.479466196751,\n",
       " 590.4786194266478,\n",
       " 590.45999017715,\n",
       " 590.4413603398732,\n",
       " 590.4354325411035,\n",
       " 590.4303515233613,\n",
       " 590.4295046828198,\n",
       " 590.3397326963517,\n",
       " 590.3177110675234,\n",
       " 590.3050059079628,\n",
       " 590.303311866027,\n",
       " 590.2711241455065,\n",
       " 590.2253806809734,\n",
       " 590.2067434382633,\n",
       " 590.1872584188852,\n",
       " 590.1847168471918,\n",
       " 590.1821752645534,\n",
       " 590.1711616133069,\n",
       " 590.1694671871801,\n",
       " 590.1474392048143,\n",
       " 590.1338831146709,\n",
       " 590.1101592075839,\n",
       " 590.0347447396637,\n",
       " 590.014406603771,\n",
       " 590.0025423674037,\n",
       " 589.9542355132303,\n",
       " 589.9381323494863,\n",
       " 589.9160957288757,\n",
       " 589.9025343224082,\n",
       " 589.9025343224082,\n",
       " 589.8838868794434,\n",
       " 589.8711723757993,\n",
       " 589.8474379023783,\n",
       " 589.8457425463034,\n",
       " 589.8126821288264,\n",
       " 589.7965751002629,\n",
       " 589.7965751002629,\n",
       " 589.7923363354258,\n",
       " 589.7838587143599,\n",
       " 589.7635119266026,\n",
       " 589.7321425867849,\n",
       " 589.729599053668,\n",
       " 589.7016194653021,\n",
       " 589.6677030328183,\n",
       " 589.6600715666611,\n",
       " 589.6414164557982,\n",
       " 589.6414164557982,\n",
       " 589.6286967236246,\n",
       " 589.6227607547049,\n",
       " 589.6074965602116,\n",
       " 589.593080013665,\n",
       " 589.59138392619,\n",
       " 589.5650939463767,\n",
       " 589.5540687672336,\n",
       " 589.5532206679902,\n",
       " 589.5447396084542,\n",
       " 589.5184475485055,\n",
       " 589.4946988735353,\n",
       " 589.4658599104786,\n",
       " 589.4599223017626,\n",
       " 589.4497434048131,\n",
       " 589.4463504001021,\n",
       " 589.4327781859438,\n",
       " 589.406481131655,\n",
       " 589.3971496368132,\n",
       " 589.3971496368132,\n",
       " 589.3810312522791,\n",
       " 589.3615189338374,\n",
       " 589.3538835029426,\n",
       " 589.3403091593176,\n",
       " 589.33521869985,\n",
       " 589.329279774898,\n",
       " 589.3029781020965,\n",
       " 589.2944934410978,\n",
       " 589.2843116866425,\n",
       " 589.261402095878,\n",
       " 589.184181729279,\n",
       " 589.1816358305815,\n",
       " 589.1629655706475,\n",
       " 589.1425973395575,\n",
       " 589.132412959939,\n",
       " 589.1256232757153,\n",
       " 589.1128924068798,\n",
       " 589.1111949369151,\n",
       " 589.1001612629213,\n",
       " 589.0984637562723,\n",
       " 589.0891273822663,\n",
       " 589.0331060305524,\n",
       " 589.0212220285446,\n",
       " 589.0161288114274,\n",
       " 588.9915109744792,\n",
       " 588.9898131546929,\n",
       " 588.9507619487388,\n",
       " 588.9456681222811,\n",
       " 588.9431211925307,\n",
       " 588.9422722134997,\n",
       " 588.9193493170351,\n",
       " 588.9032178550224,\n",
       " 588.9032178550224,\n",
       " 588.9015197806846,\n",
       " 588.8718026871384,\n",
       " 588.8539717111536,\n",
       " 588.8514243847934,\n",
       " 588.8514243847934,\n",
       " 588.8463296990141,\n",
       " 588.8412349691554,\n",
       " 588.8378384580936,\n",
       " 588.8140623320744,\n",
       " 588.7894360465377,\n",
       " 588.7631102574277,\n",
       " 588.7537685654335,\n",
       " 588.7265918913464,\n",
       " 588.7113044608537,\n",
       " 588.6526989660372,\n",
       " 588.6374096164803,\n",
       " 588.6280659295817,\n",
       " 588.6008834515966,\n",
       " 588.5838937653663,\n",
       " 588.5745492288976,\n",
       " 588.5499129215805,\n",
       " 588.5295234735468,\n",
       " 588.4972387360879,\n",
       " 588.4887424581714,\n",
       " 588.4878928236332,\n",
       " 588.4666515614967,\n",
       " 588.442010736827,\n",
       " 588.4173688802872,\n",
       " 588.3952753039406,\n",
       " 588.3935757637059,\n",
       " 588.3884771135479,\n",
       " 588.3791294735054,\n",
       " 588.3544849833304,\n",
       " 588.3493859944107,\n",
       " 588.3366383287718,\n",
       " 588.3255901284595,\n",
       " 588.3247402583032,\n",
       " 588.3230405143079,\n",
       " 588.3196410115847,\n",
       " 588.3170913716514,\n",
       " 588.3162414892181,\n",
       " 588.3128419472075,\n",
       " 588.2864948305374,\n",
       " 588.2805453183031,\n",
       " 588.2431470064058,\n",
       " 588.2320970501355,\n",
       " 588.2286970218302,\n",
       " 588.2116965855065,\n",
       " 588.1929955380292,\n",
       " 588.1904453491233,\n",
       " 588.1572918871277,\n",
       " 588.1470904459189,\n",
       " 588.1275371890013,\n",
       " 588.1105338284632,\n",
       " 588.1062829115159,\n",
       " 588.0969307860737,\n",
       " 588.0833274290302,\n",
       " 588.0348629120556,\n",
       " 588.0195574978778,\n",
       " 588.0144556046221,\n",
       " 588.0068026817377,\n",
       " 587.9787411122957,\n",
       " 587.9761899941187,\n",
       " 587.9651350207765,\n",
       " 587.9549302455079,\n",
       " 587.9489773781395,\n",
       " 587.9124084419379,\n",
       " 587.8928473795204,\n",
       " 587.8681825035269,\n",
       " 587.8681825035269,\n",
       " 587.7958829389672,\n",
       " 587.7941816656576,\n",
       " 587.7754673342534,\n",
       " 587.7507975324236,\n",
       " 587.744842597534,\n",
       " 587.7431411764836,\n",
       " 587.6818867380549,\n",
       " 587.6682737735636,\n",
       " 587.6333891126337,\n",
       " 587.5959496116358,\n",
       " 587.5806327645594,\n",
       " 587.5568057643447,\n",
       " 587.5508488633133,\n",
       " 587.5304247441148,\n",
       " 587.5278716792932,\n",
       " 587.522765516367,\n",
       " 587.4989361692495,\n",
       " 587.4887232960306,\n",
       " 587.4419120219462,\n",
       " 587.4351027985986,\n",
       " 587.4223352920793,\n",
       " 587.4146746549663,\n",
       " 587.4087163125859,\n",
       " 587.4036091138698,\n",
       " 587.4019067044301,\n",
       " 587.3985018707488,\n",
       " 587.396799446507,\n",
       " 587.3933945832214,\n",
       " 587.3865847974398,\n",
       " 587.3738162363045,\n",
       " 587.3644524483925,\n",
       " 587.3618986621451,\n",
       " 587.3338062805511,\n",
       " 587.3142259472352,\n",
       " 587.3116719425896,\n",
       " 587.3091179268375,\n",
       " 587.2946449611132,\n",
       " 587.2895367704076,\n",
       " 587.2699549610894,\n",
       " 587.2563324477651,\n",
       " 587.2316408369018,\n",
       " 587.2239777120822,\n",
       " 587.2222747818751,\n",
       " 587.2180174347513,\n",
       " 587.1873636242524,\n",
       " 587.160114449202,\n",
       " 587.1388251512584,\n",
       " 587.1328640095016,\n",
       " 587.1226447685356,\n",
       " 587.1192383153527,\n",
       " 587.112425349694,\n",
       " 587.0826176953292,\n",
       " 587.0732492628156,\n",
       " 587.0672874551946,\n",
       " 587.0357740376646,\n",
       " 587.0349223001984,\n",
       " 587.0127766922965,\n",
       " 586.992333851133,\n",
       " 586.9710384678276,\n",
       " 586.9540016048958,\n",
       " 586.9454829879859,\n",
       " 586.9327048308008,\n",
       " 586.9045919057032,\n",
       " 586.8492140235003,\n",
       " 586.8466579950848,\n",
       " 586.8023517335288,\n",
       " 586.7980913397726,\n",
       " 586.7588942657793,\n",
       " 586.7537814109083,\n",
       " 586.7512249667657,\n",
       " 586.7418512429465,\n",
       " 586.7401469134356,\n",
       " 586.6932759116982,\n",
       " 586.6890147258597,\n",
       " 586.6890147258597,\n",
       " 586.6881624849781,\n",
       " 586.6728219374066,\n",
       " 586.6719696730022,\n",
       " 586.6719696730022,\n",
       " 586.6719696730022,\n",
       " 586.6668560605755,\n",
       " 586.6472534666808,\n",
       " 586.5909989080978,\n",
       " 586.5901465248116,\n",
       " 586.5858845898016,\n",
       " 586.5611647560721,\n",
       " 586.5228043307438,\n",
       " 586.5091644637789,\n",
       " 586.5057544474735,\n",
       " 586.5031969222333,\n",
       " 586.5023444113416,\n",
       " 586.4929667097466,\n",
       " 586.4844413963597,\n",
       " 586.4622750015554,\n",
       " 586.4614224311774,\n",
       " 586.4588647126071,\n",
       " 586.4511914899654,\n",
       " 586.4222028538824,\n",
       " 586.3966234554903,\n",
       " 586.3966234554903,\n",
       " 586.3923601139428,\n",
       " 586.3838333378573,\n",
       " 586.3829806534293,\n",
       " 586.3761591333672,\n",
       " 586.363368569354,\n",
       " 586.3531359172559,\n",
       " 586.3463140499819,\n",
       " 586.3463140499819,\n",
       " 586.3454613109919,\n",
       " 586.3429030865813,\n",
       " 586.3181730084784,\n",
       " 586.2900306162471,\n",
       " 586.2422707379603,\n",
       " 586.2328888760848,\n",
       " 586.2320359721055,\n",
       " 586.2226539464335,\n",
       " 586.2149776319264,\n",
       " 586.1919480852667,\n",
       " 586.1910951217188,\n",
       " 586.1774475361535,\n",
       " 586.1655056381261,\n",
       " 586.1416211121677,\n",
       " 586.1330906884544,\n",
       " 586.1322376392549,\n",
       " 586.1296784842071,\n",
       " 586.1015270411774,\n",
       " 586.0895835962281,\n",
       " 586.0887304837041,\n",
       " 586.0853180211905,\n",
       " 586.0742273807986,\n",
       " 586.0691085529078,\n",
       " 586.053751800976,\n",
       " 586.0452200982446,\n",
       " 586.028156320155,\n",
       " 586.0145049399375,\n",
       " 586.0059726658083,\n",
       " 585.9982935128736,\n",
       " 585.9786685537282,\n",
       " 585.9624561352033,\n",
       " 585.9402699934525,\n",
       " 585.9163762858997,\n",
       " 585.912109449873,\n",
       " 585.912109449873,\n",
       " 585.9035756846001,\n",
       " 585.881387313166,\n",
       " 585.8728531003975,\n",
       " 585.8634653227662,\n",
       " 585.8472497161696,\n",
       " 585.8276196971256,\n",
       " 585.8267662031158,\n",
       " 585.8139636437493,\n",
       " 585.8054284487299,\n",
       " 585.8020143359017,\n",
       " 585.794332509286,\n",
       " 585.7909183317884,\n",
       " 585.7892112355775,\n",
       " 585.7815292410644,\n",
       " 585.7755542867934,\n",
       " 585.7533610659012,\n",
       " 585.7508002555353,\n",
       " 585.7473858242988,\n",
       " 585.719216007124,\n",
       " 585.7081184344297,\n",
       " 585.6970206514627,\n",
       " 585.6970206514627,\n",
       " 585.695313281573,\n",
       " 585.672263300901,\n",
       " 585.6662872319014,\n",
       " 585.6381135137979,\n",
       " 585.6364059721698,\n",
       " 585.6364059721698,\n",
       " 585.618476484477,\n",
       " 585.6159150842811,\n",
       " 585.607377002715,\n",
       " 585.6005464478325,\n",
       " 585.5928619783543,\n",
       " 585.5783465942026,\n",
       " 585.5587075605656,\n",
       " 585.552730332632,\n",
       " 585.5467530436831,\n",
       " 585.5458991402809,\n",
       " 585.5168656836454,\n",
       " 585.5151577884214,\n",
       " 585.5143038389413,\n",
       " 585.5100340728586,\n",
       " 585.502348415444,\n",
       " 585.4946626571416,\n",
       " 585.4844148224613,\n",
       " 585.4775828330236,\n",
       " 585.4750208164307,\n",
       " 585.4673346993835,\n",
       " 585.4502540780045,\n",
       " 585.4425676358015,\n",
       " 585.4400054659743,\n",
       " 585.4203617914225,\n",
       " 585.4126749567351,\n",
       " 585.410966757542,\n",
       " 585.3955927404988,\n",
       " 585.3879055805646,\n",
       " 585.3793641733538,\n",
       " 585.3674059938767,\n",
       " 585.3605726387797,\n",
       " 585.3332384206453,\n",
       " 585.3238419883475,\n",
       " 585.3110284284758,\n",
       " 585.3016316396188,\n",
       " 585.2947975166019,\n",
       " 585.2922346998976,\n",
       " 585.2717317622644,\n",
       " 585.2691688445582,\n",
       " 585.2452477380743,\n",
       " 585.2392673086795,\n",
       " 585.2255975262873,\n",
       " 585.211927424587,\n",
       " 585.2102186394219,\n",
       " 585.1888584038489,\n",
       " 585.1837318312942,\n",
       " 585.1700607515733,\n",
       " 585.1623706288708,\n",
       " 585.1444266161988,\n",
       " 585.1205004099583,\n",
       " 585.11366417133,\n",
       " 585.1017005615348,\n",
       " 585.066662868429,\n",
       " 585.0649536589933,\n",
       " 585.0589713866458,\n",
       " 585.024785799713,\n",
       " 585.0017093992119,\n",
       " 584.9931623532023,\n",
       " 584.988034065655,\n",
       " 584.988034065655,\n",
       " 584.9615371971049,\n",
       " 584.941877454504,\n",
       " 584.9393130915378,\n",
       " 584.9376035099813,\n",
       " 584.9350391282779,\n",
       " 584.9187977830769,\n",
       " 584.9136688435311,\n",
       " 584.9119591870216,\n",
       " 584.9034108295147,\n",
       " 584.8991366039105,\n",
       " 584.8982817550416,\n",
       " 584.8709259315256,\n",
       " 584.8486983827527,\n",
       " 584.8486983827527,\n",
       " 584.8486983827527,\n",
       " 584.8478434601601,\n",
       " 584.846133611226,\n",
       " 584.8324546397882,\n",
       " 584.8273249430125,\n",
       " 584.8050957370327,\n",
       " 584.8042407506977,\n",
       " 584.7974008150173,\n",
       " 584.7845757199825,\n",
       " 584.7657650717936,\n",
       " 584.7349827058408,\n",
       " 584.7118948678914,\n",
       " 584.7110397452745,\n",
       " 584.705908983311,\n",
       " 584.6853854852197,\n",
       " 584.6793993292392,\n",
       " 584.6682820198133,\n",
       " 584.6674268334093,\n",
       " 584.6640060752842,\n",
       " 584.6588749005697,\n",
       " 584.6469019844371,\n",
       " 584.6443363276514,\n",
       " 584.6349288231075,\n",
       " 584.6263764148861,\n",
       " 584.6092712230965,\n",
       " 584.5895996337944,\n",
       " 584.5613740232927,\n",
       " 584.5596633364297,\n",
       " 584.5425561924469,\n",
       " 584.5399900776679,\n",
       " 584.5357131946687,\n",
       " 584.5288701167805,\n",
       " 584.5263039419184,\n",
       " 584.5203161567612,\n",
       " 584.5177499443452,\n",
       " 584.4801108677694,\n",
       " 584.4749780786171,\n",
       " 584.4655678480983,\n",
       " 584.4527354713981,\n",
       " 584.4501689622477,\n",
       " 584.445891421952,\n",
       " 584.4347696706623,\n",
       " 584.410814410548,\n",
       " 584.394558496227,\n",
       " 584.394558496227,\n",
       " 584.3937029092631,\n",
       " 584.3885693611743,\n",
       " 584.374879679132,\n",
       " 584.361189676385,\n",
       " 584.3440767219258,\n",
       " 584.3372313998142,\n",
       " 584.3320973556048,\n",
       " 584.3166949523178,\n",
       " 584.3064264578989,\n",
       " 584.2739083683268,\n",
       " 584.2679179965301,\n",
       " 584.2662064504501,\n",
       " 584.2627833432488,\n",
       " 584.2567928573873,\n",
       " 584.2490907138838,\n",
       " 584.245667506401,\n",
       " 584.2388210312629,\n",
       " 584.2345419435588,\n",
       " 584.224272005195,\n",
       " 584.212290182259,\n",
       " 584.2071550400594,\n",
       " 584.2062991786378,\n",
       " 584.2020198527218,\n",
       " 584.199452242126,\n",
       " 584.190037573391,\n",
       " 584.1814786519682,\n",
       " 584.1789109510887,\n",
       " 584.1686400347078,\n",
       " 584.1549451986176,\n",
       " 584.1463857630209,\n",
       " 584.1429619536642,\n",
       " 584.1361142747468,\n",
       " 584.1232746604094,\n",
       " 584.1104347638382,\n",
       " 584.1095787606979,\n",
       " 584.0941704896566,\n",
       " 584.0941704896566,\n",
       " 584.0873222387214,\n",
       " 584.0873222387214,\n",
       " 584.0864662017088,\n",
       " 584.0821859978269,\n",
       " 584.0770497117653,\n",
       " 584.0684891346219,\n",
       " 584.0368139081645,\n",
       " 584.0351016848217,\n",
       " 584.0265404928101,\n",
       " 584.0042808062284,\n",
       " 583.9803078871753,\n",
       " 583.971745891871,\n",
       " 583.9648962052428,\n",
       " 583.9563339839718,\n",
       " 583.9452029086291,\n",
       " 583.9452029086291,\n",
       " 583.9118084094549,\n",
       " 583.898963862756,\n",
       " 583.8869753642394,\n",
       " 583.8809810226738,\n",
       " 583.8801246831407,\n",
       " 583.876699312449,\n",
       " 583.8672794394288,\n",
       " 583.8655667189151,\n",
       " 583.8527211549159,\n",
       " 583.8518647739339,\n",
       " 583.846726461663,\n",
       " 583.8398753082903,\n",
       " 583.8381625073853,\n",
       " 583.8321676646466,\n",
       " 583.8313112535161,\n",
       " 583.8295984274864,\n",
       " 583.8261727603517,\n",
       " 583.8193213657801,\n",
       " 583.8184649358052,\n",
       " 583.8090441231619,\n",
       " 583.8056183354182,\n",
       " 583.8030489814181,\n",
       " 583.8013360724691,\n",
       " 583.7996231584943,\n",
       " 583.7859196657624,\n",
       " 583.7722158513541,\n",
       " 583.7636508039876,\n",
       " 583.7465203322415,\n",
       " 583.7379549078507,\n",
       " 583.7336721485236,\n",
       " 583.7319590359946,\n",
       " 583.7259631025504,\n",
       " 583.7225368272155,\n",
       " 583.6976957295617,\n",
       " 583.6891295886878,\n",
       " 583.6848464711072,\n",
       " 583.6805633220965,\n",
       " 583.6779934176035,\n",
       " 583.6762801416552,\n",
       " 583.6719969297825,\n",
       " 583.6668570340447,\n",
       " 583.6625737530204,\n",
       " 583.6565771067777,\n",
       " 583.6403001849684,\n",
       " 583.6394434922986,\n",
       " 583.6385867983713,\n",
       " 583.6334466083999,\n",
       " 583.63258990567,\n",
       " 583.6128853957904,\n",
       " 583.6008910205672,\n",
       " 583.600034270047,\n",
       " 583.5888963988263,\n",
       " 583.5837557711832,\n",
       " 583.579471880223,\n",
       " 583.570047209416,\n",
       " 583.552054233382,\n",
       " 583.5203509732972,\n",
       " 583.4989288764805,\n",
       " 583.4869321587246,\n",
       " 583.4740782588375,\n",
       " 583.4655088349267,\n",
       " 583.447512635027,\n",
       " 583.4466556592813,\n",
       " 583.4423707616717,\n",
       " 583.4303728809463,\n",
       " 583.3960918621242,\n",
       " 583.393520704507,\n",
       " 583.384950097275,\n",
       " 583.383235960719,\n",
       " 583.3720939503363,\n",
       " 583.3703797760047,\n",
       " 583.3515235259097,\n",
       " 583.3352380921283,\n",
       " 583.3352380921283,\n",
       " 583.3343809514403,\n",
       " 583.3343809514403,\n",
       " 583.3275237805944,\n",
       " 583.2803785487731,\n",
       " 583.2580903853799,\n",
       " 583.2512323176009,\n",
       " 583.234086795345,\n",
       " 583.2306576304095,\n",
       " 583.2272284453119,\n",
       " 583.2220846298603,\n",
       " 583.2169407690418,\n",
       " 583.2160834544945,\n",
       " 583.1869340100136,\n",
       " 583.1860766513549,\n",
       " 583.1843619302562,\n",
       " 583.1715013613062,\n",
       " 583.1389199839092,\n",
       " 583.1320605145974,\n",
       " 583.1286307496829,\n",
       " 583.1243435151717,\n",
       " 583.1046218304225,\n",
       " 583.0874719971267,\n",
       " 583.0728942422209,\n",
       " 583.0711791882703,\n",
       " 583.0703216594032,\n",
       " 583.049740588228,\n",
       " 583.0488830278298,\n",
       " 583.0463103390673,\n",
       " 583.0463103390673,\n",
       " 583.0274436079317,\n",
       " 583.0197252237698,\n",
       " 583.0180100134129,\n",
       " 583.0162947980099,\n",
       " 583.0060033996219,\n",
       " 583.0017152633429,\n",
       " 582.9837047465392,\n",
       " 582.9605475501751,\n",
       " 582.9571167761828,\n",
       " 582.9476820435947,\n",
       " 582.9468243330604,\n",
       " 582.9168036692715,\n",
       " 582.9159459133024,\n",
       " 582.915088156071,\n",
       " 582.9107993509813,\n",
       " 582.9022216461351,\n",
       " 582.8927860250117,\n",
       " 582.889354852188,\n",
       " 582.8799190227778,\n",
       " 582.8653360768677,\n",
       " 582.8653360768677,\n",
       " 582.8524684686512,\n",
       " 582.8481792027835,\n",
       " 582.8293060579573,\n",
       " 582.8250166216271,\n",
       " 582.8172955566779,\n",
       " 582.8095743894398,\n",
       " 582.8001372683435,\n",
       " 582.7718249881337,\n",
       " 582.7658191761078,\n",
       " 582.746085357937,\n",
       " 582.7452273506836,\n",
       " 582.7426533213439,\n",
       " 582.7409372954675,\n",
       " 582.7375052285548,\n",
       " 582.7332151164887,\n",
       " 582.7177704515283,\n",
       " 582.7040415167892,\n",
       " 582.6980350061256,\n",
       " 582.6971769281193,\n",
       " 582.6954607683159,\n",
       " 582.6928865191337,\n",
       " 582.6920284335457,\n",
       " 582.6851637033502,\n",
       " 582.6688596449959,\n",
       " 582.6585621099205,\n",
       " 582.6491225428903,\n",
       " 582.645689935144,\n",
       " 582.6405409856063,\n",
       " 582.62852659306,\n",
       " 582.6268102310431,\n",
       " 582.6139373547461,\n",
       " 582.6053552791975,\n",
       " 582.5864742679837,\n",
       " 582.5624430050395,\n",
       " 582.5615847273144,\n",
       " 582.5469938125163,\n",
       " 582.5469938125163,\n",
       " 582.5427022974367,\n",
       " 582.5358358075492,\n",
       " 582.5178108864999,\n",
       " 582.5015021439859,\n",
       " 582.4972102937489,\n",
       " 582.4843345532994,\n",
       " 582.4774673753484,\n",
       " 582.4748921627438,\n",
       " 582.4671664566167,\n",
       " 582.455148487847,\n",
       " 582.4525731765634,\n",
       " 582.4448471743913,\n",
       " 582.4242440008829,\n",
       " 582.4190930936245,\n",
       " 582.3890452266423,\n",
       " 582.3692986413346,\n",
       " 582.3667229504103,\n",
       " 582.3650058167987,\n",
       " 582.3538443249087,\n",
       " 582.3512685656312,\n",
       " 582.3160653803053,\n",
       " 582.3091962179543,\n",
       " 582.2920229575535,\n",
       " 582.2525225363992,\n",
       " 582.2439351337204,\n",
       " 582.2362063630189,\n",
       " 582.2241836268913,\n",
       " 582.2216072939925,\n",
       " 582.2018550296796,\n",
       " 582.1992785979728,\n",
       " 582.1906904099378,\n",
       " 582.1803844170637,\n",
       " 582.1786667338473,\n",
       " 582.1735136537903,\n",
       " 582.1666428094279,\n",
       " 582.1632073568373,\n",
       " 582.1546186366643,\n",
       " 582.1477475692919,\n",
       " 582.1468886801681,\n",
       " 582.146029789777,\n",
       " 582.142594215541,\n",
       " 582.135723006242,\n",
       " 582.135723006242,\n",
       " 582.1236981948081,\n",
       " 582.0970709426392,\n",
       " 582.0936350794432,\n",
       " 582.0704424723866,\n",
       " 582.06528843421,\n",
       " 582.0524031390988,\n",
       " 582.0515441092824,\n",
       " 582.0506850781983,\n",
       " 582.04467182511,\n",
       " 582.0369404084246,\n",
       " 582.0300679518198,\n",
       " 582.01890003676,\n",
       " 581.9905497514543,\n",
       " 581.9802402143907,\n",
       " 581.9768036614518,\n",
       " 581.9742262334304,\n",
       " 581.9673530362335,\n",
       " 581.9656347242507,\n",
       " 581.9596205923569,\n",
       " 581.9561839176554,\n",
       " 581.9544655726941,\n",
       " 581.935563443239,\n",
       " 581.935563443239,\n",
       " 581.9321266264649,\n",
       " 581.9226752756762,\n",
       " 581.9192383827846,\n",
       " 581.9166606997948,\n",
       " 581.9115052995601,\n",
       " 581.9046313615316,\n",
       " 581.890883241867,\n",
       " 581.8848683373714,\n",
       " 581.8728383418494,\n",
       " 581.8685418546014,\n",
       " 581.8616674090157,\n",
       " 581.8608080976068,\n",
       " 581.8582301557657,\n",
       " 581.8530742378182,\n",
       " 581.8384655555183,\n",
       " 581.8290126832796,\n",
       " 581.8264346005602,\n",
       " 581.8152627767683,\n",
       " 581.798074936657,\n",
       " 581.7920590726553,\n",
       " 581.7903402429436,\n",
       " 581.7894808261834,\n",
       " 581.7869025682858,\n",
       " 581.7834648733152,\n",
       " 581.7826054463986,\n",
       " 581.7826054463986,\n",
       " 581.7800271580317,\n",
       " 581.7585409772684,\n",
       " 581.7568220485257,\n",
       " 581.7473678496534,\n",
       " 581.7404919721507,\n",
       " 581.7361945074416,\n",
       " 581.7353350106903,\n",
       " 581.7336160133777,\n",
       " 581.7164257608684,\n",
       " 581.7052518243238,\n",
       " 581.6803245769966,\n",
       " 581.6751670821095,\n",
       " 581.673447906985,\n",
       " 581.6528174091483,\n",
       " 581.6502385454681,\n",
       " 581.6407826141492,\n",
       " 581.6278879146013,\n",
       " 581.6270282578002,\n",
       " 581.6124138977779,\n",
       " 581.610694537162,\n",
       " 581.610694537162,\n",
       " 581.6063961133852,\n",
       " 581.600378266727,\n",
       " 581.5917812349139,\n",
       " 581.588342386606,\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The similarity between the testarr_one_sample and testarr_waiting_to_compare\n",
    "sorted(result_l2_2[0],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.966314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.799711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.869044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.891332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.655592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.949265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.662349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.900462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.959716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.757975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          0                           0.38                2   \n",
       "1                          0                           0.36                2   \n",
       "2                          0                           0.38                0   \n",
       "3                          0                           0.36                0   \n",
       "4                          0                           0.34                2   \n",
       "5                          0                           0.34                2   \n",
       "6                          0                           0.34                2   \n",
       "7                          0                           0.36                1   \n",
       "8                          0                           0.34                0   \n",
       "9                          0                           0.38                0   \n",
       "10                         0                           0.32                2   \n",
       "11                         0                           0.36                0   \n",
       "12                         0                           0.34                2   \n",
       "13                         0                           0.36                2   \n",
       "14                         0                           0.32                2   \n",
       "15                         0                           0.38                2   \n",
       "16                         0                           0.34                0   \n",
       "17                         0                           0.38                0   \n",
       "18                         0                           0.36                2   \n",
       "19                         0                           0.36                2   \n",
       "20                         0                           0.36                0   \n",
       "21                         0                           0.36                2   \n",
       "22                         0                           0.36                2   \n",
       "23                         0                           0.36                0   \n",
       "24                         0                           0.38                0   \n",
       "25                         0                           0.34                2   \n",
       "26                         0                           0.36                2   \n",
       "27                         0                           0.36                2   \n",
       "28                         0                           0.36                2   \n",
       "29                         0                           0.34                0   \n",
       "..                       ...                            ...              ...   \n",
       "470                        0                           0.34                2   \n",
       "471                        0                           0.36                2   \n",
       "472                        0                           0.34                2   \n",
       "473                        0                           0.36                2   \n",
       "474                        0                           0.38                2   \n",
       "475                        0                           0.36                0   \n",
       "476                        0                           0.36                2   \n",
       "477                        0                           0.34                0   \n",
       "478                        0                           0.36                0   \n",
       "479                        0                           0.34                2   \n",
       "480                        0                           0.36                2   \n",
       "481                        0                           0.36                0   \n",
       "482                        0                           0.36                2   \n",
       "483                        0                           0.36                0   \n",
       "484                        0                           0.36                0   \n",
       "485                        0                           0.36                2   \n",
       "486                        0                           0.36                2   \n",
       "487                        0                           0.36                2   \n",
       "488                        0                           0.34                2   \n",
       "489                        0                           0.36                2   \n",
       "490                        0                           0.34                2   \n",
       "491                        0                           0.36                0   \n",
       "492                        0                           0.38                2   \n",
       "493                        0                           0.36                0   \n",
       "494                        0                           0.34                2   \n",
       "495                        0                           0.34                2   \n",
       "496                        0                           0.40                2   \n",
       "497                        0                           0.38                2   \n",
       "498                        0                           0.34                2   \n",
       "499                        0                           0.38                2   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.541207  \n",
       "1          0.998652  \n",
       "2          0.998847  \n",
       "3          0.801601  \n",
       "4          0.999509  \n",
       "5          0.966314  \n",
       "6          0.997170  \n",
       "7          0.980144  \n",
       "8          0.973287  \n",
       "9          0.999313  \n",
       "10         0.972966  \n",
       "11         0.761090  \n",
       "12         0.995546  \n",
       "13         0.983000  \n",
       "14         0.799711  \n",
       "15         0.996289  \n",
       "16         0.837463  \n",
       "17         0.755542  \n",
       "18         0.998852  \n",
       "19         0.998982  \n",
       "20         0.999834  \n",
       "21         0.972439  \n",
       "22         0.869044  \n",
       "23         0.896911  \n",
       "24         0.726004  \n",
       "25         0.891332  \n",
       "26         0.655592  \n",
       "27         0.993189  \n",
       "28         0.998700  \n",
       "29         0.941182  \n",
       "..              ...  \n",
       "470        0.999117  \n",
       "471        0.999325  \n",
       "472        0.998547  \n",
       "473        0.998387  \n",
       "474        0.987230  \n",
       "475        0.949265  \n",
       "476        0.998980  \n",
       "477        0.662349  \n",
       "478        0.646808  \n",
       "479        0.997391  \n",
       "480        0.794412  \n",
       "481        0.975176  \n",
       "482        0.900462  \n",
       "483        0.908200  \n",
       "484        0.860421  \n",
       "485        0.959716  \n",
       "486        0.998821  \n",
       "487        0.977217  \n",
       "488        0.947271  \n",
       "489        0.757975  \n",
       "490        0.999608  \n",
       "491        0.922933  \n",
       "492        0.992511  \n",
       "493        0.971128  \n",
       "494        0.609290  \n",
       "495        0.975862  \n",
       "496        0.988310  \n",
       "497        0.941984  \n",
       "498        0.982536  \n",
       "499        0.997965  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_representations(mnist_train_RGB_x,C_x_train,C_y_train,C_VGG_Model1)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
