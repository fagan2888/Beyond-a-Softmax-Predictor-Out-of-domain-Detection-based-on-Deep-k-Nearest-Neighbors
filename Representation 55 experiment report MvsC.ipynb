{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "def MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y):\n",
    "    \"\"\"\n",
    "    Change the one-channel to RBG-channel on mnist_train_x and mnist_test_x\n",
    "    Change the shape of mnist_train_y and mnist_test_y from (length) to (length,1)\n",
    "    ---------------------------------------\n",
    "    inputs:\n",
    "    mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y which is all multi-dimension array\n",
    "    It is recommended to use the following way to import the data\n",
    "    ========================== codes ==========================\n",
    "    mnist = keras.datasets.mnist\n",
    "    (mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "    ========================== codes ==========================\n",
    "    outputs:\n",
    "    mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y \n",
    "    \"\"\"\n",
    "    from skimage import exposure\n",
    "    import imutils\n",
    "    B= []\n",
    "    for i in range(len(mnist_train_x)):\n",
    "        A = mnist_train_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_train_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    B= []\n",
    "    for i in range(len(mnist_test_x)):\n",
    "        A = mnist_test_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_test_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    M_train_y = np.array([[mnist_train_y[i]] for i in range(len(mnist_train_y))])\n",
    "    M_test_y = np.array([[mnist_test_y[i]] for i in range(len(mnist_test_y))])\n",
    "    return mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y\n",
    "mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y = MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(C_x_train, C_y_train), (C_x_test, C_y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('MNIST_vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 25\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        x_train,y_train,x_test,y_test = mnist_train_RGB_x,M_train_y,mnist_test_RGB_x,M_test_y\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('MNIST_vgg.h5')\n",
    "        return model\n",
    "class cifar10vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('cifar10vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 250\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('cifar10vgg.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1105 03:10:04.658869 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1105 03:10:04.672832 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1105 03:10:04.694787 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1105 03:10:04.695785 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1105 03:10:04.695785 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1105 03:10:05.779385 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1105 03:10:05.824190 16452 deprecation.py:506] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1105 03:10:05.891193 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1105 03:10:07.414703 16452 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1105 03:10:07.608208 16452 deprecation.py:323] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"MNIST-VGG-3.pkl\",\"rb+\")\n",
    "M_VGG_Model3 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"CIFAR-VGG-3.pkl\",\"rb+\")\n",
    "C_VGG_Model3 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"C_representation_result_IDC.pkl\",\"rb+\")\n",
    "C_representation_result_IDC = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"M_representation_result_IDM.pkl\",\"rb+\")\n",
    "M_representation_result_IDM = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"C_representation_result_ODM.pkl\",\"rb+\")\n",
    "C_representation_result_ODM = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"M_representation_result_ODC.pkl\",\"rb+\")\n",
    "M_representation_result_ODC = pickle.load(fp, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concact_results_OD(one_sample,arr_KNN_from_same_class_ratio, arr_KNN_max_class_label,MODEL):\n",
    "    pred_labels = MODEL.predict(one_sample[:500])\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],})\n",
    "    return df\n",
    "def concact_results_ID(one_sample,ground_truth_one_sample, arr_KNN_from_same_class_ratio, arr_KNN_max_class_label,MODEL):\n",
    "    pred_labels = MODEL.predict(one_sample[:500])\n",
    "    ground_truth_one_sample = ground_truth_one_sample.reshape(-1)\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],\n",
    "                'ground_truth':ground_truth_one_sample[:500]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency_of_df(df):\n",
    "    return len(df[df['arr_KNN_from_same_class_ratio']>0.7][df['arr_KNN_max_class_label'] == df['predicted_label']])/len(df[df['arr_KNN_from_same_class_ratio']>0.7]), len(df[df['arr_KNN_from_same_class_ratio']<0.4][df['arr_KNN_max_class_label'] == df['predicted_label']])/len(df[df['arr_KNN_from_same_class_ratio']<0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = [df_M_representation_result_ODC, df_M_representation_result_IDM, df_C_representation_result_ODM, df_C_representation_result_IDC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2807017543859649, 0.18518518518518517)\n",
      "(0.9705882352941176, 0.5714285714285714)\n",
      "(0.42857142857142855, 0.20603015075376885)\n",
      "(0.9333333333333333, 0.2543640897755611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for df in df_s:\n",
    "    print(consistency_of_df(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_M_representation_result_ODC = concact_results_OD(C_x_train,M_representation_result_ODC[1],M_representation_result_ODC[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6</td>\n",
       "      <td>0.328233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4</td>\n",
       "      <td>0.604946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.640614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.705629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.299051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6</td>\n",
       "      <td>0.407911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>0.984686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.391822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.703829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.676260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>0.272675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.674043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.838276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.990370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4</td>\n",
       "      <td>0.788409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.994037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.478431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.704068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7</td>\n",
       "      <td>0.976691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.974171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.926880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.382344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.771681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>0.296732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7</td>\n",
       "      <td>0.640722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.365135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.511437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "10                         0                           0.84                1   \n",
       "17                         1                           0.94                6   \n",
       "30                         4                           0.78                4   \n",
       "36                         1                           0.80                1   \n",
       "60                         4                           0.76                7   \n",
       "81                         0                           0.74                1   \n",
       "108                        1                           0.84                0   \n",
       "129                        1                           0.90                1   \n",
       "130                        0                           0.74                4   \n",
       "137                        4                           0.76                7   \n",
       "139                        1                           0.86                1   \n",
       "142                        1                           0.90                1   \n",
       "148                        1                           0.92                6   \n",
       "150                        1                           0.92                1   \n",
       "169                        1                           0.78                7   \n",
       "173                        1                           0.98                1   \n",
       "177                        1                           0.84                7   \n",
       "179                        1                           0.98                1   \n",
       "180                        0                           0.76                1   \n",
       "182                        1                           0.90                0   \n",
       "184                        4                           0.74                7   \n",
       "185                        1                           0.92                4   \n",
       "190                        4                           0.74                1   \n",
       "197                        0                           0.80                4   \n",
       "198                        1                           0.98                1   \n",
       "216                        1                           0.86                7   \n",
       "232                        1                           0.96                4   \n",
       "242                        0                           0.84                4   \n",
       "246                        1                           0.94                4   \n",
       "247                        1                           0.90                4   \n",
       "259                        1                           0.74                1   \n",
       "285                        1                           0.78                7   \n",
       "294                        1                           0.74                4   \n",
       "295                        4                           0.72                7   \n",
       "303                        0                           0.88                4   \n",
       "311                        4                           0.80                7   \n",
       "315                        1                           0.88                1   \n",
       "328                        1                           0.88                0   \n",
       "356                        1                           0.86                1   \n",
       "358                        1                           0.92                4   \n",
       "361                        1                           0.96                1   \n",
       "364                        1                           0.76                7   \n",
       "375                        4                           0.84                7   \n",
       "383                        1                           0.88                1   \n",
       "393                        4                           0.72                7   \n",
       "398                        0                           0.74                7   \n",
       "402                        1                           0.80                4   \n",
       "403                        0                           0.72                7   \n",
       "420                        0                           1.00                1   \n",
       "439                        1                           0.76                1   \n",
       "444                        4                           0.78                7   \n",
       "447                        1                           0.88                1   \n",
       "461                        5                           0.82                3   \n",
       "462                        0                           0.74                7   \n",
       "485                        1                           0.94                7   \n",
       "491                        1                           0.90                4   \n",
       "492                        1                           0.80                7   \n",
       "\n",
       "     predicted_prob  \n",
       "10         0.999750  \n",
       "17         0.328233  \n",
       "30         0.604946  \n",
       "36         0.934947  \n",
       "60         0.640614  \n",
       "81         0.937104  \n",
       "108        0.418757  \n",
       "129        0.981307  \n",
       "130        0.705629  \n",
       "137        0.299051  \n",
       "139        0.360293  \n",
       "142        0.999594  \n",
       "148        0.407911  \n",
       "150        0.721461  \n",
       "169        0.984686  \n",
       "173        0.999400  \n",
       "177        0.997697  \n",
       "179        0.856495  \n",
       "180        0.997026  \n",
       "182        0.944138  \n",
       "184        0.391822  \n",
       "185        0.703829  \n",
       "190        0.277405  \n",
       "197        0.977732  \n",
       "198        0.676260  \n",
       "216        0.272675  \n",
       "232        0.674043  \n",
       "242        0.838276  \n",
       "246        0.855199  \n",
       "247        0.983021  \n",
       "259        0.519882  \n",
       "285        0.991208  \n",
       "294        0.865640  \n",
       "295        0.990370  \n",
       "303        0.788409  \n",
       "311        0.994037  \n",
       "315        0.757894  \n",
       "328        0.290557  \n",
       "356        0.957969  \n",
       "358        0.478431  \n",
       "361        0.715366  \n",
       "364        0.704068  \n",
       "375        0.976691  \n",
       "383        0.712855  \n",
       "393        0.974171  \n",
       "398        0.926880  \n",
       "402        0.382344  \n",
       "403        0.771681  \n",
       "420        0.999791  \n",
       "439        0.899122  \n",
       "444        0.997221  \n",
       "447        0.995233  \n",
       "461        0.296732  \n",
       "462        0.825178  \n",
       "485        0.640722  \n",
       "491        0.365135  \n",
       "492        0.511437  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_ODC[df_M_representation_result_ODC['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_M_representation_result_ODC[df_M_representation_result_ODC['arr_KNN_from_same_class_ratio']>0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6</td>\n",
       "      <td>0.328233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4</td>\n",
       "      <td>0.604946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.640614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.705629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.299051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6</td>\n",
       "      <td>0.407911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>0.984686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.391822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.703829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.676260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>0.272675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.674043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.838276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.990370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4</td>\n",
       "      <td>0.788409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.994037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.478431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.704068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7</td>\n",
       "      <td>0.976691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.974171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.926880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.382344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.771681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>0.296732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7</td>\n",
       "      <td>0.640722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.365135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.511437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "10                         0                           0.84                1   \n",
       "17                         1                           0.94                6   \n",
       "30                         4                           0.78                4   \n",
       "36                         1                           0.80                1   \n",
       "60                         4                           0.76                7   \n",
       "81                         0                           0.74                1   \n",
       "108                        1                           0.84                0   \n",
       "129                        1                           0.90                1   \n",
       "130                        0                           0.74                4   \n",
       "137                        4                           0.76                7   \n",
       "139                        1                           0.86                1   \n",
       "142                        1                           0.90                1   \n",
       "148                        1                           0.92                6   \n",
       "150                        1                           0.92                1   \n",
       "169                        1                           0.78                7   \n",
       "173                        1                           0.98                1   \n",
       "177                        1                           0.84                7   \n",
       "179                        1                           0.98                1   \n",
       "180                        0                           0.76                1   \n",
       "182                        1                           0.90                0   \n",
       "184                        4                           0.74                7   \n",
       "185                        1                           0.92                4   \n",
       "190                        4                           0.74                1   \n",
       "197                        0                           0.80                4   \n",
       "198                        1                           0.98                1   \n",
       "216                        1                           0.86                7   \n",
       "232                        1                           0.96                4   \n",
       "242                        0                           0.84                4   \n",
       "246                        1                           0.94                4   \n",
       "247                        1                           0.90                4   \n",
       "259                        1                           0.74                1   \n",
       "285                        1                           0.78                7   \n",
       "294                        1                           0.74                4   \n",
       "295                        4                           0.72                7   \n",
       "303                        0                           0.88                4   \n",
       "311                        4                           0.80                7   \n",
       "315                        1                           0.88                1   \n",
       "328                        1                           0.88                0   \n",
       "356                        1                           0.86                1   \n",
       "358                        1                           0.92                4   \n",
       "361                        1                           0.96                1   \n",
       "364                        1                           0.76                7   \n",
       "375                        4                           0.84                7   \n",
       "383                        1                           0.88                1   \n",
       "393                        4                           0.72                7   \n",
       "398                        0                           0.74                7   \n",
       "402                        1                           0.80                4   \n",
       "403                        0                           0.72                7   \n",
       "420                        0                           1.00                1   \n",
       "439                        1                           0.76                1   \n",
       "444                        4                           0.78                7   \n",
       "447                        1                           0.88                1   \n",
       "461                        5                           0.82                3   \n",
       "462                        0                           0.74                7   \n",
       "485                        1                           0.94                7   \n",
       "491                        1                           0.90                4   \n",
       "492                        1                           0.80                7   \n",
       "\n",
       "     predicted_prob  \n",
       "10         0.999750  \n",
       "17         0.328233  \n",
       "30         0.604946  \n",
       "36         0.934947  \n",
       "60         0.640614  \n",
       "81         0.937104  \n",
       "108        0.418757  \n",
       "129        0.981307  \n",
       "130        0.705629  \n",
       "137        0.299051  \n",
       "139        0.360293  \n",
       "142        0.999594  \n",
       "148        0.407911  \n",
       "150        0.721461  \n",
       "169        0.984686  \n",
       "173        0.999400  \n",
       "177        0.997697  \n",
       "179        0.856495  \n",
       "180        0.997026  \n",
       "182        0.944138  \n",
       "184        0.391822  \n",
       "185        0.703829  \n",
       "190        0.277405  \n",
       "197        0.977732  \n",
       "198        0.676260  \n",
       "216        0.272675  \n",
       "232        0.674043  \n",
       "242        0.838276  \n",
       "246        0.855199  \n",
       "247        0.983021  \n",
       "259        0.519882  \n",
       "285        0.991208  \n",
       "294        0.865640  \n",
       "295        0.990370  \n",
       "303        0.788409  \n",
       "311        0.994037  \n",
       "315        0.757894  \n",
       "328        0.290557  \n",
       "356        0.957969  \n",
       "358        0.478431  \n",
       "361        0.715366  \n",
       "364        0.704068  \n",
       "375        0.976691  \n",
       "383        0.712855  \n",
       "393        0.974171  \n",
       "398        0.926880  \n",
       "402        0.382344  \n",
       "403        0.771681  \n",
       "420        0.999791  \n",
       "439        0.899122  \n",
       "444        0.997221  \n",
       "447        0.995233  \n",
       "461        0.296732  \n",
       "462        0.825178  \n",
       "485        0.640722  \n",
       "491        0.365135  \n",
       "492        0.511437  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_ODC[df_M_representation_result_ODC['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_M_representation_result_ODC[df_M_representation_result_ODC['arr_KNN_from_same_class_ratio']>0.7][df_M_representation_result_ODC['arr_KNN_max_class_label'] == df_M_representation_result_ODC['predicted_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.485816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.827864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.961915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.983568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.841327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.550421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.335351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.996275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.287250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.772040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.478722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.253254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.864852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.437678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.972917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.257798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.992411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.655631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.976598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.512767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.668273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.337780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.551052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.305047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.787894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.867049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.262501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.624858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.531626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "2                          4                           0.38                7   \n",
       "12                         4                           0.34                7   \n",
       "13                         0                           0.32                2   \n",
       "29                         8                           0.18                1   \n",
       "32                         7                           0.32                7   \n",
       "43                         0                           0.30                1   \n",
       "46                         1                           0.36                7   \n",
       "50                         4                           0.36                0   \n",
       "68                         7                           0.26                7   \n",
       "84                         4                           0.28                7   \n",
       "103                        0                           0.36                4   \n",
       "106                        4                           0.34                0   \n",
       "114                        4                           0.38                4   \n",
       "124                        4                           0.36                1   \n",
       "134                        4                           0.34                5   \n",
       "138                        1                           0.34                1   \n",
       "140                        0                           0.34                1   \n",
       "162                        7                           0.30                7   \n",
       "166                        4                           0.38                4   \n",
       "202                        1                           0.20                7   \n",
       "207                        4                           0.28                7   \n",
       "212                        0                           0.38                1   \n",
       "214                        4                           0.30                1   \n",
       "215                        4                           0.38                4   \n",
       "219                        0                           0.30                7   \n",
       "234                        0                           0.34                9   \n",
       "291                        0                           0.32                1   \n",
       "319                        0                           0.24                1   \n",
       "321                        4                           0.28                1   \n",
       "325                        4                           0.38                7   \n",
       "339                        7                           0.32                4   \n",
       "340                        4                           0.30                1   \n",
       "346                        1                           0.36                7   \n",
       "355                        1                           0.36                1   \n",
       "357                        4                           0.32                7   \n",
       "360                        4                           0.36                7   \n",
       "370                        4                           0.36                0   \n",
       "374                        0                           0.36                4   \n",
       "382                        0                           0.38                7   \n",
       "385                        0                           0.34                4   \n",
       "401                        8                           0.24                7   \n",
       "404                        7                           0.38                7   \n",
       "406                        1                           0.34                1   \n",
       "408                        0                           0.36                1   \n",
       "422                        0                           0.28                7   \n",
       "424                        0                           0.34                1   \n",
       "432                        4                           0.36                7   \n",
       "433                        4                           0.38                7   \n",
       "441                        4                           0.38                7   \n",
       "442                        4                           0.38                7   \n",
       "459                        4                           0.32                7   \n",
       "466                        1                           0.34                4   \n",
       "468                        4                           0.36                7   \n",
       "495                        4                           0.36                1   \n",
       "\n",
       "     predicted_prob  \n",
       "2          0.993760  \n",
       "12         0.666899  \n",
       "13         0.485816  \n",
       "29         0.620811  \n",
       "32         0.827864  \n",
       "43         0.708303  \n",
       "46         0.961915  \n",
       "50         0.615069  \n",
       "68         0.983568  \n",
       "84         0.841327  \n",
       "103        0.550421  \n",
       "106        0.332704  \n",
       "114        0.335351  \n",
       "124        0.805058  \n",
       "134        0.250353  \n",
       "138        0.722631  \n",
       "140        0.583224  \n",
       "162        0.996275  \n",
       "166        0.287250  \n",
       "202        0.772040  \n",
       "207        0.478722  \n",
       "212        0.770043  \n",
       "214        0.494462  \n",
       "215        0.253254  \n",
       "219        0.864852  \n",
       "234        0.437678  \n",
       "291        0.554824  \n",
       "319        0.955840  \n",
       "321        0.571665  \n",
       "325        0.972917  \n",
       "339        0.257798  \n",
       "340        0.540679  \n",
       "346        0.993617  \n",
       "355        0.433091  \n",
       "357        0.992411  \n",
       "360        0.655631  \n",
       "370        0.858190  \n",
       "374        0.976598  \n",
       "382        0.512767  \n",
       "385        0.668273  \n",
       "401        0.337780  \n",
       "404        0.551052  \n",
       "406        0.361451  \n",
       "408        0.952400  \n",
       "422        0.305047  \n",
       "424        0.787894  \n",
       "432        0.989017  \n",
       "433        0.978543  \n",
       "441        0.867049  \n",
       "442        0.262501  \n",
       "459        0.624858  \n",
       "466        0.966902  \n",
       "468        0.531626  \n",
       "495        0.572713  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_ODC[df_M_representation_result_ODC['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_M_representation_result_IDM = concact_results_ID(mnist_test_RGB_x,M_test_y,M_representation_result_IDM[1],M_representation_result_IDM[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999653</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9</td>\n",
       "      <td>0.990595</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>2</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.923092</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992982</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          7                           1.00                7   \n",
       "1                          2                           1.00                2   \n",
       "2                          1                           1.00                1   \n",
       "3                          0                           1.00                0   \n",
       "4                          4                           1.00                4   \n",
       "5                          1                           1.00                1   \n",
       "6                          4                           0.98                4   \n",
       "7                          9                           0.98                9   \n",
       "9                          9                           1.00                9   \n",
       "10                         0                           1.00                0   \n",
       "11                         6                           1.00                6   \n",
       "12                         9                           1.00                9   \n",
       "13                         0                           1.00                0   \n",
       "14                         1                           1.00                1   \n",
       "15                         5                           1.00                5   \n",
       "16                         9                           1.00                9   \n",
       "17                         7                           1.00                7   \n",
       "19                         4                           1.00                4   \n",
       "20                         9                           0.82                9   \n",
       "21                         6                           0.98                6   \n",
       "22                         6                           1.00                6   \n",
       "23                         5                           1.00                5   \n",
       "24                         4                           1.00                4   \n",
       "25                         0                           1.00                0   \n",
       "27                         4                           1.00                4   \n",
       "28                         0                           1.00                0   \n",
       "29                         1                           1.00                1   \n",
       "30                         3                           1.00                3   \n",
       "31                         1                           1.00                1   \n",
       "32                         3                           1.00                3   \n",
       "..                       ...                            ...              ...   \n",
       "467                        2                           1.00                2   \n",
       "469                        2                           0.84                5   \n",
       "470                        8                           1.00                8   \n",
       "471                        9                           1.00                9   \n",
       "472                        6                           1.00                6   \n",
       "473                        1                           1.00                1   \n",
       "474                        8                           0.82                8   \n",
       "475                        4                           1.00                4   \n",
       "476                        1                           1.00                1   \n",
       "477                        2                           1.00                2   \n",
       "478                        5                           1.00                5   \n",
       "479                        9                           0.98                9   \n",
       "480                        1                           1.00                1   \n",
       "481                        9                           1.00                9   \n",
       "482                        7                           1.00                7   \n",
       "483                        5                           1.00                5   \n",
       "484                        4                           1.00                4   \n",
       "485                        0                           1.00                0   \n",
       "486                        8                           1.00                8   \n",
       "487                        9                           0.98                9   \n",
       "488                        9                           1.00                9   \n",
       "489                        1                           1.00                1   \n",
       "490                        0                           0.78                0   \n",
       "491                        5                           1.00                5   \n",
       "492                        2                           0.98                2   \n",
       "493                        3                           1.00                3   \n",
       "494                        7                           1.00                7   \n",
       "496                        9                           1.00                9   \n",
       "497                        1                           0.74                4   \n",
       "499                        6                           1.00                6   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "0          0.999994             7  \n",
       "1          0.999490             2  \n",
       "2          0.999907             1  \n",
       "3          0.999972             0  \n",
       "4          0.999983             4  \n",
       "5          0.999893             1  \n",
       "6          0.999968             4  \n",
       "7          0.996378             9  \n",
       "9          0.999572             9  \n",
       "10         0.999984             0  \n",
       "11         0.999890             6  \n",
       "12         0.999383             9  \n",
       "13         0.999986             0  \n",
       "14         0.999917             1  \n",
       "15         0.999001             5  \n",
       "16         0.999653             9  \n",
       "17         0.999978             7  \n",
       "19         0.999999             4  \n",
       "20         0.990595             9  \n",
       "21         0.999241             6  \n",
       "22         0.999920             6  \n",
       "23         0.999638             5  \n",
       "24         0.999989             4  \n",
       "25         0.999979             0  \n",
       "27         0.999998             4  \n",
       "28         0.999944             0  \n",
       "29         0.999875             1  \n",
       "30         0.999936             3  \n",
       "31         0.999926             1  \n",
       "32         0.999791             3  \n",
       "..              ...           ...  \n",
       "467        0.999543             2  \n",
       "469        0.789094             5  \n",
       "470        0.999586             8  \n",
       "471        0.923092             9  \n",
       "472        0.999899             6  \n",
       "473        0.999921             1  \n",
       "474        0.997717             8  \n",
       "475        0.999996             4  \n",
       "476        0.999918             1  \n",
       "477        0.999709             2  \n",
       "478        0.999589             5  \n",
       "479        0.996429             9  \n",
       "480        0.999856             1  \n",
       "481        0.999862             9  \n",
       "482        0.999935             7  \n",
       "483        0.994905             5  \n",
       "484        0.999999             4  \n",
       "485        0.999972             0  \n",
       "486        0.999603             8  \n",
       "487        0.997961             9  \n",
       "488        0.998771             9  \n",
       "489        0.999922             1  \n",
       "490        0.999799             0  \n",
       "491        0.999407             5  \n",
       "492        0.987551             2  \n",
       "493        0.999986             3  \n",
       "494        0.999989             7  \n",
       "496        0.999788             9  \n",
       "497        0.992982             4  \n",
       "499        0.999663             6  \n",
       "\n",
       "[442 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_IDM[df_M_representation_result_IDM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.530925</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.669924</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.983897</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "62                         9                           0.34                9   \n",
       "78                         0                           0.34                9   \n",
       "95                         8                           0.34                4   \n",
       "97                         7                           0.38                7   \n",
       "243                        7                           0.32                7   \n",
       "460                        2                           0.34                5   \n",
       "495                        8                           0.38                8   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "62         0.530925             9  \n",
       "78         0.669924             9  \n",
       "95         0.999936             4  \n",
       "97         0.999799             7  \n",
       "243        0.999830             7  \n",
       "460        0.983897             5  \n",
       "495        0.997395             8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_IDM[df_M_representation_result_IDM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C_representation_result_ODM = concact_results_OD(mnist_train_RGB_x,C_representation_result_ODM[1],C_representation_result_ODM[2],C_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.812479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "21                         1                           0.76                2   \n",
       "88                         1                           0.92                1   \n",
       "118                        1                           0.92                2   \n",
       "326                        1                           0.80                2   \n",
       "352                        1                           0.88                5   \n",
       "359                        1                           0.82                1   \n",
       "494                        1                           0.78                1   \n",
       "\n",
       "     predicted_prob  \n",
       "21         0.783019  \n",
       "88         0.882425  \n",
       "118        0.552476  \n",
       "326        0.812479  \n",
       "352        0.988199  \n",
       "359        0.574194  \n",
       "494        0.646448  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_ODM[df_C_representation_result_ODM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.647042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.914630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.602245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.727295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.942710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.974407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.299336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.650533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.589536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.799837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.966861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.822357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.930999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.601866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          9                           0.20                0   \n",
       "3                          9                           0.26                2   \n",
       "4                          9                           0.22                2   \n",
       "6                          9                           0.18                2   \n",
       "7                          9                           0.30                1   \n",
       "8                          9                           0.30                2   \n",
       "10                         7                           0.20                2   \n",
       "11                         9                           0.26                2   \n",
       "12                         9                           0.28                2   \n",
       "14                         9                           0.30                2   \n",
       "15                         2                           0.28                0   \n",
       "16                         5                           0.24                0   \n",
       "18                         1                           0.24                2   \n",
       "20                         9                           0.18                0   \n",
       "22                         2                           0.34                2   \n",
       "23                         2                           0.20                0   \n",
       "25                         5                           0.18                2   \n",
       "26                         9                           0.32                0   \n",
       "27                         7                           0.32                2   \n",
       "29                         0                           0.26                0   \n",
       "30                         7                           0.30                0   \n",
       "31                         3                           0.26                0   \n",
       "32                         1                           0.30                2   \n",
       "33                         2                           0.32                2   \n",
       "34                         5                           0.30                2   \n",
       "35                         5                           0.36                2   \n",
       "36                         2                           0.30                2   \n",
       "37                         5                           0.26                5   \n",
       "38                         0                           0.34                0   \n",
       "39                         5                           0.38                2   \n",
       "..                       ...                            ...              ...   \n",
       "465                        9                           0.28                2   \n",
       "466                        9                           0.36                2   \n",
       "467                        5                           0.22                0   \n",
       "468                        5                           0.22                0   \n",
       "469                        5                           0.36                0   \n",
       "470                        2                           0.30                2   \n",
       "471                        2                           0.36                2   \n",
       "473                        1                           0.34                2   \n",
       "474                        9                           0.34                2   \n",
       "475                        2                           0.26                0   \n",
       "476                        9                           0.24                2   \n",
       "477                        0                           0.20                0   \n",
       "478                        0                           0.22                0   \n",
       "479                        9                           0.24                2   \n",
       "480                        2                           0.34                2   \n",
       "481                        9                           0.34                0   \n",
       "482                        3                           0.24                2   \n",
       "483                        5                           0.26                0   \n",
       "484                        9                           0.24                2   \n",
       "485                        5                           0.34                0   \n",
       "486                        9                           0.34                2   \n",
       "487                        5                           0.34                0   \n",
       "489                        0                           0.20                2   \n",
       "490                        9                           0.28                2   \n",
       "491                        0                           0.20                0   \n",
       "492                        2                           0.34                2   \n",
       "493                        0                           0.26                0   \n",
       "495                        3                           0.24                0   \n",
       "497                        7                           0.30                0   \n",
       "499                        5                           0.36                2   \n",
       "\n",
       "     predicted_prob  \n",
       "0          0.987092  \n",
       "3          0.797273  \n",
       "4          0.998277  \n",
       "6          0.999707  \n",
       "7          0.958599  \n",
       "8          0.647042  \n",
       "10         0.914630  \n",
       "11         0.965705  \n",
       "12         0.897918  \n",
       "14         0.998828  \n",
       "15         0.602245  \n",
       "16         0.990215  \n",
       "18         0.995460  \n",
       "20         0.999908  \n",
       "22         0.727295  \n",
       "23         0.714947  \n",
       "25         0.988291  \n",
       "26         0.914478  \n",
       "27         0.942710  \n",
       "29         0.997996  \n",
       "30         0.913736  \n",
       "31         0.318902  \n",
       "32         0.996099  \n",
       "33         0.999620  \n",
       "34         0.841233  \n",
       "35         0.999052  \n",
       "36         0.977818  \n",
       "37         0.974407  \n",
       "38         0.999868  \n",
       "39         0.987494  \n",
       "..              ...  \n",
       "465        0.299336  \n",
       "466        0.650533  \n",
       "467        0.998859  \n",
       "468        0.995528  \n",
       "469        0.935032  \n",
       "470        0.999060  \n",
       "471        0.991158  \n",
       "473        0.589536  \n",
       "474        0.993401  \n",
       "475        0.991422  \n",
       "476        0.799837  \n",
       "477        0.536664  \n",
       "478        0.999170  \n",
       "479        0.997516  \n",
       "480        0.986726  \n",
       "481        0.999776  \n",
       "482        0.966861  \n",
       "483        0.999095  \n",
       "484        0.822357  \n",
       "485        0.968725  \n",
       "486        0.930999  \n",
       "487        0.905537  \n",
       "489        0.601866  \n",
       "490        0.996350  \n",
       "491        0.993027  \n",
       "492        0.997020  \n",
       "493        0.993391  \n",
       "495        0.607232  \n",
       "497        0.965460  \n",
       "499        0.997396  \n",
       "\n",
       "[398 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_ODM[df_C_representation_result_ODM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C_representation_result_IDC = concact_results_ID(C_x_test,C_y_test,C_representation_result_IDC[1],C_representation_result_IDC[2],C_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995010</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>6</td>\n",
       "      <td>0.76</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>6</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>0.649042</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "95                         6                           0.84                6   \n",
       "96                         6                           0.88                6   \n",
       "231                        1                           0.78                1   \n",
       "296                        6                           0.88                6   \n",
       "299                        6                           0.90                6   \n",
       "311                        6                           0.90                6   \n",
       "329                        6                           0.90                6   \n",
       "330                        1                           0.78                1   \n",
       "334                        6                           0.76                6   \n",
       "369                        1                           0.72                1   \n",
       "380                        6                           0.92                6   \n",
       "382                        0                           0.72                0   \n",
       "456                        6                           0.74                3   \n",
       "481                        6                           0.88                6   \n",
       "490                        1                           0.82                1   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "95         0.995010             6  \n",
       "96         0.999260             6  \n",
       "231        0.999959             1  \n",
       "296        0.999957             6  \n",
       "299        0.999859             6  \n",
       "311        0.999821             6  \n",
       "329        0.999586             6  \n",
       "330        0.999903             1  \n",
       "334        0.999979             6  \n",
       "369        0.999850             1  \n",
       "380        0.999156             6  \n",
       "382        0.999850             0  \n",
       "456        0.649042             3  \n",
       "481        0.999925             6  \n",
       "490        0.999938             1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_IDC[df_C_representation_result_IDC['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997884</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973371</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864438</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.638579</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>7</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998640</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>6</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989650</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995848</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824856</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.470286</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.974922</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.991903</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.761012</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.973906</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          9                           0.34                3   \n",
       "1                          1                           0.28                8   \n",
       "3                          3                           0.26                0   \n",
       "4                          6                           0.36                6   \n",
       "5                          2                           0.24                6   \n",
       "6                          7                           0.32                1   \n",
       "7                          3                           0.24                6   \n",
       "8                          4                           0.30                3   \n",
       "9                          9                           0.28                1   \n",
       "10                         5                           0.20                0   \n",
       "11                         9                           0.38                9   \n",
       "12                         7                           0.22                5   \n",
       "13                         5                           0.24                7   \n",
       "14                         9                           0.38                9   \n",
       "16                         7                           0.36                5   \n",
       "19                         4                           0.28                6   \n",
       "20                         7                           0.24                7   \n",
       "21                         0                           0.32                0   \n",
       "22                         9                           0.20                4   \n",
       "24                         0                           0.24                5   \n",
       "25                         9                           0.24                2   \n",
       "26                         1                           0.30                4   \n",
       "27                         7                           0.22                0   \n",
       "28                         1                           0.32                9   \n",
       "29                         5                           0.38                6   \n",
       "31                         8                           0.20                5   \n",
       "32                         4                           0.32                4   \n",
       "33                         0                           0.22                5   \n",
       "35                         4                           0.26                2   \n",
       "36                         4                           0.30                4   \n",
       "..                       ...                            ...              ...   \n",
       "457                        7                           0.18                5   \n",
       "459                        8                           0.30                6   \n",
       "460                        5                           0.30                5   \n",
       "461                        6                           0.18                6   \n",
       "463                        4                           0.28                4   \n",
       "464                        9                           0.38                3   \n",
       "465                        2                           0.20                4   \n",
       "466                        7                           0.38                4   \n",
       "467                        9                           0.22                3   \n",
       "469                        3                           0.20                8   \n",
       "470                        4                           0.28                4   \n",
       "471                        4                           0.28                7   \n",
       "474                        9                           0.28                5   \n",
       "475                        2                           0.24                7   \n",
       "476                        6                           0.22                6   \n",
       "478                        7                           0.16                5   \n",
       "479                        8                           0.24                4   \n",
       "483                        8                           0.26                5   \n",
       "484                        7                           0.24                5   \n",
       "485                        9                           0.30                9   \n",
       "487                        9                           0.28                9   \n",
       "488                        0                           0.24                5   \n",
       "491                        2                           0.24                0   \n",
       "493                        1                           0.38                1   \n",
       "494                        5                           0.20                1   \n",
       "495                        8                           0.34                8   \n",
       "496                        5                           0.16                0   \n",
       "497                        0                           0.20                2   \n",
       "498                        2                           0.22                2   \n",
       "499                        0                           0.22                0   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "0          0.998380             3  \n",
       "1          0.999866             8  \n",
       "3          0.999574             0  \n",
       "4          0.999851             6  \n",
       "5          0.999952             6  \n",
       "6          0.999344             1  \n",
       "7          0.999454             6  \n",
       "8          0.999920             3  \n",
       "9          0.998949             1  \n",
       "10         0.999819             0  \n",
       "11         0.999923             9  \n",
       "12         0.998151             5  \n",
       "13         0.999975             7  \n",
       "14         0.999852             9  \n",
       "16         0.999618             5  \n",
       "19         0.999930             6  \n",
       "20         0.999091             7  \n",
       "21         0.999877             0  \n",
       "22         0.997884             4  \n",
       "24         0.999778             5  \n",
       "25         0.973371             2  \n",
       "26         0.998684             4  \n",
       "27         0.999893             0  \n",
       "28         0.999176             9  \n",
       "29         0.999982             6  \n",
       "31         0.999884             5  \n",
       "32         0.864438             4  \n",
       "33         0.997083             5  \n",
       "35         0.638579             2  \n",
       "36         0.997051             4  \n",
       "..              ...           ...  \n",
       "457        0.999626             5  \n",
       "459        0.998640             6  \n",
       "460        0.999792             5  \n",
       "461        0.999633             6  \n",
       "463        0.989650             4  \n",
       "464        0.995848             3  \n",
       "465        0.999857             4  \n",
       "466        0.999676             4  \n",
       "467        0.999959             3  \n",
       "469        0.999936             8  \n",
       "470        0.824856             3  \n",
       "471        0.999882             7  \n",
       "474        0.470286             5  \n",
       "475        0.999877             7  \n",
       "476        0.999663             6  \n",
       "478        0.996148             5  \n",
       "479        0.999609             4  \n",
       "483        0.974922             5  \n",
       "484        0.991903             5  \n",
       "485        0.761012             9  \n",
       "487        0.999856             9  \n",
       "488        0.973906             5  \n",
       "491        0.999502             0  \n",
       "493        0.999908             1  \n",
       "494        0.999923             1  \n",
       "495        0.999920             8  \n",
       "496        0.999767             0  \n",
       "497        0.999738             2  \n",
       "498        0.999976             2  \n",
       "499        0.998370             0  \n",
       "\n",
       "[401 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C_representation_result_IDC[df_C_representation_result_IDC['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_0_8_vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 9\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('MNIST_vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 25\n",
    "        learning_rate = 0.001\n",
    "        lr_decay = 1e-5\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        x_train,y_train,x_test,y_test = MNIST_ID\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        sgd = optimizers.adam(lr=learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('MNIST_vgg.h5')\n",
    "        return model\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n",
    "#     x_train, y_train, x_test, y_test = MNIST_ID\n",
    "#     x_train = x_train.astype('float32')\n",
    "#     x_test = x_test.astype('float32')\n",
    "\n",
    "#     y_train = keras.utils.to_categorical(y_train, 9)\n",
    "#     y_test = keras.utils.to_categorical(y_test, 9)\n",
    "\n",
    "#     model = MNIST_0_8_vgg()\n",
    "\n",
    "#     predicted_x = model.predict(x_test)\n",
    "#     residuals = np.argmax(predicted_x,1)!=np.argmax(y_test,1)\n",
    "\n",
    "#     loss = sum(residuals)/len(residuals)\n",
    "#     print(\"the validation 0/1 loss is: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"df_M_0_8_representation_result_ID08.pkl\",\"rb+\")\n",
    "df_M_0_8_representation_result_ID08 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"df_M_0_8_representation_result_OD9.pkl\",\"rb+\")\n",
    "df_M_0_8_representation_result_OD9 = pickle.load(fp, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2 = [df_M_0_8_representation_result_OD9, df_M_0_8_representation_result_ID08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12025316455696203, 0.0273972602739726)\n",
      "(0.9040178571428571, 0.2222222222222222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for df in df_s2:\n",
    "    print(consistency_of_df(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
