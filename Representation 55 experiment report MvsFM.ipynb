{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "def MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y):\n",
    "    \"\"\"\n",
    "    Change the one-channel to RBG-channel on mnist_train_x and mnist_test_x\n",
    "    Change the shape of mnist_train_y and mnist_test_y from (length) to (length,1)\n",
    "    ---------------------------------------\n",
    "    inputs:\n",
    "    mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y which is all multi-dimension array\n",
    "    It is recommended to use the following way to import the data\n",
    "    ========================== codes ==========================\n",
    "    mnist = keras.datasets.mnist\n",
    "    (mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "    ========================== codes ==========================\n",
    "    outputs:\n",
    "    mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y \n",
    "    \"\"\"\n",
    "    from skimage import exposure\n",
    "    import imutils\n",
    "    B= []\n",
    "    for i in range(len(mnist_train_x)):\n",
    "        A = mnist_train_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_train_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    B= []\n",
    "    for i in range(len(mnist_test_x)):\n",
    "        A = mnist_test_x[i]\n",
    "        A = exposure.rescale_intensity(A, out_range=(0, 255))\n",
    "        A = imutils.resize(A, width=32)\n",
    "        B.append(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    mnist_test_RGB_x = np.repeat(B[:,:, :, np.newaxis], 3, axis=3)\n",
    "    M_train_y = np.array([[mnist_train_y[i]] for i in range(len(mnist_train_y))])\n",
    "    M_test_y = np.array([[mnist_test_y[i]] for i in range(len(mnist_test_y))])\n",
    "    return mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y\n",
    "\n",
    "mnist_train_RGB_x, M_train_y, mnist_test_RGB_x, M_test_y = MNIST_To_CIFAR_FORM(mnist_train_x, mnist_train_y,mnist_test_x, mnist_test_y)\n",
    "(C_x_train, C_y_train), (C_x_test, C_y_test) = cifar10.load_data()\n",
    "\n",
    "(fm_x_train, fm_y_train), (fm_x_test, fm_y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "fm_train_RGB_x, fm_train_y, fm_test_RGB_x, fm_test_y = MNIST_To_CIFAR_FORM(fm_x_train, fm_y_train,fm_x_test, fm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_vgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('MNIST_vgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 25\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        x_train,y_train,x_test,y_test = mnist_train_RGB_x,M_train_y,mnist_test_RGB_x,M_test_y\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('MNIST_vgg.h5')\n",
    "        return model\n",
    "    \n",
    "class fmvgg:\n",
    "    def __init__(self,train=True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('fmvgg.h5')\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = np.mean(x)\n",
    "        std = np.std(x)\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)\n",
    "\n",
    "    def train(self,model):\n",
    "\n",
    "        #training parameters\n",
    "        batch_size = 128\n",
    "        maxepoches = 300\n",
    "        learning_rate = 0.001\n",
    "        lr_decay = 1e-5\n",
    "        lr_drop = 20\n",
    "        # The data, shuffled and split between train and test sets:\n",
    "        x_train, y_train, x_test, y_test = fm_train_RGB_x, fm_train_y, fm_test_RGB_x, fm_test_y\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        #data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "        #optimization details\n",
    "        # sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "        sgd = optimizers.adam(lr=learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # training process in a for loop with learning rate drop every 25 epoches.\n",
    "\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=maxepoches,\n",
    "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
    "        model.save_weights('fmvgg.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1112 02:17:47.689144 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1112 02:17:47.702110 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1112 02:17:47.723054 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1112 02:17:47.724053 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1112 02:17:47.725049 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1112 02:17:50.075269 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1112 02:17:50.143086 27164 deprecation.py:506] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1112 02:17:50.240825 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1112 02:17:52.075962 27164 deprecation_wrapper.py:119] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1112 02:17:52.305351 27164 deprecation.py:323] From c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"MNIST-VGG-3.pkl\",\"rb+\")\n",
    "M_VGG_Model3 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"FM-VGG-3.pkl\",\"rb+\")\n",
    "FM_VGG_Model3 = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"FM_representation_result_IDFM.pkl\",\"rb+\")\n",
    "FM_representation_result_IDFM = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"FM_representation_result_ODM.pkl\",\"rb+\")\n",
    "FM_representation_result_ODM = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"M_representation_result_ODFM.pkl\",\"rb+\")\n",
    "M_representation_result_ODFM = pickle.load(fp, encoding='bytes')\n",
    "fp = open(\"M_representation_result_IDM.pkl\",\"rb+\")\n",
    "M_representation_result_IDM = pickle.load(fp, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concact_results_OD(one_sample,arr_KNN_from_same_class_ratio, arr_KNN_max_class_label,MODEL):\n",
    "    pred_labels = MODEL.predict(one_sample[:500])\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],})\n",
    "    return df\n",
    "def concact_results_ID(one_sample,ground_truth_one_sample, arr_KNN_from_same_class_ratio, arr_KNN_max_class_label,MODEL):\n",
    "    pred_labels = MODEL.predict(one_sample[:500])\n",
    "    ground_truth_one_sample = ground_truth_one_sample.reshape(-1)\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n",
    "                   'arr_KNN_from_same_class_ratio':arr_KNN_from_same_class_ratio,\n",
    "                   'predicted_label':find_statistics(pred_labels)[2],\n",
    "                  'predicted_prob':find_statistics(pred_labels)[1],\n",
    "                'ground_truth':ground_truth_one_sample[:500]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency_of_df(df, upper_bound, lower_bound):\n",
    "    return len(df[df['arr_KNN_from_same_class_ratio']>upper_bound][df['arr_KNN_max_class_label'] == df['predicted_label']])/len(df[df['arr_KNN_from_same_class_ratio']>upper_bound]), len(df[df['arr_KNN_from_same_class_ratio']<lower_bound][df['arr_KNN_max_class_label'] == df['predicted_label']])/len(df[df['arr_KNN_from_same_class_ratio']<lower_bound])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n\t [[activation_15/Softmax/_3155]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-24c1e1b46ed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_M_representation_result_ODFM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcact_results_OD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfm_train_RGB_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_representation_result_ODFM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_representation_result_ODFM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_VGG_Model3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-25befd8f810b>\u001b[0m in \u001b[0;36mconcact_results_OD\u001b[1;34m(one_sample, arr_KNN_from_same_class_ratio, arr_KNN_max_class_label, MODEL)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconcact_results_OD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr_KNN_from_same_class_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_KNN_max_class_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     df = pd.DataFrame({'arr_KNN_max_class_label':arr_KNN_max_class_label,\n\u001b[0;32m      5\u001b[0m                    \u001b[1;34m'arr_KNN_from_same_class_ratio'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0marr_KNN_from_same_class_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-09915c3292a7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, normalize, batch_size)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_production\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n\t [[activation_15/Softmax/_3155]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node activation_1/Relu}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "df_M_representation_result_ODFM = concact_results_OD(fm_train_RGB_x,M_representation_result_ODFM[1],M_representation_result_ODFM[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_M_representation_result_ODFM[df_M_representation_result_ODFM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_M_representation_result_ODFM[df_M_representation_result_ODFM['arr_KNN_from_same_class_ratio']>0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_M_representation_result_ODFM[df_M_representation_result_ODFM['arr_KNN_from_same_class_ratio']>0.7][df_M_representation_result_ODFM['arr_KNN_max_class_label'] == df_M_representation_result_ODFM['predicted_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.223131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.869029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.828062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.754881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.437267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.493238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.955604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.980884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9</td>\n",
       "      <td>0.980384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.455902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.718872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.770876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.577216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.951905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.326222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.954585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.940388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.350126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.390554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.837487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.896402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.721837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.912700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.984478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.398803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>7</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.543499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.411857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.510567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.996437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.249650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.813529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.326427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.653694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.515971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.553844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.928808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "5                          4                           0.32                0   \n",
       "9                          2                           0.24                5   \n",
       "13                         0                           0.38                0   \n",
       "26                         8                           0.22                1   \n",
       "30                         1                           0.32                2   \n",
       "43                         8                           0.32                0   \n",
       "47                         0                           0.38                7   \n",
       "57                         0                           0.38                6   \n",
       "70                         2                           0.22                2   \n",
       "92                         1                           0.24                7   \n",
       "94                         4                           0.32                8   \n",
       "120                        7                           0.34                0   \n",
       "123                        0                           0.36                9   \n",
       "124                        0                           0.30                7   \n",
       "126                        1                           0.36                2   \n",
       "136                        1                           0.32                4   \n",
       "153                        0                           0.30                2   \n",
       "155                        0                           0.38                0   \n",
       "184                        0                           0.28                7   \n",
       "185                        4                           0.34                7   \n",
       "194                        0                           0.36                4   \n",
       "201                        8                           0.34                2   \n",
       "204                        1                           0.26                8   \n",
       "220                        0                           0.32                0   \n",
       "225                        0                           0.38                7   \n",
       "228                        0                           0.36                0   \n",
       "233                        8                           0.26                8   \n",
       "238                        1                           0.36                4   \n",
       "242                        0                           0.34                4   \n",
       "244                        8                           0.32                0   \n",
       "..                       ...                            ...              ...   \n",
       "320                        1                           0.34                6   \n",
       "325                        4                           0.34                7   \n",
       "328                        1                           0.30                4   \n",
       "335                        2                           0.38                4   \n",
       "339                        1                           0.30                1   \n",
       "341                        0                           0.34                4   \n",
       "350                        1                           0.34                7   \n",
       "361                        0                           0.38                7   \n",
       "363                        0                           0.26                0   \n",
       "376                        1                           0.32                0   \n",
       "390                        6                           0.32                1   \n",
       "394                        0                           0.32                8   \n",
       "395                        7                           0.36                0   \n",
       "403                        8                           0.30                2   \n",
       "417                        0                           0.26                2   \n",
       "431                        0                           0.32                2   \n",
       "435                        4                           0.32                0   \n",
       "436                        8                           0.18                1   \n",
       "454                        0                           0.24                4   \n",
       "459                        4                           0.36                7   \n",
       "464                        0                           0.36                4   \n",
       "471                        0                           0.38                7   \n",
       "473                        2                           0.38                4   \n",
       "477                        0                           0.28                4   \n",
       "483                        0                           0.38                4   \n",
       "487                        7                           0.32                2   \n",
       "488                        4                           0.36                1   \n",
       "490                        1                           0.28                7   \n",
       "492                        0                           0.32                4   \n",
       "497                        0                           0.30                2   \n",
       "\n",
       "     predicted_prob  \n",
       "5          0.931305  \n",
       "9          0.223131  \n",
       "13         0.869029  \n",
       "26         0.405436  \n",
       "30         0.828062  \n",
       "43         0.716087  \n",
       "47         0.754881  \n",
       "57         0.437267  \n",
       "70         0.493238  \n",
       "92         0.955604  \n",
       "94         0.980884  \n",
       "120        0.894069  \n",
       "123        0.980384  \n",
       "124        0.455902  \n",
       "126        0.718872  \n",
       "136        0.770876  \n",
       "153        0.577216  \n",
       "155        0.413379  \n",
       "184        0.951905  \n",
       "185        0.999169  \n",
       "194        0.999467  \n",
       "201        0.326222  \n",
       "204        0.954585  \n",
       "220        0.465023  \n",
       "225        0.741392  \n",
       "228        0.522842  \n",
       "233        0.940388  \n",
       "238        0.518582  \n",
       "242        0.350126  \n",
       "244        0.957195  \n",
       "..              ...  \n",
       "320        0.390554  \n",
       "325        0.837487  \n",
       "328        0.528191  \n",
       "335        0.896402  \n",
       "339        0.923061  \n",
       "341        0.721837  \n",
       "350        0.912700  \n",
       "361        0.984478  \n",
       "363        0.813396  \n",
       "376        0.380305  \n",
       "390        0.714238  \n",
       "394        0.398803  \n",
       "395        0.522615  \n",
       "403        0.543499  \n",
       "417        0.750348  \n",
       "431        0.411857  \n",
       "435        0.977082  \n",
       "436        0.731409  \n",
       "454        0.948537  \n",
       "459        0.510567  \n",
       "464        0.996437  \n",
       "471        0.249650  \n",
       "473        0.813529  \n",
       "477        0.900396  \n",
       "483        0.326427  \n",
       "487        0.653694  \n",
       "488        0.460252  \n",
       "490        0.515971  \n",
       "492        0.553844  \n",
       "497        0.928808  \n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_ODFM[df_M_representation_result_ODFM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_M_representation_result_IDM = concact_results_ID(mnist_test_RGB_x,M_test_y,M_representation_result_IDM[1],M_representation_result_IDM[2],M_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999653</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9</td>\n",
       "      <td>0.990595</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>2</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.923092</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992982</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "0                          7                           1.00                7   \n",
       "1                          2                           1.00                2   \n",
       "2                          1                           1.00                1   \n",
       "3                          0                           1.00                0   \n",
       "4                          4                           1.00                4   \n",
       "5                          1                           1.00                1   \n",
       "6                          4                           0.98                4   \n",
       "7                          9                           0.98                9   \n",
       "9                          9                           1.00                9   \n",
       "10                         0                           1.00                0   \n",
       "11                         6                           1.00                6   \n",
       "12                         9                           1.00                9   \n",
       "13                         0                           1.00                0   \n",
       "14                         1                           1.00                1   \n",
       "15                         5                           1.00                5   \n",
       "16                         9                           1.00                9   \n",
       "17                         7                           1.00                7   \n",
       "19                         4                           1.00                4   \n",
       "20                         9                           0.82                9   \n",
       "21                         6                           0.98                6   \n",
       "22                         6                           1.00                6   \n",
       "23                         5                           1.00                5   \n",
       "24                         4                           1.00                4   \n",
       "25                         0                           1.00                0   \n",
       "27                         4                           1.00                4   \n",
       "28                         0                           1.00                0   \n",
       "29                         1                           1.00                1   \n",
       "30                         3                           1.00                3   \n",
       "31                         1                           1.00                1   \n",
       "32                         3                           1.00                3   \n",
       "..                       ...                            ...              ...   \n",
       "467                        2                           1.00                2   \n",
       "469                        2                           0.84                5   \n",
       "470                        8                           1.00                8   \n",
       "471                        9                           1.00                9   \n",
       "472                        6                           1.00                6   \n",
       "473                        1                           1.00                1   \n",
       "474                        8                           0.82                8   \n",
       "475                        4                           1.00                4   \n",
       "476                        1                           1.00                1   \n",
       "477                        2                           1.00                2   \n",
       "478                        5                           1.00                5   \n",
       "479                        9                           0.98                9   \n",
       "480                        1                           1.00                1   \n",
       "481                        9                           1.00                9   \n",
       "482                        7                           1.00                7   \n",
       "483                        5                           1.00                5   \n",
       "484                        4                           1.00                4   \n",
       "485                        0                           1.00                0   \n",
       "486                        8                           1.00                8   \n",
       "487                        9                           0.98                9   \n",
       "488                        9                           1.00                9   \n",
       "489                        1                           1.00                1   \n",
       "490                        0                           0.78                0   \n",
       "491                        5                           1.00                5   \n",
       "492                        2                           0.98                2   \n",
       "493                        3                           1.00                3   \n",
       "494                        7                           1.00                7   \n",
       "496                        9                           1.00                9   \n",
       "497                        1                           0.74                4   \n",
       "499                        6                           1.00                6   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "0          0.999994             7  \n",
       "1          0.999490             2  \n",
       "2          0.999907             1  \n",
       "3          0.999972             0  \n",
       "4          0.999983             4  \n",
       "5          0.999893             1  \n",
       "6          0.999968             4  \n",
       "7          0.996378             9  \n",
       "9          0.999572             9  \n",
       "10         0.999984             0  \n",
       "11         0.999890             6  \n",
       "12         0.999383             9  \n",
       "13         0.999986             0  \n",
       "14         0.999917             1  \n",
       "15         0.999001             5  \n",
       "16         0.999653             9  \n",
       "17         0.999978             7  \n",
       "19         0.999999             4  \n",
       "20         0.990595             9  \n",
       "21         0.999241             6  \n",
       "22         0.999920             6  \n",
       "23         0.999638             5  \n",
       "24         0.999989             4  \n",
       "25         0.999979             0  \n",
       "27         0.999998             4  \n",
       "28         0.999944             0  \n",
       "29         0.999875             1  \n",
       "30         0.999936             3  \n",
       "31         0.999926             1  \n",
       "32         0.999791             3  \n",
       "..              ...           ...  \n",
       "467        0.999543             2  \n",
       "469        0.789094             5  \n",
       "470        0.999586             8  \n",
       "471        0.923092             9  \n",
       "472        0.999899             6  \n",
       "473        0.999921             1  \n",
       "474        0.997717             8  \n",
       "475        0.999996             4  \n",
       "476        0.999918             1  \n",
       "477        0.999709             2  \n",
       "478        0.999589             5  \n",
       "479        0.996429             9  \n",
       "480        0.999856             1  \n",
       "481        0.999862             9  \n",
       "482        0.999935             7  \n",
       "483        0.994905             5  \n",
       "484        0.999999             4  \n",
       "485        0.999972             0  \n",
       "486        0.999603             8  \n",
       "487        0.997961             9  \n",
       "488        0.998771             9  \n",
       "489        0.999922             1  \n",
       "490        0.999799             0  \n",
       "491        0.999407             5  \n",
       "492        0.987551             2  \n",
       "493        0.999986             3  \n",
       "494        0.999989             7  \n",
       "496        0.999788             9  \n",
       "497        0.992982             4  \n",
       "499        0.999663             6  \n",
       "\n",
       "[442 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_IDM[df_M_representation_result_IDM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.530925</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.669924</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.983897</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "62                         9                           0.34                9   \n",
       "78                         0                           0.34                9   \n",
       "95                         8                           0.34                4   \n",
       "97                         7                           0.38                7   \n",
       "243                        7                           0.32                7   \n",
       "460                        2                           0.34                5   \n",
       "495                        8                           0.38                8   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "62         0.530925             9  \n",
       "78         0.669924             9  \n",
       "95         0.999936             4  \n",
       "97         0.999799             7  \n",
       "243        0.999830             7  \n",
       "460        0.983897             5  \n",
       "495        0.997395             8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_representation_result_IDM[df_M_representation_result_IDM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FM_representation_result_ODM = concact_results_OD(mnist_train_RGB_x,FM_representation_result_ODM[1],FM_representation_result_ODM[2],FM_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8</td>\n",
       "      <td>0.974921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.920886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2</td>\n",
       "      <td>0.385207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.721807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0.990215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7</td>\n",
       "      <td>0.84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.989189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>3</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8</td>\n",
       "      <td>0.894938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8</td>\n",
       "      <td>0.888270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8</td>\n",
       "      <td>0.993521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "      <td>0.541351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>8</td>\n",
       "      <td>0.933289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0.973378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>9</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0.602527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "5                          9                           0.72                8   \n",
       "8                          1                           0.96                1   \n",
       "21                         8                           0.84                8   \n",
       "23                         3                           0.72                1   \n",
       "40                         1                           1.00                1   \n",
       "56                         8                           0.76                0   \n",
       "82                         9                           0.86                2   \n",
       "102                        1                           0.86                1   \n",
       "104                        1                           0.86                1   \n",
       "112                        1                           0.96                1   \n",
       "124                        1                           0.80                1   \n",
       "135                        9                           0.78                8   \n",
       "156                        2                           0.86                0   \n",
       "168                        3                           0.78                1   \n",
       "174                        1                           0.86                1   \n",
       "180                        8                           0.86                1   \n",
       "193                        0                           0.78                8   \n",
       "199                        7                           0.84                8   \n",
       "264                        3                           0.74                0   \n",
       "270                        1                           0.82                1   \n",
       "276                        1                           0.92                1   \n",
       "309                        3                           0.80                1   \n",
       "310                        1                           0.86                1   \n",
       "330                        2                           0.86                8   \n",
       "397                        3                           0.80                1   \n",
       "423                        4                           0.72                8   \n",
       "447                        3                           0.72                1   \n",
       "448                        9                           0.78                8   \n",
       "452                        9                           0.80                8   \n",
       "454                        1                           0.98                6   \n",
       "475                        3                           0.90                1   \n",
       "477                        9                           0.96                8   \n",
       "479                        2                           0.90                8   \n",
       "497                        9                           0.90                8   \n",
       "\n",
       "     predicted_prob  \n",
       "5          0.974921  \n",
       "8          0.926724  \n",
       "21         0.920886  \n",
       "23         0.952120  \n",
       "40         0.998118  \n",
       "56         0.443508  \n",
       "82         0.385207  \n",
       "102        0.984364  \n",
       "104        0.987287  \n",
       "112        0.991701  \n",
       "124        0.929854  \n",
       "135        0.996298  \n",
       "156        0.721807  \n",
       "168        0.863586  \n",
       "174        0.968076  \n",
       "180        0.869710  \n",
       "193        0.990215  \n",
       "199        0.989189  \n",
       "264        0.443231  \n",
       "270        0.449305  \n",
       "276        0.591703  \n",
       "309        0.990564  \n",
       "310        0.974263  \n",
       "330        0.894938  \n",
       "397        0.980993  \n",
       "423        0.888270  \n",
       "447        0.966857  \n",
       "448        0.500363  \n",
       "452        0.993521  \n",
       "454        0.541351  \n",
       "475        0.971047  \n",
       "477        0.933289  \n",
       "479        0.973378  \n",
       "497        0.602527  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FM_representation_result_ODM[df_FM_representation_result_ODM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.744535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.883240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.935659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.868039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.884808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.927261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.848993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.854105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.488206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.609902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.974942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.959948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.952336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.464874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.908826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.674861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.425101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.742648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.583293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.505959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.405891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.918956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.903109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.967850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.646868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.968569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.874108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.690904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.654959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.638222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.980431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.970060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.632056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.780763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.457622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.920437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "4                          1                           0.22                8   \n",
       "6                          1                           0.30                1   \n",
       "7                          2                           0.32                8   \n",
       "13                         3                           0.38                0   \n",
       "15                         6                           0.22                8   \n",
       "16                         2                           0.18                8   \n",
       "17                         4                           0.36                8   \n",
       "27                         8                           0.36                8   \n",
       "31                         4                           0.34                8   \n",
       "32                         3                           0.28                0   \n",
       "33                         0                           0.36                8   \n",
       "34                         4                           0.28                8   \n",
       "36                         5                           0.30                8   \n",
       "37                         9                           0.30                8   \n",
       "38                         0                           0.32                0   \n",
       "41                         3                           0.20                0   \n",
       "43                         3                           0.28                1   \n",
       "44                         2                           0.32                0   \n",
       "46                         3                           0.34                8   \n",
       "48                         3                           0.38                1   \n",
       "49                         2                           0.20                8   \n",
       "51                         8                           0.28                2   \n",
       "52                         3                           0.26                8   \n",
       "57                         4                           0.30                8   \n",
       "60                         4                           0.26                2   \n",
       "61                         0                           0.34                8   \n",
       "62                         9                           0.34                8   \n",
       "64                         3                           0.36                0   \n",
       "67                         2                           0.32                1   \n",
       "69                         4                           0.28                8   \n",
       "..                       ...                            ...              ...   \n",
       "427                        8                           0.24                7   \n",
       "430                        3                           0.26                8   \n",
       "432                        4                           0.36                8   \n",
       "433                        5                           0.28                8   \n",
       "435                        8                           0.30                0   \n",
       "439                        4                           0.28                8   \n",
       "441                        6                           0.26                1   \n",
       "449                        4                           0.28                3   \n",
       "450                        2                           0.30                1   \n",
       "451                        0                           0.34                8   \n",
       "456                        1                           0.38                0   \n",
       "458                        2                           0.28                2   \n",
       "461                        4                           0.22                2   \n",
       "464                        8                           0.22                0   \n",
       "467                        8                           0.34                8   \n",
       "468                        6                           0.28                8   \n",
       "470                        6                           0.30                1   \n",
       "472                        6                           0.32                1   \n",
       "473                        2                           0.32                8   \n",
       "476                        5                           0.38                8   \n",
       "481                        2                           0.24                8   \n",
       "482                        1                           0.26                1   \n",
       "483                        9                           0.34                8   \n",
       "485                        2                           0.32                8   \n",
       "486                        9                           0.30                8   \n",
       "487                        2                           0.22                8   \n",
       "492                        3                           0.22                1   \n",
       "494                        8                           0.26                8   \n",
       "496                        4                           0.34                8   \n",
       "499                        3                           0.20                0   \n",
       "\n",
       "     predicted_prob  \n",
       "4          0.744535  \n",
       "6          0.996362  \n",
       "7          0.883240  \n",
       "13         0.991715  \n",
       "15         0.935659  \n",
       "16         0.868039  \n",
       "17         0.884808  \n",
       "27         0.927261  \n",
       "31         0.848993  \n",
       "32         0.985358  \n",
       "33         0.854105  \n",
       "34         0.488206  \n",
       "36         0.609902  \n",
       "37         0.974942  \n",
       "38         0.802506  \n",
       "41         0.630400  \n",
       "43         0.454414  \n",
       "44         0.967876  \n",
       "46         0.959948  \n",
       "48         0.569515  \n",
       "49         0.952336  \n",
       "51         0.464874  \n",
       "52         0.908826  \n",
       "57         0.674861  \n",
       "60         0.991407  \n",
       "61         0.425101  \n",
       "62         0.742648  \n",
       "64         0.400859  \n",
       "67         0.993956  \n",
       "69         0.583293  \n",
       "..              ...  \n",
       "427        0.505959  \n",
       "430        0.405891  \n",
       "432        0.918956  \n",
       "433        0.903109  \n",
       "435        0.923357  \n",
       "439        0.967850  \n",
       "441        0.871045  \n",
       "449        0.281493  \n",
       "450        0.726918  \n",
       "451        0.646868  \n",
       "456        0.469533  \n",
       "458        0.475236  \n",
       "461        0.704782  \n",
       "464        0.697835  \n",
       "467        0.968569  \n",
       "468        0.874108  \n",
       "470        0.644633  \n",
       "472        0.945853  \n",
       "473        0.690904  \n",
       "476        0.654959  \n",
       "481        0.638222  \n",
       "482        0.855819  \n",
       "483        0.980431  \n",
       "485        0.970060  \n",
       "486        0.632056  \n",
       "487        0.780763  \n",
       "492        0.931218  \n",
       "494        0.457622  \n",
       "496        0.920437  \n",
       "499        0.842110  \n",
       "\n",
       "[244 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FM_representation_result_ODM[df_FM_representation_result_ODM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FM_representation_result_IDFM = concact_results_ID(fm_test_RGB_x,fm_test_y,FM_representation_result_IDFM[1],FM_representation_result_IDFM[2],FM_VGG_Model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997872</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997555</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833627</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995362</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>7</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>5</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>7</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>7</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.981596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>3</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995052</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>7</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "2                          1                           1.00                1   \n",
       "3                          1                           0.98                1   \n",
       "5                          1                           1.00                1   \n",
       "6                          1                           0.98                4   \n",
       "8                          5                           0.84                5   \n",
       "9                          7                           0.92                7   \n",
       "11                         5                           0.76                5   \n",
       "13                         3                           0.74                3   \n",
       "15                         1                           0.96                1   \n",
       "19                         0                           0.76                0   \n",
       "22                         7                           0.84                7   \n",
       "24                         1                           1.00                1   \n",
       "30                         8                           0.86                8   \n",
       "32                         1                           1.00                3   \n",
       "36                         7                           0.88                7   \n",
       "37                         5                           0.86                5   \n",
       "38                         7                           0.86                7   \n",
       "39                         9                           1.00                9   \n",
       "41                         1                           1.00                1   \n",
       "45                         7                           0.72                7   \n",
       "47                         1                           0.84                1   \n",
       "52                         5                           0.94                5   \n",
       "55                         2                           0.80                2   \n",
       "56                         8                           0.80                8   \n",
       "57                         6                           0.74                4   \n",
       "58                         8                           0.84                8   \n",
       "61                         7                           0.72                7   \n",
       "63                         5                           0.88                5   \n",
       "64                         1                           1.00                1   \n",
       "65                         1                           1.00                1   \n",
       "..                       ...                            ...              ...   \n",
       "399                        2                           0.90                2   \n",
       "402                        7                           0.90                7   \n",
       "409                        1                           1.00                1   \n",
       "415                        5                           0.78                4   \n",
       "417                        1                           0.98                1   \n",
       "420                        7                           0.84                5   \n",
       "422                        8                           0.76                8   \n",
       "424                        8                           0.84                8   \n",
       "426                        4                           0.74                4   \n",
       "428                        9                           0.84                9   \n",
       "429                        8                           0.90                8   \n",
       "432                        4                           0.72                4   \n",
       "436                        1                           1.00                1   \n",
       "438                        1                           1.00                1   \n",
       "439                        3                           0.76                3   \n",
       "447                        1                           1.00                1   \n",
       "448                        7                           0.78                9   \n",
       "451                        3                           0.80                3   \n",
       "453                        1                           0.92                1   \n",
       "455                        2                           0.78                2   \n",
       "462                        2                           0.98                2   \n",
       "466                        3                           0.74                3   \n",
       "472                        0                           0.96                0   \n",
       "481                        9                           0.90                9   \n",
       "487                        1                           1.00                1   \n",
       "488                        0                           0.82                0   \n",
       "489                        0                           0.88                0   \n",
       "494                        7                           0.74                7   \n",
       "496                        1                           1.00                1   \n",
       "497                        2                           1.00                2   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "2          0.999982             1  \n",
       "3          0.999995             1  \n",
       "5          0.999993             1  \n",
       "6          0.997872             4  \n",
       "8          0.999892             5  \n",
       "9          0.999997             7  \n",
       "11         0.999852             5  \n",
       "13         0.997555             3  \n",
       "15         0.999995             1  \n",
       "19         0.999496             0  \n",
       "22         0.999970             7  \n",
       "24         0.999977             1  \n",
       "30         0.999990             8  \n",
       "32         0.833627             3  \n",
       "36         0.999885             7  \n",
       "37         0.999961             5  \n",
       "38         0.999965             7  \n",
       "39         0.999975             9  \n",
       "41         0.999981             1  \n",
       "45         0.997853             7  \n",
       "47         0.999894             1  \n",
       "52         0.999953             5  \n",
       "55         0.995362             2  \n",
       "56         0.999991             8  \n",
       "57         0.992534             4  \n",
       "58         0.999920             8  \n",
       "61         0.999751             7  \n",
       "63         0.999936             5  \n",
       "64         0.999973             1  \n",
       "65         0.999991             1  \n",
       "..              ...           ...  \n",
       "399        0.996216             2  \n",
       "402        0.999930             7  \n",
       "409        0.999993             1  \n",
       "415        0.998319             4  \n",
       "417        0.999977             1  \n",
       "420        0.999952             5  \n",
       "422        0.999986             8  \n",
       "424        0.999979             8  \n",
       "426        0.999917             4  \n",
       "428        0.999950             9  \n",
       "429        0.999998             8  \n",
       "432        0.999801             4  \n",
       "436        0.999995             1  \n",
       "438        0.999962             1  \n",
       "439        0.997689             3  \n",
       "447        0.999990             1  \n",
       "448        0.999766             9  \n",
       "451        0.994076             3  \n",
       "453        0.999995             1  \n",
       "455        0.997570             2  \n",
       "462        0.981596             2  \n",
       "466        0.995052             3  \n",
       "472        0.999988             0  \n",
       "481        0.999983             9  \n",
       "487        0.999990             1  \n",
       "488        0.833891             0  \n",
       "489        0.999995             0  \n",
       "494        0.999973             7  \n",
       "496        0.999985             1  \n",
       "497        0.998611             2  \n",
       "\n",
       "[176 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FM_representation_result_IDFM[df_FM_representation_result_IDFM['arr_KNN_from_same_class_ratio']>0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_KNN_max_class_label</th>\n",
       "      <th>arr_KNN_from_same_class_ratio</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9</td>\n",
       "      <td>0.594272</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997714</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.929888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.981747</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.809682</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998891</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997497</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.978797</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>7</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998889</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.518214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998336</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.833045</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974040</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999314</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817767</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.969499</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998568</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.997578</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9</td>\n",
       "      <td>0.994234</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_KNN_max_class_label  arr_KNN_from_same_class_ratio  predicted_label  \\\n",
       "18                         6                           0.32                8   \n",
       "23                         0                           0.22                9   \n",
       "29                         4                           0.32                3   \n",
       "33                         4                           0.38                3   \n",
       "34                         0                           0.30                8   \n",
       "40                         4                           0.38                6   \n",
       "48                         5                           0.28                2   \n",
       "51                         5                           0.26                4   \n",
       "66                         2                           0.26                2   \n",
       "67                         3                           0.38                3   \n",
       "81                         4                           0.34                8   \n",
       "82                         2                           0.34                5   \n",
       "91                         3                           0.32                3   \n",
       "92                         6                           0.34                6   \n",
       "103                        2                           0.38                2   \n",
       "105                        5                           0.30                8   \n",
       "116                        8                           0.36                8   \n",
       "124                        0                           0.36                3   \n",
       "128                        1                           0.30                1   \n",
       "136                        2                           0.32                2   \n",
       "145                        4                           0.38                6   \n",
       "150                        2                           0.36                3   \n",
       "156                        4                           0.28                4   \n",
       "160                        5                           0.32                7   \n",
       "168                        4                           0.36                4   \n",
       "182                        3                           0.32                3   \n",
       "188                        4                           0.34                4   \n",
       "196                        7                           0.34                8   \n",
       "198                        6                           0.28                6   \n",
       "205                        4                           0.32                4   \n",
       "..                       ...                            ...              ...   \n",
       "381                        6                           0.28                6   \n",
       "383                        2                           0.22                3   \n",
       "384                        2                           0.32                5   \n",
       "387                        3                           0.34                6   \n",
       "390                        6                           0.36                6   \n",
       "393                        2                           0.38                5   \n",
       "394                        5                           0.38                2   \n",
       "403                        6                           0.28                0   \n",
       "404                        2                           0.20                4   \n",
       "416                        9                           0.30                2   \n",
       "421                        4                           0.36                3   \n",
       "423                        4                           0.34                5   \n",
       "430                        6                           0.30                6   \n",
       "433                        4                           0.36                4   \n",
       "442                        3                           0.38                8   \n",
       "443                        2                           0.30                8   \n",
       "452                        4                           0.38                0   \n",
       "457                        2                           0.36                4   \n",
       "459                        5                           0.30                6   \n",
       "463                        0                           0.36                0   \n",
       "464                        3                           0.20                0   \n",
       "467                        3                           0.28                8   \n",
       "474                        0                           0.38                6   \n",
       "477                        7                           0.38                9   \n",
       "478                        6                           0.26                2   \n",
       "479                        8                           0.36                9   \n",
       "480                        5                           0.34                5   \n",
       "484                        4                           0.38                5   \n",
       "493                        9                           0.34                9   \n",
       "495                        9                           0.36                9   \n",
       "\n",
       "     predicted_prob  ground_truth  \n",
       "18         0.999910             8  \n",
       "23         0.594272             9  \n",
       "29         0.997260             3  \n",
       "33         0.997714             3  \n",
       "34         0.999987             8  \n",
       "40         0.999169             6  \n",
       "48         0.929888             2  \n",
       "51         0.964323             4  \n",
       "66         0.789516             2  \n",
       "67         0.962343             3  \n",
       "81         0.999985             8  \n",
       "82         0.999928             5  \n",
       "91         0.999696             3  \n",
       "92         0.999861             6  \n",
       "103        0.973831             2  \n",
       "105        0.999994             8  \n",
       "116        0.999988             8  \n",
       "124        0.981747             3  \n",
       "128        0.999971             1  \n",
       "136        0.970122             2  \n",
       "145        0.998667             6  \n",
       "150        0.809682             4  \n",
       "156        0.998891             4  \n",
       "160        0.997497             7  \n",
       "168        0.999974             4  \n",
       "182        0.978797             3  \n",
       "188        0.990186             4  \n",
       "196        0.998182             8  \n",
       "198        0.999866             6  \n",
       "205        0.998889             4  \n",
       "..              ...           ...  \n",
       "381        0.518214             0  \n",
       "383        0.998336             3  \n",
       "384        0.999910             5  \n",
       "387        0.833045             6  \n",
       "390        0.999661             6  \n",
       "393        0.999945             5  \n",
       "394        0.801660             2  \n",
       "403        0.645223             0  \n",
       "404        0.974040             4  \n",
       "416        0.998401             2  \n",
       "421        0.999314             3  \n",
       "423        0.999955             5  \n",
       "430        0.999875             6  \n",
       "433        0.999909             4  \n",
       "442        0.999976             8  \n",
       "443        0.999985             8  \n",
       "452        0.747874             0  \n",
       "457        0.817767             2  \n",
       "459        0.969499             6  \n",
       "463        0.999821             0  \n",
       "464        0.999723             0  \n",
       "467        0.999969             8  \n",
       "474        0.992990             6  \n",
       "477        0.999743             9  \n",
       "478        0.998568             2  \n",
       "479        0.999976             9  \n",
       "480        0.999858             5  \n",
       "484        0.999965             5  \n",
       "493        0.997578             9  \n",
       "495        0.994234             9  \n",
       "\n",
       "[89 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FM_representation_result_IDFM[df_FM_representation_result_IDFM['arr_KNN_from_same_class_ratio']<0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = [df_M_representation_result_ODFM, df_M_representation_result_IDM, df_FM_representation_result_ODM, df_FM_representation_result_IDFM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1774891774891775, 0.1388888888888889)\n",
      "(0.9705882352941176, 0.5714285714285714)\n",
      "(0.3235294117647059, 0.16393442622950818)\n",
      "(0.9375, 0.3595505617977528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for df in df_s:\n",
    "    print(consistency_of_df(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
